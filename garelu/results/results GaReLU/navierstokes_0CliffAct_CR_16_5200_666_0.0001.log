INFO:root:*************
INFO:root:             
INFO:root:model chosen: CR
INFO:root:multivector activation function?: 0
INFO:root:training trajectories: 5200
INFO:root:training epochs: 200
INFO:root:training batchsize: 16
INFO:root:learning rate: 0.0001
INFO:root:seed: 666
INFO:root:patience: 15
INFO:root:training dataset path: datasets/trainingdataviscous/
INFO:root:test dataset path: datasets/testdataviscous/
INFO:root:             
INFO:root:*************
INFO:root:Using device: cuda
INFO:root:[[[1.6940998  1.5566934  1.3046039  1.0440726 ]
  [1.6066581  1.3995012  1.342347   1.233624  ]
  [1.4666691  1.3354036  1.3883016  1.2737162 ]
  [1.4122795  1.3854291  1.4587754  1.339578  ]]

 [[1.6459564  1.3450366  1.0299298  0.77708894]
  [1.6489182  1.5250436  1.3721011  1.2203181 ]
  [1.4844782  1.3996952  1.3643513  1.3251002 ]
  [1.3969231  1.3963239  1.4048748  1.4067723 ]]]
INFO:root:****
INFO:root:[[[1.6940998  1.5566934  1.3046039  1.0440726 ]
  [1.6066581  1.3995012  1.342347   1.233624  ]
  [1.4666691  1.3354036  1.3883016  1.2737162 ]
  [1.4122795  1.3854291  1.4587754  1.339578  ]]

 [[1.6459564  1.3450366  1.0299298  0.77708894]
  [1.6489182  1.5250436  1.3721011  1.2203181 ]
  [1.4844782  1.3996952  1.3643513  1.3251002 ]
  [1.3969231  1.3963239  1.4048748  1.4067723 ]]]
INFO:root:Train input shape: torch.Size([5200, 2, 128, 128, 3])
INFO:root:Train labels shape: torch.Size([5200, 1, 128, 128, 3])
INFO:root:                   
INFO:root:Val input shape: torch.Size([4680, 2, 128, 128, 3])
INFO:root:Val labels shape: torch.Size([4680, 1, 128, 128, 3])
INFO:root:*************
INFO:root:             
INFO:root:Starting to train....
INFO:root:  batch 100 loss: 0.2237401482462883
INFO:root:LOSS train' 0.2237401482462883, 100
INFO:root:  batch 200 loss: 0.15176510751247407
INFO:root:LOSS train' 0.15176510751247407, 200
INFO:root:  batch 300 loss: 0.12985586442053318
INFO:root:LOSS train' 0.12985586442053318, 300
INFO:root:Epoch: 0 - LOSS train: 0.12985586442053318 LOSS val: 0.11463585495948792 - Elapsed time: 155.89089965820312 s
INFO:root:  batch 100 loss: 0.11516006261110306
INFO:root:LOSS train' 0.11516006261110306, 425
INFO:root:  batch 200 loss: 0.1036349169909954
INFO:root:LOSS train' 0.1036349169909954, 525
INFO:root:  batch 300 loss: 0.09827411264181136
INFO:root:LOSS train' 0.09827411264181136, 625
INFO:root:Epoch: 1 - LOSS train: 0.09827411264181136 LOSS val: 0.08971422910690308 - Elapsed time: 154.92679476737976 s
INFO:root:  batch 100 loss: 0.08861189506947995
INFO:root:LOSS train' 0.08861189506947995, 750
INFO:root:  batch 200 loss: 0.08286004453897476
INFO:root:LOSS train' 0.08286004453897476, 850
INFO:root:  batch 300 loss: 0.0808971755951643
INFO:root:LOSS train' 0.0808971755951643, 950
INFO:root:Epoch: 2 - LOSS train: 0.0808971755951643 LOSS val: 0.0713183730840683 - Elapsed time: 154.73246359825134 s
INFO:root:  batch 100 loss: 0.07392488345503807
INFO:root:LOSS train' 0.07392488345503807, 1075
INFO:root:  batch 200 loss: 0.06966370351612568
INFO:root:LOSS train' 0.06966370351612568, 1175
INFO:root:  batch 300 loss: 0.06739564683288336
INFO:root:LOSS train' 0.06739564683288336, 1275
INFO:root:Epoch: 3 - LOSS train: 0.06739564683288336 LOSS val: 0.06491579860448837 - Elapsed time: 154.7321424484253 s
INFO:root:  batch 100 loss: 0.07402702622115612
INFO:root:LOSS train' 0.07402702622115612, 1400
INFO:root:  batch 200 loss: 0.06402110025286674
INFO:root:LOSS train' 0.06402110025286674, 1500
INFO:root:  batch 300 loss: 0.061201176717877386
INFO:root:LOSS train' 0.061201176717877386, 1600
INFO:root:Epoch: 4 - LOSS train: 0.061201176717877386 LOSS val: 0.06390772759914398 - Elapsed time: 154.97459650039673 s
INFO:root:  batch 100 loss: 0.057321498617529866
INFO:root:LOSS train' 0.057321498617529866, 1725
INFO:root:  batch 200 loss: 0.056564215943217276
INFO:root:LOSS train' 0.056564215943217276, 1825
INFO:root:  batch 300 loss: 0.05311390690505505
INFO:root:LOSS train' 0.05311390690505505, 1925
INFO:root:Epoch: 5 - LOSS train: 0.05311390690505505 LOSS val: 0.055154237896203995 - Elapsed time: 154.7448649406433 s
INFO:root:  batch 100 loss: 0.05269655492156744
INFO:root:LOSS train' 0.05269655492156744, 2050
INFO:root:  batch 200 loss: 0.04971580110490322
INFO:root:LOSS train' 0.04971580110490322, 2150
INFO:root:  batch 300 loss: 0.04966544669121504
INFO:root:LOSS train' 0.04966544669121504, 2250
INFO:root:Epoch: 6 - LOSS train: 0.04966544669121504 LOSS val: 0.04733908548951149 - Elapsed time: 155.0713164806366 s
INFO:root:  batch 100 loss: 0.04714213594794273
INFO:root:LOSS train' 0.04714213594794273, 2375
INFO:root:  batch 200 loss: 0.049313502945005895
INFO:root:LOSS train' 0.049313502945005895, 2475
INFO:root:  batch 300 loss: 0.04662047192454338
INFO:root:LOSS train' 0.04662047192454338, 2575
INFO:root:Epoch: 7 - LOSS train: 0.04662047192454338 LOSS val: 0.042248331010341644 - Elapsed time: 154.7224018573761 s
INFO:root:  batch 100 loss: 0.045714652873575685
INFO:root:LOSS train' 0.045714652873575685, 2700
INFO:root:  batch 200 loss: 0.046650501899421215
INFO:root:LOSS train' 0.046650501899421215, 2800
INFO:root:  batch 300 loss: 0.042349636889994144
INFO:root:LOSS train' 0.042349636889994144, 2900
INFO:root:Epoch: 8 - LOSS train: 0.042349636889994144 LOSS val: 0.04181869700551033 - Elapsed time: 154.9311864376068 s
INFO:root:  batch 100 loss: 0.041760173141956326
INFO:root:LOSS train' 0.041760173141956326, 3025
INFO:root:  batch 200 loss: 0.04090022474527359
INFO:root:LOSS train' 0.04090022474527359, 3125
INFO:root:  batch 300 loss: 0.04121211815625429
INFO:root:LOSS train' 0.04121211815625429, 3225
INFO:root:Epoch: 9 - LOSS train: 0.04121211815625429 LOSS val: 0.03939646854996681 - Elapsed time: 154.6706075668335 s
INFO:root:  batch 100 loss: 0.040710543505847456
INFO:root:LOSS train' 0.040710543505847456, 3350
INFO:root:  batch 200 loss: 0.04036239694803953
INFO:root:LOSS train' 0.04036239694803953, 3450
INFO:root:  batch 300 loss: 0.04216856386512518
INFO:root:LOSS train' 0.04216856386512518, 3550
INFO:root:Epoch: 10 - LOSS train: 0.04216856386512518 LOSS val: 0.03639834746718407 - Elapsed time: 154.66233348846436 s
INFO:root:  batch 100 loss: 0.0381052976846695
INFO:root:LOSS train' 0.0381052976846695, 3675
INFO:root:  batch 200 loss: 0.03722889482975006
INFO:root:LOSS train' 0.03722889482975006, 3775
INFO:root:  batch 300 loss: 0.03555762857198715
INFO:root:LOSS train' 0.03555762857198715, 3875
INFO:root:Epoch: 11 - LOSS train: 0.03555762857198715 LOSS val: 0.03532743081450462 - Elapsed time: 154.80475068092346 s
INFO:root:  batch 100 loss: 0.03749764814972877
INFO:root:LOSS train' 0.03749764814972877, 4000
INFO:root:  batch 200 loss: 0.03503309557214379
INFO:root:LOSS train' 0.03503309557214379, 4100
INFO:root:  batch 300 loss: 0.05233260756358504
INFO:root:LOSS train' 0.05233260756358504, 4200
INFO:root:Epoch: 12 - LOSS train: 0.05233260756358504 LOSS val: 0.039982955902814865 - Elapsed time: 154.66134095191956 s
INFO:root:  batch 100 loss: 0.03724837217479944
INFO:root:LOSS train' 0.03724837217479944, 4325
INFO:root:  batch 200 loss: 0.03381770942360163
INFO:root:LOSS train' 0.03381770942360163, 4425
INFO:root:  batch 300 loss: 0.03779491761699319
INFO:root:LOSS train' 0.03779491761699319, 4525
INFO:root:Epoch: 13 - LOSS train: 0.03779491761699319 LOSS val: 0.035733841359615326 - Elapsed time: 154.94501948356628 s
INFO:root:  batch 100 loss: 0.0324755953066051
INFO:root:LOSS train' 0.0324755953066051, 4650
INFO:root:  batch 200 loss: 0.03223765047267079
INFO:root:LOSS train' 0.03223765047267079, 4750
INFO:root:  batch 300 loss: 0.03160212740302086
INFO:root:LOSS train' 0.03160212740302086, 4850
INFO:root:Epoch: 14 - LOSS train: 0.03160212740302086 LOSS val: 0.029819857329130173 - Elapsed time: 154.89796590805054 s
INFO:root:  batch 100 loss: 0.03268547730520368
INFO:root:LOSS train' 0.03268547730520368, 4975
INFO:root:  batch 200 loss: 0.03199344197288156
INFO:root:LOSS train' 0.03199344197288156, 5075
INFO:root:  batch 300 loss: 0.032842242568731306
INFO:root:LOSS train' 0.032842242568731306, 5175
INFO:root:Epoch: 15 - LOSS train: 0.032842242568731306 LOSS val: 0.03796229511499405 - Elapsed time: 155.05006790161133 s
INFO:root:  batch 100 loss: 0.033396279383450744
INFO:root:LOSS train' 0.033396279383450744, 5300
INFO:root:  batch 200 loss: 0.037559534143656495
INFO:root:LOSS train' 0.037559534143656495, 5400
INFO:root:  batch 300 loss: 0.030374879855662583
INFO:root:LOSS train' 0.030374879855662583, 5500
INFO:root:Epoch: 16 - LOSS train: 0.030374879855662583 LOSS val: 0.02873598411679268 - Elapsed time: 154.80335688591003 s
INFO:root:  batch 100 loss: 0.03259642386808991
INFO:root:LOSS train' 0.03259642386808991, 5625
INFO:root:  batch 200 loss: 0.029209797643125056
INFO:root:LOSS train' 0.029209797643125056, 5725
INFO:root:  batch 300 loss: 0.030360487904399634
INFO:root:LOSS train' 0.030360487904399634, 5825
INFO:root:Epoch: 17 - LOSS train: 0.030360487904399634 LOSS val: 0.027969354763627052 - Elapsed time: 154.973046541214 s
INFO:root:  batch 100 loss: 0.02925143264234066
INFO:root:LOSS train' 0.02925143264234066, 5950
INFO:root:  batch 200 loss: 0.02832943020388484
INFO:root:LOSS train' 0.02832943020388484, 6050
INFO:root:  batch 300 loss: 0.028513590656220913
INFO:root:LOSS train' 0.028513590656220913, 6150
INFO:root:Epoch: 18 - LOSS train: 0.028513590656220913 LOSS val: 0.027182430028915405 - Elapsed time: 154.96194314956665 s
INFO:root:  batch 100 loss: 0.026905018500983716
INFO:root:LOSS train' 0.026905018500983716, 6275
INFO:root:  batch 200 loss: 0.027423232942819595
INFO:root:LOSS train' 0.027423232942819595, 6375
INFO:root:  batch 300 loss: 0.030672295950353146
INFO:root:LOSS train' 0.030672295950353146, 6475
INFO:root:Epoch: 19 - LOSS train: 0.030672295950353146 LOSS val: 0.025352120399475098 - Elapsed time: 155.14107131958008 s
INFO:root:  batch 100 loss: 0.028826134502887724
INFO:root:LOSS train' 0.028826134502887724, 6600
INFO:root:  batch 200 loss: 0.026404808536171914
INFO:root:LOSS train' 0.026404808536171914, 6700
INFO:root:  batch 300 loss: 0.02587970092892647
INFO:root:LOSS train' 0.02587970092892647, 6800
INFO:root:Epoch: 20 - LOSS train: 0.02587970092892647 LOSS val: 0.026370016857981682 - Elapsed time: 154.97681736946106 s
INFO:root:  batch 100 loss: 0.025629108026623725
INFO:root:LOSS train' 0.025629108026623725, 6925
INFO:root:  batch 200 loss: 0.026912322994321586
INFO:root:LOSS train' 0.026912322994321586, 7025
INFO:root:  batch 300 loss: 0.026951553486287593
INFO:root:LOSS train' 0.026951553486287593, 7125
INFO:root:Epoch: 21 - LOSS train: 0.026951553486287593 LOSS val: 0.024218911305069923 - Elapsed time: 154.85539078712463 s
INFO:root:  batch 100 loss: 0.025130746103823185
INFO:root:LOSS train' 0.025130746103823185, 7250
INFO:root:  batch 200 loss: 0.025176568925380706
INFO:root:LOSS train' 0.025176568925380706, 7350
INFO:root:  batch 300 loss: 0.044639112073928115
INFO:root:LOSS train' 0.044639112073928115, 7450
INFO:root:Epoch: 22 - LOSS train: 0.044639112073928115 LOSS val: 0.04542500898241997 - Elapsed time: 154.68621850013733 s
INFO:root:  batch 100 loss: 0.03420348782092333
INFO:root:LOSS train' 0.03420348782092333, 7575
INFO:root:  batch 200 loss: 0.028095427751541138
INFO:root:LOSS train' 0.028095427751541138, 7675
INFO:root:  batch 300 loss: 0.025134406946599484
INFO:root:LOSS train' 0.025134406946599484, 7775
INFO:root:Epoch: 23 - LOSS train: 0.025134406946599484 LOSS val: 0.024213725700974464 - Elapsed time: 154.95472049713135 s
INFO:root:  batch 100 loss: 0.02588291687890887
INFO:root:LOSS train' 0.02588291687890887, 7900
INFO:root:  batch 200 loss: 0.02641119757667184
INFO:root:LOSS train' 0.02641119757667184, 8000
INFO:root:  batch 300 loss: 0.023972934186458586
INFO:root:LOSS train' 0.023972934186458586, 8100
INFO:root:Epoch: 24 - LOSS train: 0.023972934186458586 LOSS val: 0.02376118302345276 - Elapsed time: 155.07920932769775 s
INFO:root:  batch 100 loss: 0.025906797647476196
INFO:root:LOSS train' 0.025906797647476196, 8225
INFO:root:  batch 200 loss: 0.024139457475394012
INFO:root:LOSS train' 0.024139457475394012, 8325
INFO:root:  batch 300 loss: 0.023451325241476296
INFO:root:LOSS train' 0.023451325241476296, 8425
INFO:root:Epoch: 25 - LOSS train: 0.023451325241476296 LOSS val: 0.023089848458766937 - Elapsed time: 154.73906135559082 s
INFO:root:  batch 100 loss: 0.026263406276702882
INFO:root:LOSS train' 0.026263406276702882, 8550
INFO:root:  batch 200 loss: 0.023163117691874503
INFO:root:LOSS train' 0.023163117691874503, 8650
INFO:root:  batch 300 loss: 0.023011133056133986
INFO:root:LOSS train' 0.023011133056133986, 8750
INFO:root:Epoch: 26 - LOSS train: 0.023011133056133986 LOSS val: 0.022306766360998154 - Elapsed time: 154.9791498184204 s
INFO:root:  batch 100 loss: 0.03904368460178375
INFO:root:LOSS train' 0.03904368460178375, 8875
INFO:root:  batch 200 loss: 0.03039062861353159
INFO:root:LOSS train' 0.03039062861353159, 8975
INFO:root:  batch 300 loss: 0.024546571895480155
INFO:root:LOSS train' 0.024546571895480155, 9075
INFO:root:Epoch: 27 - LOSS train: 0.024546571895480155 LOSS val: 0.022803014144301414 - Elapsed time: 154.6142795085907 s
INFO:root:  batch 100 loss: 0.02435648787766695
INFO:root:LOSS train' 0.02435648787766695, 9200
INFO:root:  batch 200 loss: 0.026152829732745887
INFO:root:LOSS train' 0.026152829732745887, 9300
INFO:root:  batch 300 loss: 0.023492980282753706
INFO:root:LOSS train' 0.023492980282753706, 9400
INFO:root:Epoch: 28 - LOSS train: 0.023492980282753706 LOSS val: 0.02248642034828663 - Elapsed time: 154.90987539291382 s
INFO:root:  batch 100 loss: 0.022579381689429284
INFO:root:LOSS train' 0.022579381689429284, 9525
INFO:root:  batch 200 loss: 0.02219809515401721
INFO:root:LOSS train' 0.02219809515401721, 9625
INFO:root:  batch 300 loss: 0.021481145825237035
INFO:root:LOSS train' 0.021481145825237035, 9725
INFO:root:Epoch: 29 - LOSS train: 0.021481145825237035 LOSS val: 0.021085694432258606 - Elapsed time: 154.98412585258484 s
INFO:root:  batch 100 loss: 0.02286755423992872
INFO:root:LOSS train' 0.02286755423992872, 9850
INFO:root:  batch 200 loss: 0.021516930628567934
INFO:root:LOSS train' 0.021516930628567934, 9950
INFO:root:  batch 300 loss: 0.021090866606682537
INFO:root:LOSS train' 0.021090866606682537, 10050
INFO:root:Epoch: 30 - LOSS train: 0.021090866606682537 LOSS val: 0.02090620808303356 - Elapsed time: 154.57289457321167 s
INFO:root:  batch 100 loss: 0.020915841776877643
INFO:root:LOSS train' 0.020915841776877643, 10175
INFO:root:  batch 200 loss: 0.021507067680358885
INFO:root:LOSS train' 0.021507067680358885, 10275
INFO:root:  batch 300 loss: 0.021615781243890523
INFO:root:LOSS train' 0.021615781243890523, 10375
INFO:root:Epoch: 31 - LOSS train: 0.021615781243890523 LOSS val: 0.02056220918893814 - Elapsed time: 154.9380133152008 s
INFO:root:  batch 100 loss: 0.023428832553327082
INFO:root:LOSS train' 0.023428832553327082, 10500
INFO:root:  batch 200 loss: 0.043377694059163335
INFO:root:LOSS train' 0.043377694059163335, 10600
INFO:root:  batch 300 loss: 0.026524177119135857
INFO:root:LOSS train' 0.026524177119135857, 10700
INFO:root:Epoch: 32 - LOSS train: 0.026524177119135857 LOSS val: 0.022311493754386902 - Elapsed time: 154.76524806022644 s
INFO:root:  batch 100 loss: 0.022766567468643188
INFO:root:LOSS train' 0.022766567468643188, 10825
INFO:root:  batch 200 loss: 0.021477074231952428
INFO:root:LOSS train' 0.021477074231952428, 10925
INFO:root:  batch 300 loss: 0.020881344117224216
INFO:root:LOSS train' 0.020881344117224216, 11025
INFO:root:Epoch: 33 - LOSS train: 0.020881344117224216 LOSS val: 0.02063789777457714 - Elapsed time: 154.56737780570984 s
INFO:root:  batch 100 loss: 0.021454465631395577
INFO:root:LOSS train' 0.021454465631395577, 11150
INFO:root:  batch 200 loss: 0.02013481590896845
INFO:root:LOSS train' 0.02013481590896845, 11250
INFO:root:  batch 300 loss: 0.025417131651192904
INFO:root:LOSS train' 0.025417131651192904, 11350
INFO:root:Epoch: 34 - LOSS train: 0.025417131651192904 LOSS val: 0.025247205048799515 - Elapsed time: 154.77259063720703 s
INFO:root:  batch 100 loss: 0.02164981488138437
INFO:root:LOSS train' 0.02164981488138437, 11475
INFO:root:  batch 200 loss: 0.02024522306397557
INFO:root:LOSS train' 0.02024522306397557, 11575
INFO:root:  batch 300 loss: 0.02045145057141781
INFO:root:LOSS train' 0.02045145057141781, 11675
INFO:root:Epoch: 35 - LOSS train: 0.02045145057141781 LOSS val: 0.019997555762529373 - Elapsed time: 154.88955163955688 s
INFO:root:  batch 100 loss: 0.019334527160972358
INFO:root:LOSS train' 0.019334527160972358, 11800
INFO:root:  batch 200 loss: 0.02005152504891157
INFO:root:LOSS train' 0.02005152504891157, 11900
INFO:root:  batch 300 loss: 0.01974184947088361
INFO:root:LOSS train' 0.01974184947088361, 12000
INFO:root:Epoch: 36 - LOSS train: 0.01974184947088361 LOSS val: 0.020421741530299187 - Elapsed time: 154.7723264694214 s
INFO:root:  batch 100 loss: 0.019071178659796715
INFO:root:LOSS train' 0.019071178659796715, 12125
INFO:root:  batch 200 loss: 0.01872705599293113
INFO:root:LOSS train' 0.01872705599293113, 12225
INFO:root:  batch 300 loss: 0.019063341617584228
INFO:root:LOSS train' 0.019063341617584228, 12325
INFO:root:Epoch: 37 - LOSS train: 0.019063341617584228 LOSS val: 0.019142284989356995 - Elapsed time: 154.76833605766296 s
INFO:root:  batch 100 loss: 0.018695787973701954
INFO:root:LOSS train' 0.018695787973701954, 12450
INFO:root:  batch 200 loss: 0.018640578808262944
INFO:root:LOSS train' 0.018640578808262944, 12550
INFO:root:  batch 300 loss: 0.018852320201694965
INFO:root:LOSS train' 0.018852320201694965, 12650
INFO:root:Epoch: 38 - LOSS train: 0.018852320201694965 LOSS val: 0.01935681514441967 - Elapsed time: 154.62125539779663 s
INFO:root:  batch 100 loss: 0.01822184095159173
INFO:root:LOSS train' 0.01822184095159173, 12775
INFO:root:  batch 200 loss: 0.020990427546203137
INFO:root:LOSS train' 0.020990427546203137, 12875
INFO:root:  batch 300 loss: 0.020621062368154527
INFO:root:LOSS train' 0.020621062368154527, 12975
INFO:root:Epoch: 39 - LOSS train: 0.020621062368154527 LOSS val: 0.018350347876548767 - Elapsed time: 154.86893773078918 s
INFO:root:  batch 100 loss: 0.01854623164050281
INFO:root:LOSS train' 0.01854623164050281, 13100
INFO:root:  batch 200 loss: 0.018243473656475544
INFO:root:LOSS train' 0.018243473656475544, 13200
INFO:root:  batch 300 loss: 0.018849050067365168
INFO:root:LOSS train' 0.018849050067365168, 13300
INFO:root:Epoch: 40 - LOSS train: 0.018849050067365168 LOSS val: 0.01850193738937378 - Elapsed time: 154.7474639415741 s
INFO:root:  batch 100 loss: 0.017991007240489125
INFO:root:LOSS train' 0.017991007240489125, 13425
INFO:root:  batch 200 loss: 0.01909455979242921
INFO:root:LOSS train' 0.01909455979242921, 13525
INFO:root:  batch 300 loss: 0.01833559675142169
INFO:root:LOSS train' 0.01833559675142169, 13625
INFO:root:Epoch: 41 - LOSS train: 0.01833559675142169 LOSS val: 0.01735081896185875 - Elapsed time: 154.77002668380737 s
INFO:root:  batch 100 loss: 0.017666100664064287
INFO:root:LOSS train' 0.017666100664064287, 13750
INFO:root:  batch 200 loss: 0.018055762108415366
INFO:root:LOSS train' 0.018055762108415366, 13850
INFO:root:  batch 300 loss: 0.01748764522373676
INFO:root:LOSS train' 0.01748764522373676, 13950
INFO:root:Epoch: 42 - LOSS train: 0.01748764522373676 LOSS val: 0.01774006150662899 - Elapsed time: 154.85684418678284 s
INFO:root:  batch 100 loss: 0.0215560007840395
INFO:root:LOSS train' 0.0215560007840395, 14075
INFO:root:  batch 200 loss: 0.017273387312889098
INFO:root:LOSS train' 0.017273387312889098, 14175
INFO:root:  batch 300 loss: 0.017287604194134474
INFO:root:LOSS train' 0.017287604194134474, 14275
INFO:root:Epoch: 43 - LOSS train: 0.017287604194134474 LOSS val: 0.017569147050380707 - Elapsed time: 154.49502897262573 s
INFO:root:*************
INFO:root:             
INFO:root:Starting to test....
INFO:root:             
INFO:root:OneStep loss: 0.01756581850349903
INFO:root:Scalar loss: 0.023455951362848282
INFO:root:Vector loss: 0.014620755799114704
INFO:root:             
INFO:root:Done.

INFO:root:*************
INFO:root:             
INFO:root:model chosen: CR
INFO:root:multivector activation function?: 3
INFO:root:training trajectories: 2080
INFO:root:training epochs: 200
INFO:root:training batchsize: 16
INFO:root:learning rate: 0.0001
INFO:root:seed: 28996
INFO:root:patience: 15
INFO:root:training dataset path: datasets/trainingdataviscous/
INFO:root:test dataset path: datasets/testdataviscous/
INFO:root:             
INFO:root:*************
INFO:root:Using device: cuda
INFO:root:[[[1.6940998  1.5566934  1.3046039  1.0440726 ]
  [1.6066581  1.3995012  1.342347   1.233624  ]
  [1.4666691  1.3354036  1.3883016  1.2737162 ]
  [1.4122795  1.3854291  1.4587754  1.339578  ]]

 [[1.6459564  1.3450366  1.0299298  0.77708894]
  [1.6489182  1.5250436  1.3721011  1.2203181 ]
  [1.4844782  1.3996952  1.3643513  1.3251002 ]
  [1.3969231  1.3963239  1.4048748  1.4067723 ]]]
INFO:root:****
INFO:root:[[[1.6940998  1.5566934  1.3046039  1.0440726 ]
  [1.6066581  1.3995012  1.342347   1.233624  ]
  [1.4666691  1.3354036  1.3883016  1.2737162 ]
  [1.4122795  1.3854291  1.4587754  1.339578  ]]

 [[1.6459564  1.3450366  1.0299298  0.77708894]
  [1.6489182  1.5250436  1.3721011  1.2203181 ]
  [1.4844782  1.3996952  1.3643513  1.3251002 ]
  [1.3969231  1.3963239  1.4048748  1.4067723 ]]]
INFO:root:Train input shape: torch.Size([2080, 2, 128, 128, 3])
INFO:root:Train labels shape: torch.Size([2080, 1, 128, 128, 3])
INFO:root:                   
INFO:root:Val input shape: torch.Size([4680, 2, 128, 128, 3])
INFO:root:Val labels shape: torch.Size([4680, 1, 128, 128, 3])
INFO:root:*************
INFO:root:             
INFO:root:Starting to train....
INFO:root:  batch 100 loss: 0.217164186835289
INFO:root:LOSS train' 0.217164186835289, 100
INFO:root:Epoch: 0 - LOSS train: 0.217164186835289 LOSS val: 0.14453276991844177 - Elapsed time: 96.31217956542969 s
INFO:root:  batch 100 loss: 0.13903224661946298
INFO:root:LOSS train' 0.13903224661946298, 230
INFO:root:Epoch: 1 - LOSS train: 0.13903224661946298 LOSS val: 0.11757970601320267 - Elapsed time: 95.55145812034607 s
INFO:root:  batch 100 loss: 0.11937134183943271
INFO:root:LOSS train' 0.11937134183943271, 360
INFO:root:Epoch: 2 - LOSS train: 0.11937134183943271 LOSS val: 0.10886576026678085 - Elapsed time: 95.67410230636597 s
INFO:root:  batch 100 loss: 0.10806830935180187
INFO:root:LOSS train' 0.10806830935180187, 490
INFO:root:Epoch: 3 - LOSS train: 0.10806830935180187 LOSS val: 0.09760952740907669 - Elapsed time: 95.5928168296814 s
INFO:root:  batch 100 loss: 0.0979955031722784
INFO:root:LOSS train' 0.0979955031722784, 620
INFO:root:Epoch: 4 - LOSS train: 0.0979955031722784 LOSS val: 0.08777394145727158 - Elapsed time: 95.61660051345825 s
INFO:root:  batch 100 loss: 0.08844786919653416
INFO:root:LOSS train' 0.08844786919653416, 750
INFO:root:Epoch: 5 - LOSS train: 0.08844786919653416 LOSS val: 0.07874803245067596 - Elapsed time: 95.99851059913635 s
INFO:root:  batch 100 loss: 0.08559086404740811
INFO:root:LOSS train' 0.08559086404740811, 880
INFO:root:Epoch: 6 - LOSS train: 0.08559086404740811 LOSS val: 0.07499179989099503 - Elapsed time: 95.77921175956726 s
INFO:root:  batch 100 loss: 0.07499132499098778
INFO:root:LOSS train' 0.07499132499098778, 1010
INFO:root:Epoch: 7 - LOSS train: 0.07499132499098778 LOSS val: 0.06696362793445587 - Elapsed time: 95.65415072441101 s
INFO:root:  batch 100 loss: 0.07360840756446123
INFO:root:LOSS train' 0.07360840756446123, 1140
INFO:root:Epoch: 8 - LOSS train: 0.07360840756446123 LOSS val: 0.06460703909397125 - Elapsed time: 95.7653398513794 s
INFO:root:  batch 100 loss: 0.07016778342425824
INFO:root:LOSS train' 0.07016778342425824, 1270
INFO:root:Epoch: 9 - LOSS train: 0.07016778342425824 LOSS val: 0.06598331034183502 - Elapsed time: 95.7445170879364 s
INFO:root:  batch 100 loss: 0.0646918473765254
INFO:root:LOSS train' 0.0646918473765254, 1400
INFO:root:Epoch: 10 - LOSS train: 0.0646918473765254 LOSS val: 0.05760430917143822 - Elapsed time: 95.75043773651123 s
INFO:root:  batch 100 loss: 0.05854440324008465
INFO:root:LOSS train' 0.05854440324008465, 1530
INFO:root:Epoch: 11 - LOSS train: 0.05854440324008465 LOSS val: 0.070245660841465 - Elapsed time: 95.68005681037903 s
INFO:root:  batch 100 loss: 0.05794848583638668
INFO:root:LOSS train' 0.05794848583638668, 1660
INFO:root:Epoch: 12 - LOSS train: 0.05794848583638668 LOSS val: 0.05401598662137985 - Elapsed time: 95.71347570419312 s
INFO:root:  batch 100 loss: 0.055159840397536755
INFO:root:LOSS train' 0.055159840397536755, 1790
INFO:root:Epoch: 13 - LOSS train: 0.055159840397536755 LOSS val: 0.055039599537849426 - Elapsed time: 95.74968338012695 s
INFO:root:  batch 100 loss: 0.05268260039389133
INFO:root:LOSS train' 0.05268260039389133, 1920
INFO:root:Epoch: 14 - LOSS train: 0.05268260039389133 LOSS val: 0.054896265268325806 - Elapsed time: 95.77637982368469 s
INFO:root:  batch 100 loss: 0.05619010042399168
INFO:root:LOSS train' 0.05619010042399168, 2050
INFO:root:Epoch: 15 - LOSS train: 0.05619010042399168 LOSS val: 0.04810698702931404 - Elapsed time: 95.70634746551514 s
INFO:root:  batch 100 loss: 0.04885478619486094
INFO:root:LOSS train' 0.04885478619486094, 2180
INFO:root:Epoch: 16 - LOSS train: 0.04885478619486094 LOSS val: 0.0458429753780365 - Elapsed time: 95.68351149559021 s
INFO:root:  batch 100 loss: 0.04683086819946766
INFO:root:LOSS train' 0.04683086819946766, 2310
INFO:root:Epoch: 17 - LOSS train: 0.04683086819946766 LOSS val: 0.04449409991502762 - Elapsed time: 95.80771493911743 s
INFO:root:  batch 100 loss: 0.045513359121978285
INFO:root:LOSS train' 0.045513359121978285, 2440
INFO:root:Epoch: 18 - LOSS train: 0.045513359121978285 LOSS val: 0.042635414749383926 - Elapsed time: 95.78915929794312 s
INFO:root:  batch 100 loss: 0.04515950355678797
INFO:root:LOSS train' 0.04515950355678797, 2570
INFO:root:Epoch: 19 - LOSS train: 0.04515950355678797 LOSS val: 0.04610874131321907 - Elapsed time: 95.68351554870605 s
INFO:root:  batch 100 loss: 0.04246848288923502
INFO:root:LOSS train' 0.04246848288923502, 2700
INFO:root:Epoch: 20 - LOSS train: 0.04246848288923502 LOSS val: 0.04142509400844574 - Elapsed time: 95.78446841239929 s
INFO:root:  batch 100 loss: 0.04214564248919487
INFO:root:LOSS train' 0.04214564248919487, 2830
INFO:root:Epoch: 21 - LOSS train: 0.04214564248919487 LOSS val: 0.06749193370342255 - Elapsed time: 95.68513178825378 s
INFO:root:  batch 100 loss: 0.04360291864722967
INFO:root:LOSS train' 0.04360291864722967, 2960
INFO:root:Epoch: 22 - LOSS train: 0.04360291864722967 LOSS val: 0.040566135197877884 - Elapsed time: 95.60423851013184 s
INFO:root:  batch 100 loss: 0.03999589905142784
INFO:root:LOSS train' 0.03999589905142784, 3090
INFO:root:Epoch: 23 - LOSS train: 0.03999589905142784 LOSS val: 0.040870301425457 - Elapsed time: 95.72309708595276 s
INFO:root:  batch 100 loss: 0.03872610971331596
INFO:root:LOSS train' 0.03872610971331596, 3220
INFO:root:Epoch: 24 - LOSS train: 0.03872610971331596 LOSS val: 0.03777491673827171 - Elapsed time: 95.78700709342957 s
INFO:root:  batch 100 loss: 0.03787184774875641
INFO:root:LOSS train' 0.03787184774875641, 3350
INFO:root:Epoch: 25 - LOSS train: 0.03787184774875641 LOSS val: 0.04864585027098656 - Elapsed time: 95.8216290473938 s
INFO:root:  batch 100 loss: 0.03773843050003052
INFO:root:LOSS train' 0.03773843050003052, 3480
INFO:root:Epoch: 26 - LOSS train: 0.03773843050003052 LOSS val: 0.035841505974531174 - Elapsed time: 95.6956536769867 s
INFO:root:  batch 100 loss: 0.046928454078733924
INFO:root:LOSS train' 0.046928454078733924, 3610
INFO:root:Epoch: 27 - LOSS train: 0.046928454078733924 LOSS val: 0.03963256627321243 - Elapsed time: 95.66997742652893 s
INFO:root:  batch 100 loss: 0.036480130292475224
INFO:root:LOSS train' 0.036480130292475224, 3740
INFO:root:Epoch: 28 - LOSS train: 0.036480130292475224 LOSS val: 0.03440159559249878 - Elapsed time: 95.79598212242126 s
INFO:root:  batch 100 loss: 0.03484398020431399
INFO:root:LOSS train' 0.03484398020431399, 3870
INFO:root:Epoch: 29 - LOSS train: 0.03484398020431399 LOSS val: 0.03517964854836464 - Elapsed time: 95.84712767601013 s
INFO:root:  batch 100 loss: 0.03582135273143649
INFO:root:LOSS train' 0.03582135273143649, 4000
INFO:root:Epoch: 30 - LOSS train: 0.03582135273143649 LOSS val: 0.03605107218027115 - Elapsed time: 95.72113633155823 s
INFO:root:  batch 100 loss: 0.03295915147289634
INFO:root:LOSS train' 0.03295915147289634, 4130
INFO:root:Epoch: 31 - LOSS train: 0.03295915147289634 LOSS val: 0.032137997448444366 - Elapsed time: 95.71384835243225 s
INFO:root:  batch 100 loss: 0.03815071489661932
INFO:root:LOSS train' 0.03815071489661932, 4260
INFO:root:Epoch: 32 - LOSS train: 0.03815071489661932 LOSS val: 0.03271092101931572 - Elapsed time: 95.7506308555603 s
INFO:root:  batch 100 loss: 0.03280835222452879
INFO:root:LOSS train' 0.03280835222452879, 4390
INFO:root:Epoch: 33 - LOSS train: 0.03280835222452879 LOSS val: 0.032658446580171585 - Elapsed time: 95.72621178627014 s
INFO:root:  batch 100 loss: 0.043610763493925335
INFO:root:LOSS train' 0.043610763493925335, 4520
INFO:root:Epoch: 34 - LOSS train: 0.043610763493925335 LOSS val: 0.031721509993076324 - Elapsed time: 95.98760557174683 s
INFO:root:  batch 100 loss: 0.03313516728579998
INFO:root:LOSS train' 0.03313516728579998, 4650
INFO:root:Epoch: 35 - LOSS train: 0.03313516728579998 LOSS val: 0.032884012907743454 - Elapsed time: 95.91614365577698 s
INFO:root:  batch 100 loss: 0.0326092647574842
INFO:root:LOSS train' 0.0326092647574842, 4780
INFO:root:Epoch: 36 - LOSS train: 0.0326092647574842 LOSS val: 0.03103100135922432 - Elapsed time: 95.71508693695068 s
INFO:root:  batch 100 loss: 0.031059842705726624
INFO:root:LOSS train' 0.031059842705726624, 4910
INFO:root:Epoch: 37 - LOSS train: 0.031059842705726624 LOSS val: 0.030003271996974945 - Elapsed time: 95.76901912689209 s
INFO:root:  batch 100 loss: 0.033250358514487745
INFO:root:LOSS train' 0.033250358514487745, 5040
INFO:root:Epoch: 38 - LOSS train: 0.033250358514487745 LOSS val: 0.030009688809514046 - Elapsed time: 95.7600347995758 s
INFO:root:*************
INFO:root:             
INFO:root:Starting to test....
INFO:root:             
INFO:root:OneStep loss: 0.030300581827759743
INFO:root:Scalar loss: 0.039295341819524765
INFO:root:Vector loss: 0.025803199037909508
INFO:root:             
INFO:root:Done.

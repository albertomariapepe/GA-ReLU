INFO:root:*************
INFO:root:             
INFO:root:model chosen: CR
INFO:root:multivector activation function?: 3
INFO:root:training trajectories: 5200
INFO:root:training epochs: 200
INFO:root:training batchsize: 16
INFO:root:learning rate: 0.0001
INFO:root:seed: 666
INFO:root:patience: 15
INFO:root:training dataset path: datasets/trainingdataviscous/
INFO:root:test dataset path: datasets/testdataviscous/
INFO:root:             
INFO:root:*************
INFO:root:Using device: cuda
INFO:root:[[[1.6940998  1.5566934  1.3046039  1.0440726 ]
  [1.6066581  1.3995012  1.342347   1.233624  ]
  [1.4666691  1.3354036  1.3883016  1.2737162 ]
  [1.4122795  1.3854291  1.4587754  1.339578  ]]

 [[1.6459564  1.3450366  1.0299298  0.77708894]
  [1.6489182  1.5250436  1.3721011  1.2203181 ]
  [1.4844782  1.3996952  1.3643513  1.3251002 ]
  [1.3969231  1.3963239  1.4048748  1.4067723 ]]]
INFO:root:****
INFO:root:[[[1.6940998  1.5566934  1.3046039  1.0440726 ]
  [1.6066581  1.3995012  1.342347   1.233624  ]
  [1.4666691  1.3354036  1.3883016  1.2737162 ]
  [1.4122795  1.3854291  1.4587754  1.339578  ]]

 [[1.6459564  1.3450366  1.0299298  0.77708894]
  [1.6489182  1.5250436  1.3721011  1.2203181 ]
  [1.4844782  1.3996952  1.3643513  1.3251002 ]
  [1.3969231  1.3963239  1.4048748  1.4067723 ]]]
INFO:root:Train input shape: torch.Size([5200, 2, 128, 128, 3])
INFO:root:Train labels shape: torch.Size([5200, 1, 128, 128, 3])
INFO:root:                   
INFO:root:Val input shape: torch.Size([4680, 2, 128, 128, 3])
INFO:root:Val labels shape: torch.Size([4680, 1, 128, 128, 3])
INFO:root:*************
INFO:root:             
INFO:root:Starting to train....
INFO:root:  batch 100 loss: 0.21619653820991516
INFO:root:LOSS train' 0.21619653820991516, 100
INFO:root:  batch 200 loss: 0.15114523723721504
INFO:root:LOSS train' 0.15114523723721504, 200
INFO:root:  batch 300 loss: 0.13172835856676102
INFO:root:LOSS train' 0.13172835856676102, 300
INFO:root:Epoch: 0 - LOSS train: 0.13172835856676102 LOSS val: 0.12481388449668884 - Elapsed time: 156.0655059814453 s
INFO:root:  batch 100 loss: 0.11370531134307385
INFO:root:LOSS train' 0.11370531134307385, 425
INFO:root:  batch 200 loss: 0.10933161295950412
INFO:root:LOSS train' 0.10933161295950412, 525
INFO:root:  batch 300 loss: 0.09699123695492745
INFO:root:LOSS train' 0.09699123695492745, 625
INFO:root:Epoch: 1 - LOSS train: 0.09699123695492745 LOSS val: 0.10088497400283813 - Elapsed time: 154.69742965698242 s
INFO:root:  batch 100 loss: 0.08790447607636452
INFO:root:LOSS train' 0.08790447607636452, 750
INFO:root:  batch 200 loss: 0.08353261925280094
INFO:root:LOSS train' 0.08353261925280094, 850
INFO:root:  batch 300 loss: 0.0793320033699274
INFO:root:LOSS train' 0.0793320033699274, 950
INFO:root:Epoch: 2 - LOSS train: 0.0793320033699274 LOSS val: 0.06836790591478348 - Elapsed time: 154.86616158485413 s
INFO:root:  batch 100 loss: 0.07115670014172792
INFO:root:LOSS train' 0.07115670014172792, 1075
INFO:root:  batch 200 loss: 0.07184463486075401
INFO:root:LOSS train' 0.07184463486075401, 1175
INFO:root:  batch 300 loss: 0.06458464406430721
INFO:root:LOSS train' 0.06458464406430721, 1275
INFO:root:Epoch: 3 - LOSS train: 0.06458464406430721 LOSS val: 0.06405806541442871 - Elapsed time: 154.91156792640686 s
INFO:root:  batch 100 loss: 0.0658834820613265
INFO:root:LOSS train' 0.0658834820613265, 1400
INFO:root:  batch 200 loss: 0.061439663134515286
INFO:root:LOSS train' 0.061439663134515286, 1500
INFO:root:  batch 300 loss: 0.05781197238713503
INFO:root:LOSS train' 0.05781197238713503, 1600
INFO:root:Epoch: 4 - LOSS train: 0.05781197238713503 LOSS val: 0.05915023386478424 - Elapsed time: 154.84828805923462 s
INFO:root:  batch 100 loss: 0.05800562959164381
INFO:root:LOSS train' 0.05800562959164381, 1725
INFO:root:  batch 200 loss: 0.05333404697477818
INFO:root:LOSS train' 0.05333404697477818, 1825
INFO:root:  batch 300 loss: 0.05610936794430017
INFO:root:LOSS train' 0.05610936794430017, 1925
INFO:root:Epoch: 5 - LOSS train: 0.05610936794430017 LOSS val: 0.07573658227920532 - Elapsed time: 154.84642887115479 s
INFO:root:  batch 100 loss: 0.0531325488165021
INFO:root:LOSS train' 0.0531325488165021, 2050
INFO:root:  batch 200 loss: 0.049473039917647836
INFO:root:LOSS train' 0.049473039917647836, 2150
INFO:root:  batch 300 loss: 0.05033476997166872
INFO:root:LOSS train' 0.05033476997166872, 2250
INFO:root:Epoch: 6 - LOSS train: 0.05033476997166872 LOSS val: 0.04636022448539734 - Elapsed time: 155.0630865097046 s
INFO:root:  batch 100 loss: 0.04562963616102934
INFO:root:LOSS train' 0.04562963616102934, 2375
INFO:root:  batch 200 loss: 0.04783125296235084
INFO:root:LOSS train' 0.04783125296235084, 2475
INFO:root:  batch 300 loss: 0.044222782589495184
INFO:root:LOSS train' 0.044222782589495184, 2575
INFO:root:Epoch: 7 - LOSS train: 0.044222782589495184 LOSS val: 0.045489490032196045 - Elapsed time: 155.29658341407776 s
INFO:root:  batch 100 loss: 0.04499234113842249
INFO:root:LOSS train' 0.04499234113842249, 2700
INFO:root:  batch 200 loss: 0.043412575274705885
INFO:root:LOSS train' 0.043412575274705885, 2800
INFO:root:  batch 300 loss: 0.04295125689357519
INFO:root:LOSS train' 0.04295125689357519, 2900
INFO:root:Epoch: 8 - LOSS train: 0.04295125689357519 LOSS val: 0.04247526079416275 - Elapsed time: 154.89196395874023 s
INFO:root:  batch 100 loss: 0.04039269052445889
INFO:root:LOSS train' 0.04039269052445889, 3025
INFO:root:  batch 200 loss: 0.04035428736358881
INFO:root:LOSS train' 0.04035428736358881, 3125
INFO:root:  batch 300 loss: 0.0398043542727828
INFO:root:LOSS train' 0.0398043542727828, 3225
INFO:root:Epoch: 9 - LOSS train: 0.0398043542727828 LOSS val: 0.038009271025657654 - Elapsed time: 154.888085603714 s
INFO:root:  batch 100 loss: 0.05411222562193871
INFO:root:LOSS train' 0.05411222562193871, 3350
INFO:root:  batch 200 loss: 0.04107188433408737
INFO:root:LOSS train' 0.04107188433408737, 3450
INFO:root:  batch 300 loss: 0.04314247574657202
INFO:root:LOSS train' 0.04314247574657202, 3550
INFO:root:Epoch: 10 - LOSS train: 0.04314247574657202 LOSS val: 0.03912239149212837 - Elapsed time: 154.8989086151123 s
INFO:root:  batch 100 loss: 0.03648919582366943
INFO:root:LOSS train' 0.03648919582366943, 3675
INFO:root:  batch 200 loss: 0.036615734770894054
INFO:root:LOSS train' 0.036615734770894054, 3775
INFO:root:  batch 300 loss: 0.035011654645204546
INFO:root:LOSS train' 0.035011654645204546, 3875
INFO:root:Epoch: 11 - LOSS train: 0.035011654645204546 LOSS val: 0.033432669937610626 - Elapsed time: 154.8570008277893 s
INFO:root:  batch 100 loss: 0.035252042897045616
INFO:root:LOSS train' 0.035252042897045616, 4000
INFO:root:  batch 200 loss: 0.03982986556366086
INFO:root:LOSS train' 0.03982986556366086, 4100
INFO:root:  batch 300 loss: 0.0353831042163074
INFO:root:LOSS train' 0.0353831042163074, 4200
INFO:root:Epoch: 12 - LOSS train: 0.0353831042163074 LOSS val: 0.033582549542188644 - Elapsed time: 155.10329222679138 s
INFO:root:  batch 100 loss: 0.03484319683164358
INFO:root:LOSS train' 0.03484319683164358, 4325
INFO:root:  batch 200 loss: 0.03346647258847952
INFO:root:LOSS train' 0.03346647258847952, 4425
INFO:root:  batch 300 loss: 0.034304149616509676
INFO:root:LOSS train' 0.034304149616509676, 4525
INFO:root:Epoch: 13 - LOSS train: 0.034304149616509676 LOSS val: 0.03207075968384743 - Elapsed time: 154.75868368148804 s
INFO:root:  batch 100 loss: 0.03181101081892848
INFO:root:LOSS train' 0.03181101081892848, 4650
INFO:root:  batch 200 loss: 0.03302900085225701
INFO:root:LOSS train' 0.03302900085225701, 4750
INFO:root:  batch 300 loss: 0.031188446469604968
INFO:root:LOSS train' 0.031188446469604968, 4850
INFO:root:Epoch: 14 - LOSS train: 0.031188446469604968 LOSS val: 0.03414621949195862 - Elapsed time: 154.77796864509583 s
INFO:root:  batch 100 loss: 0.06476454755291343
INFO:root:LOSS train' 0.06476454755291343, 4975
INFO:root:  batch 200 loss: 0.03985193260014057
INFO:root:LOSS train' 0.03985193260014057, 5075
INFO:root:  batch 300 loss: 0.03342387896031141
INFO:root:LOSS train' 0.03342387896031141, 5175
INFO:root:Epoch: 15 - LOSS train: 0.03342387896031141 LOSS val: 0.032499995082616806 - Elapsed time: 154.51514768600464 s
INFO:root:  batch 100 loss: 0.03155718652531505
INFO:root:LOSS train' 0.03155718652531505, 5300
INFO:root:  batch 200 loss: 0.03160717356950045
INFO:root:LOSS train' 0.03160717356950045, 5400
INFO:root:  batch 300 loss: 0.030118897166103123
INFO:root:LOSS train' 0.030118897166103123, 5500
INFO:root:Epoch: 16 - LOSS train: 0.030118897166103123 LOSS val: 0.033708106726408005 - Elapsed time: 154.73081851005554 s
INFO:root:  batch 100 loss: 0.03117247110232711
INFO:root:LOSS train' 0.03117247110232711, 5625
INFO:root:  batch 200 loss: 0.029075797330588102
INFO:root:LOSS train' 0.029075797330588102, 5725
INFO:root:  batch 300 loss: 0.041348080690950154
INFO:root:LOSS train' 0.041348080690950154, 5825
INFO:root:Epoch: 17 - LOSS train: 0.041348080690950154 LOSS val: 0.029263481497764587 - Elapsed time: 154.93084478378296 s
INFO:root:  batch 100 loss: 0.03117841115221381
INFO:root:LOSS train' 0.03117841115221381, 5950
INFO:root:  batch 200 loss: 0.02889966020360589
INFO:root:LOSS train' 0.02889966020360589, 6050
INFO:root:  batch 300 loss: 0.02892649656161666
INFO:root:LOSS train' 0.02892649656161666, 6150
INFO:root:Epoch: 18 - LOSS train: 0.02892649656161666 LOSS val: 0.030123334378004074 - Elapsed time: 154.98052144050598 s
INFO:root:  batch 100 loss: 0.027884107455611228
INFO:root:LOSS train' 0.027884107455611228, 6275
INFO:root:  batch 200 loss: 0.028787324130535127
INFO:root:LOSS train' 0.028787324130535127, 6375
INFO:root:  batch 300 loss: 0.02988127974793315
INFO:root:LOSS train' 0.02988127974793315, 6475
INFO:root:Epoch: 19 - LOSS train: 0.02988127974793315 LOSS val: 0.026979880407452583 - Elapsed time: 154.88226294517517 s
INFO:root:  batch 100 loss: 0.031204582005739213
INFO:root:LOSS train' 0.031204582005739213, 6600
INFO:root:  batch 200 loss: 0.02640215082094073
INFO:root:LOSS train' 0.02640215082094073, 6700
INFO:root:  batch 300 loss: 0.02613747453317046
INFO:root:LOSS train' 0.02613747453317046, 6800
INFO:root:Epoch: 20 - LOSS train: 0.02613747453317046 LOSS val: 0.02696371264755726 - Elapsed time: 155.12199521064758 s
INFO:root:  batch 100 loss: 0.02985875612124801
INFO:root:LOSS train' 0.02985875612124801, 6925
INFO:root:  batch 200 loss: 0.025876458995044233
INFO:root:LOSS train' 0.025876458995044233, 7025
INFO:root:  batch 300 loss: 0.026270655319094657
INFO:root:LOSS train' 0.026270655319094657, 7125
INFO:root:Epoch: 21 - LOSS train: 0.026270655319094657 LOSS val: 0.024241970852017403 - Elapsed time: 154.80191588401794 s
INFO:root:  batch 100 loss: 0.025219884440302848
INFO:root:LOSS train' 0.025219884440302848, 7250
INFO:root:  batch 200 loss: 0.02550528258085251
INFO:root:LOSS train' 0.02550528258085251, 7350
INFO:root:  batch 300 loss: 0.03653373278677464
INFO:root:LOSS train' 0.03653373278677464, 7450
INFO:root:Epoch: 22 - LOSS train: 0.03653373278677464 LOSS val: 0.02831183932721615 - Elapsed time: 154.77593231201172 s
INFO:root:  batch 100 loss: 0.025991368629038333
INFO:root:LOSS train' 0.025991368629038333, 7575
INFO:root:  batch 200 loss: 0.024830660223960875
INFO:root:LOSS train' 0.024830660223960875, 7675
INFO:root:  batch 300 loss: 0.0240310113504529
INFO:root:LOSS train' 0.0240310113504529, 7775
INFO:root:Epoch: 23 - LOSS train: 0.0240310113504529 LOSS val: 0.023032354190945625 - Elapsed time: 154.88265991210938 s
INFO:root:  batch 100 loss: 0.024399512223899366
INFO:root:LOSS train' 0.024399512223899366, 7900
INFO:root:  batch 200 loss: 0.023588608261197807
INFO:root:LOSS train' 0.023588608261197807, 8000
INFO:root:  batch 300 loss: 0.026145654283463955
INFO:root:LOSS train' 0.026145654283463955, 8100
INFO:root:Epoch: 24 - LOSS train: 0.026145654283463955 LOSS val: 0.02295256033539772 - Elapsed time: 155.1080026626587 s
INFO:root:  batch 100 loss: 0.02432846860960126
INFO:root:LOSS train' 0.02432846860960126, 8225
INFO:root:  batch 200 loss: 0.023432376757264138
INFO:root:LOSS train' 0.023432376757264138, 8325
INFO:root:  batch 300 loss: 0.024449256509542466
INFO:root:LOSS train' 0.024449256509542466, 8425
INFO:root:Epoch: 25 - LOSS train: 0.024449256509542466 LOSS val: 0.023242413997650146 - Elapsed time: 154.81327486038208 s
INFO:root:  batch 100 loss: 0.023120482303202152
INFO:root:LOSS train' 0.023120482303202152, 8550
INFO:root:  batch 200 loss: 0.026260094568133354
INFO:root:LOSS train' 0.026260094568133354, 8650
INFO:root:  batch 300 loss: 0.02270909333601594
INFO:root:LOSS train' 0.02270909333601594, 8750
INFO:root:Epoch: 26 - LOSS train: 0.02270909333601594 LOSS val: 0.022394606843590736 - Elapsed time: 154.88638067245483 s
INFO:root:  batch 100 loss: 0.023758716564625502
INFO:root:LOSS train' 0.023758716564625502, 8875
INFO:root:  batch 200 loss: 0.02281091406941414
INFO:root:LOSS train' 0.02281091406941414, 8975
INFO:root:  batch 300 loss: 0.022408162392675877
INFO:root:LOSS train' 0.022408162392675877, 9075
INFO:root:Epoch: 27 - LOSS train: 0.022408162392675877 LOSS val: 0.021857207641005516 - Elapsed time: 154.8331949710846 s
INFO:root:  batch 100 loss: 0.02202076483517885
INFO:root:LOSS train' 0.02202076483517885, 9200
INFO:root:  batch 200 loss: 0.02331779129803181
INFO:root:LOSS train' 0.02331779129803181, 9300
INFO:root:  batch 300 loss: 0.023134825453162193
INFO:root:LOSS train' 0.023134825453162193, 9400
INFO:root:Epoch: 28 - LOSS train: 0.023134825453162193 LOSS val: 0.021617917343974113 - Elapsed time: 154.8372609615326 s
INFO:root:  batch 100 loss: 0.022010122518986465
INFO:root:LOSS train' 0.022010122518986465, 9525
INFO:root:  batch 200 loss: 0.023224003985524176
INFO:root:LOSS train' 0.023224003985524176, 9625
INFO:root:  batch 300 loss: 0.02767292745411396
INFO:root:LOSS train' 0.02767292745411396, 9725
INFO:root:Epoch: 29 - LOSS train: 0.02767292745411396 LOSS val: 0.02170279249548912 - Elapsed time: 154.80152654647827 s
INFO:root:  batch 100 loss: 0.0221234498731792
INFO:root:LOSS train' 0.0221234498731792, 9850
INFO:root:  batch 200 loss: 0.030729196835309266
INFO:root:LOSS train' 0.030729196835309266, 9950
INFO:root:  batch 300 loss: 0.025190134793519975
INFO:root:LOSS train' 0.025190134793519975, 10050
INFO:root:Epoch: 30 - LOSS train: 0.025190134793519975 LOSS val: 0.0218791663646698 - Elapsed time: 154.73000407218933 s
INFO:root:  batch 100 loss: 0.021384659577161073
INFO:root:LOSS train' 0.021384659577161073, 10175
INFO:root:  batch 200 loss: 0.021313036400824784
INFO:root:LOSS train' 0.021313036400824784, 10275
INFO:root:  batch 300 loss: 0.02126921307295561
INFO:root:LOSS train' 0.02126921307295561, 10375
INFO:root:Epoch: 31 - LOSS train: 0.02126921307295561 LOSS val: 0.0212099589407444 - Elapsed time: 154.94995951652527 s
INFO:root:  batch 100 loss: 0.02060967369005084
INFO:root:LOSS train' 0.02060967369005084, 10500
INFO:root:  batch 200 loss: 0.020453975051641465
INFO:root:LOSS train' 0.020453975051641465, 10600
INFO:root:  batch 300 loss: 0.01975786654278636
INFO:root:LOSS train' 0.01975786654278636, 10700
INFO:root:Epoch: 32 - LOSS train: 0.01975786654278636 LOSS val: 0.021078230813145638 - Elapsed time: 155.0097897052765 s
INFO:root:  batch 100 loss: 0.02068212166428566
INFO:root:LOSS train' 0.02068212166428566, 10825
INFO:root:  batch 200 loss: 0.020061699729412793
INFO:root:LOSS train' 0.020061699729412793, 10925
INFO:root:  batch 300 loss: 0.01983200551941991
INFO:root:LOSS train' 0.01983200551941991, 11025
INFO:root:Epoch: 33 - LOSS train: 0.01983200551941991 LOSS val: 0.01972678303718567 - Elapsed time: 155.01355624198914 s
INFO:root:  batch 100 loss: 0.0210255797021091
INFO:root:LOSS train' 0.0210255797021091, 11150
INFO:root:  batch 200 loss: 0.01947941118851304
INFO:root:LOSS train' 0.01947941118851304, 11250
INFO:root:  batch 300 loss: 0.019960047621279956
INFO:root:LOSS train' 0.019960047621279956, 11350
INFO:root:Epoch: 34 - LOSS train: 0.019960047621279956 LOSS val: 0.01893213391304016 - Elapsed time: 154.82502508163452 s
INFO:root:  batch 100 loss: 0.019547915551811457
INFO:root:LOSS train' 0.019547915551811457, 11475
INFO:root:  batch 200 loss: 0.02162057276815176
INFO:root:LOSS train' 0.02162057276815176, 11575
INFO:root:  batch 300 loss: 0.019717216417193414
INFO:root:LOSS train' 0.019717216417193414, 11675
INFO:root:Epoch: 35 - LOSS train: 0.019717216417193414 LOSS val: 0.018689310178160667 - Elapsed time: 154.67278122901917 s
INFO:root:  batch 100 loss: 0.018620511097833515
INFO:root:LOSS train' 0.018620511097833515, 11800
INFO:root:  batch 200 loss: 0.01896549515426159
INFO:root:LOSS train' 0.01896549515426159, 11900
INFO:root:  batch 300 loss: 0.01976806053891778
INFO:root:LOSS train' 0.01976806053891778, 12000
INFO:root:Epoch: 36 - LOSS train: 0.01976806053891778 LOSS val: 0.019390789791941643 - Elapsed time: 154.7341878414154 s
INFO:root:  batch 100 loss: 0.01885068541392684
INFO:root:LOSS train' 0.01885068541392684, 12125
INFO:root:  batch 200 loss: 0.018268178133293986
INFO:root:LOSS train' 0.018268178133293986, 12225
INFO:root:  batch 300 loss: 0.018480913154780863
INFO:root:LOSS train' 0.018480913154780863, 12325
INFO:root:Epoch: 37 - LOSS train: 0.018480913154780863 LOSS val: 0.018089307472109795 - Elapsed time: 154.7600440979004 s
INFO:root:  batch 100 loss: 0.018202075036242604
INFO:root:LOSS train' 0.018202075036242604, 12450
INFO:root:  batch 200 loss: 0.018502546418458225
INFO:root:LOSS train' 0.018502546418458225, 12550
INFO:root:  batch 300 loss: 0.018873364701867103
INFO:root:LOSS train' 0.018873364701867103, 12650
INFO:root:Epoch: 38 - LOSS train: 0.018873364701867103 LOSS val: 0.01986958459019661 - Elapsed time: 154.82175207138062 s
INFO:root:  batch 100 loss: 0.018553940374404193
INFO:root:LOSS train' 0.018553940374404193, 12775
INFO:root:  batch 200 loss: 0.01799556815996766
INFO:root:LOSS train' 0.01799556815996766, 12875
INFO:root:  batch 300 loss: 0.028687802050262688
INFO:root:LOSS train' 0.028687802050262688, 12975
INFO:root:Epoch: 39 - LOSS train: 0.028687802050262688 LOSS val: 0.02279849909245968 - Elapsed time: 154.70360374450684 s
INFO:root:  batch 100 loss: 0.01981817132793367
INFO:root:LOSS train' 0.01981817132793367, 13100
INFO:root:  batch 200 loss: 0.018628655225038527
INFO:root:LOSS train' 0.018628655225038527, 13200
INFO:root:  batch 300 loss: 0.021847955007106065
INFO:root:LOSS train' 0.021847955007106065, 13300
INFO:root:Epoch: 40 - LOSS train: 0.021847955007106065 LOSS val: 0.0181556548923254 - Elapsed time: 154.618999004364 s
INFO:root:*************
INFO:root:             
INFO:root:Starting to test....
INFO:root:             
INFO:root:OneStep loss: 0.01828662119805813
INFO:root:Scalar loss: 0.02481956034898758
INFO:root:Vector loss: 0.015020148828625679
INFO:root:             
INFO:root:Done.

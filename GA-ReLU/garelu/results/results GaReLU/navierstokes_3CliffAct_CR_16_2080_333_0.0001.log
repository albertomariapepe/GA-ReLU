INFO:root:*************
INFO:root:             
INFO:root:model chosen: CR
INFO:root:multivector activation function?: 3
INFO:root:training trajectories: 2080
INFO:root:training epochs: 200
INFO:root:training batchsize: 16
INFO:root:learning rate: 0.0001
INFO:root:seed: 333
INFO:root:patience: 15
INFO:root:training dataset path: datasets/trainingdataviscous/
INFO:root:test dataset path: datasets/testdataviscous/
INFO:root:             
INFO:root:*************
INFO:root:Using device: cuda
INFO:root:[[[1.6940998  1.5566934  1.3046039  1.0440726 ]
  [1.6066581  1.3995012  1.342347   1.233624  ]
  [1.4666691  1.3354036  1.3883016  1.2737162 ]
  [1.4122795  1.3854291  1.4587754  1.339578  ]]

 [[1.6459564  1.3450366  1.0299298  0.77708894]
  [1.6489182  1.5250436  1.3721011  1.2203181 ]
  [1.4844782  1.3996952  1.3643513  1.3251002 ]
  [1.3969231  1.3963239  1.4048748  1.4067723 ]]]
INFO:root:****
INFO:root:[[[1.6940998  1.5566934  1.3046039  1.0440726 ]
  [1.6066581  1.3995012  1.342347   1.233624  ]
  [1.4666691  1.3354036  1.3883016  1.2737162 ]
  [1.4122795  1.3854291  1.4587754  1.339578  ]]

 [[1.6459564  1.3450366  1.0299298  0.77708894]
  [1.6489182  1.5250436  1.3721011  1.2203181 ]
  [1.4844782  1.3996952  1.3643513  1.3251002 ]
  [1.3969231  1.3963239  1.4048748  1.4067723 ]]]
INFO:root:Train input shape: torch.Size([2080, 2, 128, 128, 3])
INFO:root:Train labels shape: torch.Size([2080, 1, 128, 128, 3])
INFO:root:                   
INFO:root:Val input shape: torch.Size([4680, 2, 128, 128, 3])
INFO:root:Val labels shape: torch.Size([4680, 1, 128, 128, 3])
INFO:root:*************
INFO:root:             
INFO:root:Starting to train....
INFO:root:  batch 100 loss: 0.2271910311281681
INFO:root:LOSS train' 0.2271910311281681, 100
INFO:root:Epoch: 0 - LOSS train: 0.2271910311281681 LOSS val: 0.14875923097133636 - Elapsed time: 96.84853386878967 s
INFO:root:  batch 100 loss: 0.14515294954180719
INFO:root:LOSS train' 0.14515294954180719, 230
INFO:root:Epoch: 1 - LOSS train: 0.14515294954180719 LOSS val: 0.1261395514011383 - Elapsed time: 95.61833477020264 s
INFO:root:  batch 100 loss: 0.12791676715016365
INFO:root:LOSS train' 0.12791676715016365, 360
INFO:root:Epoch: 2 - LOSS train: 0.12791676715016365 LOSS val: 0.10975714772939682 - Elapsed time: 95.6149115562439 s
INFO:root:  batch 100 loss: 0.11420768320560455
INFO:root:LOSS train' 0.11420768320560455, 490
INFO:root:Epoch: 3 - LOSS train: 0.11420768320560455 LOSS val: 0.10462547093629837 - Elapsed time: 95.6776762008667 s
INFO:root:  batch 100 loss: 0.10063774906098842
INFO:root:LOSS train' 0.10063774906098842, 620
INFO:root:Epoch: 4 - LOSS train: 0.10063774906098842 LOSS val: 0.09059922397136688 - Elapsed time: 95.69615435600281 s
INFO:root:  batch 100 loss: 0.09282392382621765
INFO:root:LOSS train' 0.09282392382621765, 750
INFO:root:Epoch: 5 - LOSS train: 0.09282392382621765 LOSS val: 0.0803159549832344 - Elapsed time: 95.7390558719635 s
INFO:root:  batch 100 loss: 0.08534718260169029
INFO:root:LOSS train' 0.08534718260169029, 880
INFO:root:Epoch: 6 - LOSS train: 0.08534718260169029 LOSS val: 0.07997456938028336 - Elapsed time: 95.64093160629272 s
INFO:root:  batch 100 loss: 0.0770296023786068
INFO:root:LOSS train' 0.0770296023786068, 1010
INFO:root:Epoch: 7 - LOSS train: 0.0770296023786068 LOSS val: 0.07613685727119446 - Elapsed time: 95.81034469604492 s
INFO:root:  batch 100 loss: 0.07494192831218242
INFO:root:LOSS train' 0.07494192831218242, 1140
INFO:root:Epoch: 8 - LOSS train: 0.07494192831218242 LOSS val: 0.06915589421987534 - Elapsed time: 95.68908047676086 s
INFO:root:  batch 100 loss: 0.0710863658413291
INFO:root:LOSS train' 0.0710863658413291, 1270
INFO:root:Epoch: 9 - LOSS train: 0.0710863658413291 LOSS val: 0.06413634121417999 - Elapsed time: 95.6194236278534 s
INFO:root:  batch 100 loss: 0.06601271647959947
INFO:root:LOSS train' 0.06601271647959947, 1400
INFO:root:Epoch: 10 - LOSS train: 0.06601271647959947 LOSS val: 0.06323091685771942 - Elapsed time: 95.64505338668823 s
INFO:root:  batch 100 loss: 0.06106676734983921
INFO:root:LOSS train' 0.06106676734983921, 1530
INFO:root:Epoch: 11 - LOSS train: 0.06106676734983921 LOSS val: 0.056956417858600616 - Elapsed time: 95.73728632926941 s
INFO:root:  batch 100 loss: 0.05788077834993601
INFO:root:LOSS train' 0.05788077834993601, 1660
INFO:root:Epoch: 12 - LOSS train: 0.05788077834993601 LOSS val: 0.07387777417898178 - Elapsed time: 95.75482273101807 s
INFO:root:  batch 100 loss: 0.05783054731786251
INFO:root:LOSS train' 0.05783054731786251, 1790
INFO:root:Epoch: 13 - LOSS train: 0.05783054731786251 LOSS val: 0.055327240377664566 - Elapsed time: 95.67000317573547 s
INFO:root:  batch 100 loss: 0.05395630951970816
INFO:root:LOSS train' 0.05395630951970816, 1920
INFO:root:Epoch: 14 - LOSS train: 0.05395630951970816 LOSS val: 0.055423520505428314 - Elapsed time: 95.87016677856445 s
INFO:root:  batch 100 loss: 0.05553865868598223
INFO:root:LOSS train' 0.05553865868598223, 2050
INFO:root:Epoch: 15 - LOSS train: 0.05553865868598223 LOSS val: 0.051976993680000305 - Elapsed time: 95.69669246673584 s
INFO:root:  batch 100 loss: 0.05027642726898193
INFO:root:LOSS train' 0.05027642726898193, 2180
INFO:root:Epoch: 16 - LOSS train: 0.05027642726898193 LOSS val: 0.05006745830178261 - Elapsed time: 95.72849178314209 s
INFO:root:  batch 100 loss: 0.05056837361305952
INFO:root:LOSS train' 0.05056837361305952, 2310
INFO:root:Epoch: 17 - LOSS train: 0.05056837361305952 LOSS val: 0.046373773366212845 - Elapsed time: 95.6773054599762 s
INFO:root:  batch 100 loss: 0.052004507184028624
INFO:root:LOSS train' 0.052004507184028624, 2440
INFO:root:Epoch: 18 - LOSS train: 0.052004507184028624 LOSS val: 0.04568605124950409 - Elapsed time: 95.74594855308533 s
INFO:root:  batch 100 loss: 0.04710760958492756
INFO:root:LOSS train' 0.04710760958492756, 2570
INFO:root:Epoch: 19 - LOSS train: 0.04710760958492756 LOSS val: 0.046962376683950424 - Elapsed time: 95.73527097702026 s
INFO:root:  batch 100 loss: 0.05680463530123234
INFO:root:LOSS train' 0.05680463530123234, 2700
INFO:root:Epoch: 20 - LOSS train: 0.05680463530123234 LOSS val: 0.047783177345991135 - Elapsed time: 95.66399145126343 s
INFO:root:  batch 100 loss: 0.04413396265357733
INFO:root:LOSS train' 0.04413396265357733, 2830
INFO:root:Epoch: 21 - LOSS train: 0.04413396265357733 LOSS val: 0.04621102660894394 - Elapsed time: 95.74137043952942 s
INFO:root:  batch 100 loss: 0.04211492624133825
INFO:root:LOSS train' 0.04211492624133825, 2960
INFO:root:Epoch: 22 - LOSS train: 0.04211492624133825 LOSS val: 0.04197975620627403 - Elapsed time: 95.63794374465942 s
INFO:root:  batch 100 loss: 0.04030852362513542
INFO:root:LOSS train' 0.04030852362513542, 3090
INFO:root:Epoch: 23 - LOSS train: 0.04030852362513542 LOSS val: 0.045658569782972336 - Elapsed time: 95.77828097343445 s
INFO:root:  batch 100 loss: 0.041995822452008724
INFO:root:LOSS train' 0.041995822452008724, 3220
INFO:root:Epoch: 24 - LOSS train: 0.041995822452008724 LOSS val: 0.04176140949130058 - Elapsed time: 95.61867189407349 s
INFO:root:  batch 100 loss: 0.03915691070258617
INFO:root:LOSS train' 0.03915691070258617, 3350
INFO:root:Epoch: 25 - LOSS train: 0.03915691070258617 LOSS val: 0.037866320461034775 - Elapsed time: 95.66146850585938 s
INFO:root:  batch 100 loss: 0.03861183848232031
INFO:root:LOSS train' 0.03861183848232031, 3480
INFO:root:Epoch: 26 - LOSS train: 0.03861183848232031 LOSS val: 0.042717866599559784 - Elapsed time: 95.77126908302307 s
INFO:root:  batch 100 loss: 0.04000038720667362
INFO:root:LOSS train' 0.04000038720667362, 3610
INFO:root:Epoch: 27 - LOSS train: 0.04000038720667362 LOSS val: 0.03956778347492218 - Elapsed time: 95.6974515914917 s
INFO:root:  batch 100 loss: 0.03650705981999636
INFO:root:LOSS train' 0.03650705981999636, 3740
INFO:root:Epoch: 28 - LOSS train: 0.03650705981999636 LOSS val: 0.03717627748847008 - Elapsed time: 95.67252969741821 s
INFO:root:  batch 100 loss: 0.037533621974289416
INFO:root:LOSS train' 0.037533621974289416, 3870
INFO:root:Epoch: 29 - LOSS train: 0.037533621974289416 LOSS val: 0.0372060127556324 - Elapsed time: 95.7136652469635 s
INFO:root:  batch 100 loss: 0.04005135590210557
INFO:root:LOSS train' 0.04005135590210557, 4000
INFO:root:Epoch: 30 - LOSS train: 0.04005135590210557 LOSS val: 0.03458959981799126 - Elapsed time: 95.57643365859985 s
INFO:root:  batch 100 loss: 0.03391211686655879
INFO:root:LOSS train' 0.03391211686655879, 4130
INFO:root:Epoch: 31 - LOSS train: 0.03391211686655879 LOSS val: 0.0411231592297554 - Elapsed time: 95.57560110092163 s
INFO:root:  batch 100 loss: 0.03978597225621343
INFO:root:LOSS train' 0.03978597225621343, 4260
INFO:root:Epoch: 32 - LOSS train: 0.03978597225621343 LOSS val: 0.03371347114443779 - Elapsed time: 95.60006284713745 s
INFO:root:  batch 100 loss: 0.03579869039356708
INFO:root:LOSS train' 0.03579869039356708, 4390
INFO:root:Epoch: 33 - LOSS train: 0.03579869039356708 LOSS val: 0.03606252372264862 - Elapsed time: 95.56839418411255 s
INFO:root:  batch 100 loss: 0.03386841470375657
INFO:root:LOSS train' 0.03386841470375657, 4520
INFO:root:Epoch: 34 - LOSS train: 0.03386841470375657 LOSS val: 0.033026229590177536 - Elapsed time: 95.6472270488739 s
INFO:root:  batch 100 loss: 0.03226279880851507
INFO:root:LOSS train' 0.03226279880851507, 4650
INFO:root:Epoch: 35 - LOSS train: 0.03226279880851507 LOSS val: 0.03259573504328728 - Elapsed time: 95.63835191726685 s
INFO:root:  batch 100 loss: 0.0451483916118741
INFO:root:LOSS train' 0.0451483916118741, 4780
INFO:root:Epoch: 36 - LOSS train: 0.0451483916118741 LOSS val: 0.03345012292265892 - Elapsed time: 95.69682121276855 s
INFO:root:  batch 100 loss: 0.032945050410926345
INFO:root:LOSS train' 0.032945050410926345, 4910
INFO:root:Epoch: 37 - LOSS train: 0.032945050410926345 LOSS val: 0.0315464586019516 - Elapsed time: 95.68688488006592 s
INFO:root:  batch 100 loss: 0.032693478520959614
INFO:root:LOSS train' 0.032693478520959614, 5040
INFO:root:Epoch: 38 - LOSS train: 0.032693478520959614 LOSS val: 0.029972979798913002 - Elapsed time: 95.7744369506836 s
INFO:root:  batch 100 loss: 0.031918457113206386
INFO:root:LOSS train' 0.031918457113206386, 5170
INFO:root:Epoch: 39 - LOSS train: 0.031918457113206386 LOSS val: 0.03316808119416237 - Elapsed time: 95.67050886154175 s
INFO:root:  batch 100 loss: 0.03056896520778537
INFO:root:LOSS train' 0.03056896520778537, 5300
INFO:root:Epoch: 40 - LOSS train: 0.03056896520778537 LOSS val: 0.029953068122267723 - Elapsed time: 95.65235137939453 s
INFO:root:  batch 100 loss: 0.034051185473799706
INFO:root:LOSS train' 0.034051185473799706, 5430
INFO:root:Epoch: 41 - LOSS train: 0.034051185473799706 LOSS val: 0.02940784953534603 - Elapsed time: 95.78793430328369 s
INFO:root:  batch 100 loss: 0.029964483361691236
INFO:root:LOSS train' 0.029964483361691236, 5560
INFO:root:Epoch: 42 - LOSS train: 0.029964483361691236 LOSS val: 0.02956167422235012 - Elapsed time: 95.57617568969727 s
INFO:root:  batch 100 loss: 0.03205161355435848
INFO:root:LOSS train' 0.03205161355435848, 5690
INFO:root:Epoch: 43 - LOSS train: 0.03205161355435848 LOSS val: 0.02925736829638481 - Elapsed time: 95.55860614776611 s
INFO:root:  batch 100 loss: 0.03014335297048092
INFO:root:LOSS train' 0.03014335297048092, 5820
INFO:root:Epoch: 44 - LOSS train: 0.03014335297048092 LOSS val: 0.0286865197122097 - Elapsed time: 95.61574268341064 s
INFO:root:  batch 100 loss: 0.030458856914192436
INFO:root:LOSS train' 0.030458856914192436, 5950
INFO:root:Epoch: 45 - LOSS train: 0.030458856914192436 LOSS val: 0.03046092763543129 - Elapsed time: 95.68793940544128 s
INFO:root:*************
INFO:root:             
INFO:root:Starting to test....
INFO:root:             
INFO:root:OneStep loss: 0.02898387238383293
INFO:root:Scalar loss: 0.03826233372092247
INFO:root:Vector loss: 0.02434464544057846
INFO:root:             
INFO:root:Done.

INFO:root:*************
INFO:root:             
INFO:root:model chosen: CR
INFO:root:multivector activation function?: 0
INFO:root:training trajectories: 2080
INFO:root:training epochs: 200
INFO:root:training batchsize: 16
INFO:root:learning rate: 0.0001
INFO:root:seed: 666
INFO:root:patience: 15
INFO:root:training dataset path: datasets/trainingdataviscous/
INFO:root:test dataset path: datasets/testdataviscous/
INFO:root:             
INFO:root:*************
INFO:root:Using device: cuda
INFO:root:[[[1.6940998  1.5566934  1.3046039  1.0440726 ]
  [1.6066581  1.3995012  1.342347   1.233624  ]
  [1.4666691  1.3354036  1.3883016  1.2737162 ]
  [1.4122795  1.3854291  1.4587754  1.339578  ]]

 [[1.6459564  1.3450366  1.0299298  0.77708894]
  [1.6489182  1.5250436  1.3721011  1.2203181 ]
  [1.4844782  1.3996952  1.3643513  1.3251002 ]
  [1.3969231  1.3963239  1.4048748  1.4067723 ]]]
INFO:root:****
INFO:root:[[[1.6940998  1.5566934  1.3046039  1.0440726 ]
  [1.6066581  1.3995012  1.342347   1.233624  ]
  [1.4666691  1.3354036  1.3883016  1.2737162 ]
  [1.4122795  1.3854291  1.4587754  1.339578  ]]

 [[1.6459564  1.3450366  1.0299298  0.77708894]
  [1.6489182  1.5250436  1.3721011  1.2203181 ]
  [1.4844782  1.3996952  1.3643513  1.3251002 ]
  [1.3969231  1.3963239  1.4048748  1.4067723 ]]]
INFO:root:Train input shape: torch.Size([2080, 2, 128, 128, 3])
INFO:root:Train labels shape: torch.Size([2080, 1, 128, 128, 3])
INFO:root:                   
INFO:root:Val input shape: torch.Size([4680, 2, 128, 128, 3])
INFO:root:Val labels shape: torch.Size([4680, 1, 128, 128, 3])
INFO:root:*************
INFO:root:             
INFO:root:Starting to train....
INFO:root:  batch 100 loss: 0.2303486306965351
INFO:root:LOSS train' 0.2303486306965351, 100
INFO:root:Epoch: 0 - LOSS train: 0.2303486306965351 LOSS val: 0.16104502975940704 - Elapsed time: 96.2614381313324 s
INFO:root:  batch 100 loss: 0.1443516120314598
INFO:root:LOSS train' 0.1443516120314598, 230
INFO:root:Epoch: 1 - LOSS train: 0.1443516120314598 LOSS val: 0.13919663429260254 - Elapsed time: 95.45527005195618 s
INFO:root:  batch 100 loss: 0.12837775491178036
INFO:root:LOSS train' 0.12837775491178036, 360
INFO:root:Epoch: 2 - LOSS train: 0.12837775491178036 LOSS val: 0.11640661954879761 - Elapsed time: 95.76927638053894 s
INFO:root:  batch 100 loss: 0.11144297234714032
INFO:root:LOSS train' 0.11144297234714032, 490
INFO:root:Epoch: 3 - LOSS train: 0.11144297234714032 LOSS val: 0.09764347970485687 - Elapsed time: 95.62019085884094 s
INFO:root:  batch 100 loss: 0.10525877617299556
INFO:root:LOSS train' 0.10525877617299556, 620
INFO:root:Epoch: 4 - LOSS train: 0.10525877617299556 LOSS val: 0.09413595497608185 - Elapsed time: 95.69058084487915 s
INFO:root:  batch 100 loss: 0.09210731267929077
INFO:root:LOSS train' 0.09210731267929077, 750
INFO:root:Epoch: 5 - LOSS train: 0.09210731267929077 LOSS val: 0.08162402361631393 - Elapsed time: 95.73040461540222 s
INFO:root:  batch 100 loss: 0.08384083919227123
INFO:root:LOSS train' 0.08384083919227123, 880
INFO:root:Epoch: 6 - LOSS train: 0.08384083919227123 LOSS val: 0.08644922822713852 - Elapsed time: 95.80259895324707 s
INFO:root:  batch 100 loss: 0.0804590194672346
INFO:root:LOSS train' 0.0804590194672346, 1010
INFO:root:Epoch: 7 - LOSS train: 0.0804590194672346 LOSS val: 0.07376278936862946 - Elapsed time: 95.66836833953857 s
INFO:root:  batch 100 loss: 0.07941647425293923
INFO:root:LOSS train' 0.07941647425293923, 1140
INFO:root:Epoch: 8 - LOSS train: 0.07941647425293923 LOSS val: 0.07369449734687805 - Elapsed time: 95.7696795463562 s
INFO:root:  batch 100 loss: 0.07042719122022391
INFO:root:LOSS train' 0.07042719122022391, 1270
INFO:root:Epoch: 9 - LOSS train: 0.07042719122022391 LOSS val: 0.06854444742202759 - Elapsed time: 95.7722384929657 s
INFO:root:  batch 100 loss: 0.06599880527704954
INFO:root:LOSS train' 0.06599880527704954, 1400
INFO:root:Epoch: 10 - LOSS train: 0.06599880527704954 LOSS val: 0.06669848412275314 - Elapsed time: 95.65842723846436 s
INFO:root:  batch 100 loss: 0.0673243759199977
INFO:root:LOSS train' 0.0673243759199977, 1530
INFO:root:Epoch: 11 - LOSS train: 0.0673243759199977 LOSS val: 0.061500903218984604 - Elapsed time: 95.74099087715149 s
INFO:root:  batch 100 loss: 0.06045456830412149
INFO:root:LOSS train' 0.06045456830412149, 1660
INFO:root:Epoch: 12 - LOSS train: 0.06045456830412149 LOSS val: 0.07583459466695786 - Elapsed time: 95.75863814353943 s
INFO:root:  batch 100 loss: 0.06128219466656446
INFO:root:LOSS train' 0.06128219466656446, 1790
INFO:root:Epoch: 13 - LOSS train: 0.06128219466656446 LOSS val: 0.05455624684691429 - Elapsed time: 95.72891426086426 s
INFO:root:  batch 100 loss: 0.056880489364266394
INFO:root:LOSS train' 0.056880489364266394, 1920
INFO:root:Epoch: 14 - LOSS train: 0.056880489364266394 LOSS val: 0.05406802147626877 - Elapsed time: 95.75746417045593 s
INFO:root:  batch 100 loss: 0.053413278087973595
INFO:root:LOSS train' 0.053413278087973595, 2050
INFO:root:Epoch: 15 - LOSS train: 0.053413278087973595 LOSS val: 0.05166936665773392 - Elapsed time: 95.7069776058197 s
INFO:root:  batch 100 loss: 0.05472119461745024
INFO:root:LOSS train' 0.05472119461745024, 2180
INFO:root:Epoch: 16 - LOSS train: 0.05472119461745024 LOSS val: 0.05408714339137077 - Elapsed time: 95.65905499458313 s
INFO:root:  batch 100 loss: 0.05161910522729159
INFO:root:LOSS train' 0.05161910522729159, 2310
INFO:root:Epoch: 17 - LOSS train: 0.05161910522729159 LOSS val: 0.04739381745457649 - Elapsed time: 95.70762467384338 s
INFO:root:  batch 100 loss: 0.0490748493373394
INFO:root:LOSS train' 0.0490748493373394, 2440
INFO:root:Epoch: 18 - LOSS train: 0.0490748493373394 LOSS val: 0.04458313062787056 - Elapsed time: 95.78887939453125 s
INFO:root:  batch 100 loss: 0.04832391738891602
INFO:root:LOSS train' 0.04832391738891602, 2570
INFO:root:Epoch: 19 - LOSS train: 0.04832391738891602 LOSS val: 0.04534491151571274 - Elapsed time: 95.62576103210449 s
INFO:root:  batch 100 loss: 0.045332283042371274
INFO:root:LOSS train' 0.045332283042371274, 2700
INFO:root:Epoch: 20 - LOSS train: 0.045332283042371274 LOSS val: 0.047485675662755966 - Elapsed time: 95.7027530670166 s
INFO:root:  batch 100 loss: 0.050622364431619646
INFO:root:LOSS train' 0.050622364431619646, 2830
INFO:root:Epoch: 21 - LOSS train: 0.050622364431619646 LOSS val: 0.042529188096523285 - Elapsed time: 95.67667961120605 s
INFO:root:  batch 100 loss: 0.04260173622518778
INFO:root:LOSS train' 0.04260173622518778, 2960
INFO:root:Epoch: 22 - LOSS train: 0.04260173622518778 LOSS val: 0.04056720435619354 - Elapsed time: 95.756356716156 s
INFO:root:  batch 100 loss: 0.041346317380666735
INFO:root:LOSS train' 0.041346317380666735, 3090
INFO:root:Epoch: 23 - LOSS train: 0.041346317380666735 LOSS val: 0.04044730216264725 - Elapsed time: 95.68040752410889 s
INFO:root:  batch 100 loss: 0.04251866042613983
INFO:root:LOSS train' 0.04251866042613983, 3220
INFO:root:Epoch: 24 - LOSS train: 0.04251866042613983 LOSS val: 0.04295205697417259 - Elapsed time: 95.69308662414551 s
INFO:root:  batch 100 loss: 0.0395013764500618
INFO:root:LOSS train' 0.0395013764500618, 3350
INFO:root:Epoch: 25 - LOSS train: 0.0395013764500618 LOSS val: 0.04218848794698715 - Elapsed time: 95.71725034713745 s
INFO:root:  batch 100 loss: 0.04149590115994215
INFO:root:LOSS train' 0.04149590115994215, 3480
INFO:root:Epoch: 26 - LOSS train: 0.04149590115994215 LOSS val: 0.038812994956970215 - Elapsed time: 95.81610655784607 s
INFO:root:  batch 100 loss: 0.037795461155474185
INFO:root:LOSS train' 0.037795461155474185, 3610
INFO:root:Epoch: 27 - LOSS train: 0.037795461155474185 LOSS val: 0.04088273271918297 - Elapsed time: 95.72462391853333 s
INFO:root:  batch 100 loss: 0.03855871807783842
INFO:root:LOSS train' 0.03855871807783842, 3740
INFO:root:Epoch: 28 - LOSS train: 0.03855871807783842 LOSS val: 0.03735931217670441 - Elapsed time: 95.79320478439331 s
INFO:root:  batch 100 loss: 0.03582877404987812
INFO:root:LOSS train' 0.03582877404987812, 3870
INFO:root:Epoch: 29 - LOSS train: 0.03582877404987812 LOSS val: 0.03702511638402939 - Elapsed time: 95.79789185523987 s
INFO:root:  batch 100 loss: 0.03625211000442505
INFO:root:LOSS train' 0.03625211000442505, 4000
INFO:root:Epoch: 30 - LOSS train: 0.03625211000442505 LOSS val: 0.03447449579834938 - Elapsed time: 95.88381958007812 s
INFO:root:  batch 100 loss: 0.035998601354658606
INFO:root:LOSS train' 0.035998601354658606, 4130
INFO:root:Epoch: 31 - LOSS train: 0.035998601354658606 LOSS val: 0.034432269632816315 - Elapsed time: 95.67995285987854 s
INFO:root:  batch 100 loss: 0.03475722976028919
INFO:root:LOSS train' 0.03475722976028919, 4260
INFO:root:Epoch: 32 - LOSS train: 0.03475722976028919 LOSS val: 0.03454700857400894 - Elapsed time: 95.7201075553894 s
INFO:root:  batch 100 loss: 0.034592771418392655
INFO:root:LOSS train' 0.034592771418392655, 4390
INFO:root:Epoch: 33 - LOSS train: 0.034592771418392655 LOSS val: 0.04834003001451492 - Elapsed time: 95.68769645690918 s
INFO:root:  batch 100 loss: 0.03629329569637776
INFO:root:LOSS train' 0.03629329569637776, 4520
INFO:root:Epoch: 34 - LOSS train: 0.03629329569637776 LOSS val: 0.032832782715559006 - Elapsed time: 95.74839329719543 s
INFO:root:  batch 100 loss: 0.035908848103135826
INFO:root:LOSS train' 0.035908848103135826, 4650
INFO:root:Epoch: 35 - LOSS train: 0.035908848103135826 LOSS val: 0.03260589763522148 - Elapsed time: 95.895822763443 s
INFO:root:  batch 100 loss: 0.032795295249670744
INFO:root:LOSS train' 0.032795295249670744, 4780
INFO:root:Epoch: 36 - LOSS train: 0.032795295249670744 LOSS val: 0.032636526972055435 - Elapsed time: 95.6681342124939 s
INFO:root:  batch 100 loss: 0.03237398020923138
INFO:root:LOSS train' 0.03237398020923138, 4910
INFO:root:Epoch: 37 - LOSS train: 0.03237398020923138 LOSS val: 0.03538064286112785 - Elapsed time: 95.68714952468872 s
INFO:root:  batch 100 loss: 0.031648829262703654
INFO:root:LOSS train' 0.031648829262703654, 5040
INFO:root:Epoch: 38 - LOSS train: 0.031648829262703654 LOSS val: 0.029756279662251472 - Elapsed time: 95.82459449768066 s
INFO:root:  batch 100 loss: 0.03532923299819231
INFO:root:LOSS train' 0.03532923299819231, 5170
INFO:root:Epoch: 39 - LOSS train: 0.03532923299819231 LOSS val: 0.0299945417791605 - Elapsed time: 95.72974967956543 s
INFO:root:  batch 100 loss: 0.03105156060308218
INFO:root:LOSS train' 0.03105156060308218, 5300
INFO:root:Epoch: 40 - LOSS train: 0.03105156060308218 LOSS val: 0.03044331632554531 - Elapsed time: 95.80946373939514 s
INFO:root:  batch 100 loss: 0.030709176547825335
INFO:root:LOSS train' 0.030709176547825335, 5430
INFO:root:Epoch: 41 - LOSS train: 0.030709176547825335 LOSS val: 0.03204018995165825 - Elapsed time: 95.8923614025116 s
INFO:root:*************
INFO:root:             
INFO:root:Starting to test....
INFO:root:             
INFO:root:OneStep loss: 0.030027545988559723
INFO:root:Scalar loss: 0.03913021832704544
INFO:root:Vector loss: 0.025476213544607162
INFO:root:             
INFO:root:Done.

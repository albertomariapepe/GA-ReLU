INFO:root:*************
INFO:root:             
INFO:root:model chosen: CR
INFO:root:multivector activation function?: 3
INFO:root:training trajectories: 5200
INFO:root:training epochs: 200
INFO:root:training batchsize: 16
INFO:root:learning rate: 0.0001
INFO:root:seed: 28996
INFO:root:patience: 15
INFO:root:training dataset path: datasets/trainingdataviscous/
INFO:root:test dataset path: datasets/testdataviscous/
INFO:root:             
INFO:root:*************
INFO:root:Using device: cuda
INFO:root:[[[1.6940998  1.5566934  1.3046039  1.0440726 ]
  [1.6066581  1.3995012  1.342347   1.233624  ]
  [1.4666691  1.3354036  1.3883016  1.2737162 ]
  [1.4122795  1.3854291  1.4587754  1.339578  ]]

 [[1.6459564  1.3450366  1.0299298  0.77708894]
  [1.6489182  1.5250436  1.3721011  1.2203181 ]
  [1.4844782  1.3996952  1.3643513  1.3251002 ]
  [1.3969231  1.3963239  1.4048748  1.4067723 ]]]
INFO:root:****
INFO:root:[[[1.6940998  1.5566934  1.3046039  1.0440726 ]
  [1.6066581  1.3995012  1.342347   1.233624  ]
  [1.4666691  1.3354036  1.3883016  1.2737162 ]
  [1.4122795  1.3854291  1.4587754  1.339578  ]]

 [[1.6459564  1.3450366  1.0299298  0.77708894]
  [1.6489182  1.5250436  1.3721011  1.2203181 ]
  [1.4844782  1.3996952  1.3643513  1.3251002 ]
  [1.3969231  1.3963239  1.4048748  1.4067723 ]]]
INFO:root:Train input shape: torch.Size([5200, 2, 128, 128, 3])
INFO:root:Train labels shape: torch.Size([5200, 1, 128, 128, 3])
INFO:root:                   
INFO:root:Val input shape: torch.Size([4680, 2, 128, 128, 3])
INFO:root:Val labels shape: torch.Size([4680, 1, 128, 128, 3])
INFO:root:*************
INFO:root:             
INFO:root:Starting to train....
INFO:root:  batch 100 loss: 0.23391352206468582
INFO:root:LOSS train' 0.23391352206468582, 100
INFO:root:  batch 200 loss: 0.1556393301486969
INFO:root:LOSS train' 0.1556393301486969, 200
INFO:root:  batch 300 loss: 0.13480794347822667
INFO:root:LOSS train' 0.13480794347822667, 300
INFO:root:Epoch: 0 - LOSS train: 0.13480794347822667 LOSS val: 0.11964572966098785 - Elapsed time: 155.81077003479004 s
INFO:root:  batch 100 loss: 0.11831731677055358
INFO:root:LOSS train' 0.11831731677055358, 425
INFO:root:  batch 200 loss: 0.1086451581865549
INFO:root:LOSS train' 0.1086451581865549, 525
INFO:root:  batch 300 loss: 0.0990921838581562
INFO:root:LOSS train' 0.0990921838581562, 625
INFO:root:Epoch: 1 - LOSS train: 0.0990921838581562 LOSS val: 0.0940900593996048 - Elapsed time: 154.71824383735657 s
INFO:root:  batch 100 loss: 0.09009605623781682
INFO:root:LOSS train' 0.09009605623781682, 750
INFO:root:  batch 200 loss: 0.09307935126125813
INFO:root:LOSS train' 0.09307935126125813, 850
INFO:root:  batch 300 loss: 0.07894860334694385
INFO:root:LOSS train' 0.07894860334694385, 950
INFO:root:Epoch: 2 - LOSS train: 0.07894860334694385 LOSS val: 0.07962555438280106 - Elapsed time: 154.99080777168274 s
INFO:root:  batch 100 loss: 0.07567576438188553
INFO:root:LOSS train' 0.07567576438188553, 1075
INFO:root:  batch 200 loss: 0.07193228919059039
INFO:root:LOSS train' 0.07193228919059039, 1175
INFO:root:  batch 300 loss: 0.06857464134693146
INFO:root:LOSS train' 0.06857464134693146, 1275
INFO:root:Epoch: 3 - LOSS train: 0.06857464134693146 LOSS val: 0.07149910181760788 - Elapsed time: 154.908704996109 s
INFO:root:  batch 100 loss: 0.06302015732973815
INFO:root:LOSS train' 0.06302015732973815, 1400
INFO:root:  batch 200 loss: 0.06237815584987402
INFO:root:LOSS train' 0.06237815584987402, 1500
INFO:root:  batch 300 loss: 0.06884498577564954
INFO:root:LOSS train' 0.06884498577564954, 1600
INFO:root:Epoch: 4 - LOSS train: 0.06884498577564954 LOSS val: 0.057211969047784805 - Elapsed time: 154.78280639648438 s
INFO:root:  batch 100 loss: 0.05580751035362482
INFO:root:LOSS train' 0.05580751035362482, 1725
INFO:root:  batch 200 loss: 0.05631618645042181
INFO:root:LOSS train' 0.05631618645042181, 1825
INFO:root:  batch 300 loss: 0.0547997035831213
INFO:root:LOSS train' 0.0547997035831213, 1925
INFO:root:Epoch: 5 - LOSS train: 0.0547997035831213 LOSS val: 0.05891571566462517 - Elapsed time: 154.94108629226685 s
INFO:root:  batch 100 loss: 0.051766014397144317
INFO:root:LOSS train' 0.051766014397144317, 2050
INFO:root:  batch 200 loss: 0.05045840419828892
INFO:root:LOSS train' 0.05045840419828892, 2150
INFO:root:  batch 300 loss: 0.07111470881849527
INFO:root:LOSS train' 0.07111470881849527, 2250
INFO:root:Epoch: 6 - LOSS train: 0.07111470881849527 LOSS val: 0.04864490032196045 - Elapsed time: 154.94116258621216 s
INFO:root:  batch 100 loss: 0.048438407629728314
INFO:root:LOSS train' 0.048438407629728314, 2375
INFO:root:  batch 200 loss: 0.04803802315145731
INFO:root:LOSS train' 0.04803802315145731, 2475
INFO:root:  batch 300 loss: 0.04588202722370625
INFO:root:LOSS train' 0.04588202722370625, 2575
INFO:root:Epoch: 7 - LOSS train: 0.04588202722370625 LOSS val: 0.043304692953825 - Elapsed time: 154.7048819065094 s
INFO:root:  batch 100 loss: 0.044989665225148204
INFO:root:LOSS train' 0.044989665225148204, 2700
INFO:root:  batch 200 loss: 0.04908012628555298
INFO:root:LOSS train' 0.04908012628555298, 2800
INFO:root:  batch 300 loss: 0.04200535908341408
INFO:root:LOSS train' 0.04200535908341408, 2900
INFO:root:Epoch: 8 - LOSS train: 0.04200535908341408 LOSS val: 0.055357616394758224 - Elapsed time: 154.66347408294678 s
INFO:root:  batch 100 loss: 0.05227424874901772
INFO:root:LOSS train' 0.05227424874901772, 3025
INFO:root:  batch 200 loss: 0.042374843433499336
INFO:root:LOSS train' 0.042374843433499336, 3125
INFO:root:  batch 300 loss: 0.04092300206422806
INFO:root:LOSS train' 0.04092300206422806, 3225
INFO:root:Epoch: 9 - LOSS train: 0.04092300206422806 LOSS val: 0.04272250831127167 - Elapsed time: 154.80059003829956 s
INFO:root:  batch 100 loss: 0.038876155726611614
INFO:root:LOSS train' 0.038876155726611614, 3350
INFO:root:  batch 200 loss: 0.041781850792467594
INFO:root:LOSS train' 0.041781850792467594, 3450
INFO:root:  batch 300 loss: 0.03847143553197384
INFO:root:LOSS train' 0.03847143553197384, 3550
INFO:root:Epoch: 10 - LOSS train: 0.03847143553197384 LOSS val: 0.0947025716304779 - Elapsed time: 154.7045259475708 s
INFO:root:  batch 100 loss: 0.059105956964194774
INFO:root:LOSS train' 0.059105956964194774, 3675
INFO:root:  batch 200 loss: 0.042622717432677745
INFO:root:LOSS train' 0.042622717432677745, 3775
INFO:root:  batch 300 loss: 0.039197141006588936
INFO:root:LOSS train' 0.039197141006588936, 3875
INFO:root:Epoch: 11 - LOSS train: 0.039197141006588936 LOSS val: 0.040535714477300644 - Elapsed time: 154.78017950057983 s
INFO:root:  batch 100 loss: 0.03938420470803976
INFO:root:LOSS train' 0.03938420470803976, 4000
INFO:root:  batch 200 loss: 0.0374702063575387
INFO:root:LOSS train' 0.0374702063575387, 4100
INFO:root:  batch 300 loss: 0.03559014100581408
INFO:root:LOSS train' 0.03559014100581408, 4200
INFO:root:Epoch: 12 - LOSS train: 0.03559014100581408 LOSS val: 0.03453188017010689 - Elapsed time: 154.60684490203857 s
INFO:root:  batch 100 loss: 0.05409008163958788
INFO:root:LOSS train' 0.05409008163958788, 4325
INFO:root:  batch 200 loss: 0.036958838962018487
INFO:root:LOSS train' 0.036958838962018487, 4425
INFO:root:  batch 300 loss: 0.03542986512184143
INFO:root:LOSS train' 0.03542986512184143, 4525
INFO:root:Epoch: 13 - LOSS train: 0.03542986512184143 LOSS val: 0.03275396674871445 - Elapsed time: 154.68595814704895 s
INFO:root:  batch 100 loss: 0.054021791126579045
INFO:root:LOSS train' 0.054021791126579045, 4650
INFO:root:  batch 200 loss: 0.03676507005468011
INFO:root:LOSS train' 0.03676507005468011, 4750
INFO:root:  batch 300 loss: 0.033970829267054796
INFO:root:LOSS train' 0.033970829267054796, 4850
INFO:root:Epoch: 14 - LOSS train: 0.033970829267054796 LOSS val: 0.03346049040555954 - Elapsed time: 154.94064807891846 s
INFO:root:  batch 100 loss: 0.03302958248183131
INFO:root:LOSS train' 0.03302958248183131, 4975
INFO:root:  batch 200 loss: 0.03314450062811375
INFO:root:LOSS train' 0.03314450062811375, 5075
INFO:root:  batch 300 loss: 0.032611458227038384
INFO:root:LOSS train' 0.032611458227038384, 5175
INFO:root:Epoch: 15 - LOSS train: 0.032611458227038384 LOSS val: 0.03081699274480343 - Elapsed time: 154.7604742050171 s
INFO:root:  batch 100 loss: 0.03199319383129477
INFO:root:LOSS train' 0.03199319383129477, 5300
INFO:root:  batch 200 loss: 0.031124076955020428
INFO:root:LOSS train' 0.031124076955020428, 5400
INFO:root:  batch 300 loss: 0.0364376650005579
INFO:root:LOSS train' 0.0364376650005579, 5500
INFO:root:Epoch: 16 - LOSS train: 0.0364376650005579 LOSS val: 0.030474035069346428 - Elapsed time: 154.55730724334717 s
INFO:root:  batch 100 loss: 0.03089883817359805
INFO:root:LOSS train' 0.03089883817359805, 5625
INFO:root:  batch 200 loss: 0.03176181858405471
INFO:root:LOSS train' 0.03176181858405471, 5725
INFO:root:  batch 300 loss: 0.02896044362336397
INFO:root:LOSS train' 0.02896044362336397, 5825
INFO:root:Epoch: 17 - LOSS train: 0.02896044362336397 LOSS val: 0.028735296800732613 - Elapsed time: 154.65188360214233 s
INFO:root:  batch 100 loss: 0.03341572502627969
INFO:root:LOSS train' 0.03341572502627969, 5950
INFO:root:  batch 200 loss: 0.03153171140700579
INFO:root:LOSS train' 0.03153171140700579, 6050
INFO:root:  batch 300 loss: 0.03700895350426436
INFO:root:LOSS train' 0.03700895350426436, 6150
INFO:root:Epoch: 18 - LOSS train: 0.03700895350426436 LOSS val: 0.05315142869949341 - Elapsed time: 154.56844329833984 s
INFO:root:  batch 100 loss: 0.03860706767067313
INFO:root:LOSS train' 0.03860706767067313, 6275
INFO:root:  batch 200 loss: 0.030966067276895045
INFO:root:LOSS train' 0.030966067276895045, 6375
INFO:root:  batch 300 loss: 0.03036397522315383
INFO:root:LOSS train' 0.03036397522315383, 6475
INFO:root:Epoch: 19 - LOSS train: 0.03036397522315383 LOSS val: 0.028208522126078606 - Elapsed time: 154.60172820091248 s
INFO:root:  batch 100 loss: 0.02814638156443834
INFO:root:LOSS train' 0.02814638156443834, 6600
INFO:root:  batch 200 loss: 0.02892395293340087
INFO:root:LOSS train' 0.02892395293340087, 6700
INFO:root:  batch 300 loss: 0.026748436205089092
INFO:root:LOSS train' 0.026748436205089092, 6800
INFO:root:Epoch: 20 - LOSS train: 0.026748436205089092 LOSS val: 0.026448652148246765 - Elapsed time: 154.94436025619507 s
INFO:root:  batch 100 loss: 0.02668071858584881
INFO:root:LOSS train' 0.02668071858584881, 6925
INFO:root:  batch 200 loss: 0.032402683906257154
INFO:root:LOSS train' 0.032402683906257154, 7025
INFO:root:  batch 300 loss: 0.02660274403169751
INFO:root:LOSS train' 0.02660274403169751, 7125
INFO:root:Epoch: 21 - LOSS train: 0.02660274403169751 LOSS val: 0.0252655278891325 - Elapsed time: 154.69726252555847 s
INFO:root:  batch 100 loss: 0.026727480441331865
INFO:root:LOSS train' 0.026727480441331865, 7250
INFO:root:  batch 200 loss: 0.026205829810351133
INFO:root:LOSS train' 0.026205829810351133, 7350
INFO:root:  batch 300 loss: 0.026572551429271698
INFO:root:LOSS train' 0.026572551429271698, 7450
INFO:root:Epoch: 22 - LOSS train: 0.026572551429271698 LOSS val: 0.02488521672785282 - Elapsed time: 154.7049684524536 s
INFO:root:  batch 100 loss: 0.026207864433526993
INFO:root:LOSS train' 0.026207864433526993, 7575
INFO:root:  batch 200 loss: 0.025165834221988915
INFO:root:LOSS train' 0.025165834221988915, 7675
INFO:root:  batch 300 loss: 0.025201762653887273
INFO:root:LOSS train' 0.025201762653887273, 7775
INFO:root:Epoch: 23 - LOSS train: 0.025201762653887273 LOSS val: 0.024718834087252617 - Elapsed time: 154.71629190444946 s
INFO:root:  batch 100 loss: 0.0249670167081058
INFO:root:LOSS train' 0.0249670167081058, 7900
INFO:root:  batch 200 loss: 0.05636886440217495
INFO:root:LOSS train' 0.05636886440217495, 8000
INFO:root:  batch 300 loss: 0.03996384577825665
INFO:root:LOSS train' 0.03996384577825665, 8100
INFO:root:Epoch: 24 - LOSS train: 0.03996384577825665 LOSS val: 0.03387850522994995 - Elapsed time: 154.87171959877014 s
INFO:root:  batch 100 loss: 0.029498384147882462
INFO:root:LOSS train' 0.029498384147882462, 8225
INFO:root:  batch 200 loss: 0.02907667674124241
INFO:root:LOSS train' 0.02907667674124241, 8325
INFO:root:  batch 300 loss: 0.02605471869930625
INFO:root:LOSS train' 0.02605471869930625, 8425
INFO:root:Epoch: 25 - LOSS train: 0.02605471869930625 LOSS val: 0.02530982717871666 - Elapsed time: 154.71782565116882 s
INFO:root:  batch 100 loss: 0.02542777106165886
INFO:root:LOSS train' 0.02542777106165886, 8550
INFO:root:  batch 200 loss: 0.024817440714687108
INFO:root:LOSS train' 0.024817440714687108, 8650
INFO:root:  batch 300 loss: 0.04049725446850062
INFO:root:LOSS train' 0.04049725446850062, 8750
INFO:root:Epoch: 26 - LOSS train: 0.04049725446850062 LOSS val: 0.02990015223622322 - Elapsed time: 154.71588587760925 s
INFO:root:  batch 100 loss: 0.027913989722728728
INFO:root:LOSS train' 0.027913989722728728, 8875
INFO:root:  batch 200 loss: 0.024995299819856882
INFO:root:LOSS train' 0.024995299819856882, 8975
INFO:root:  batch 300 loss: 0.02447847316041589
INFO:root:LOSS train' 0.02447847316041589, 9075
INFO:root:Epoch: 27 - LOSS train: 0.02447847316041589 LOSS val: 0.023051926866173744 - Elapsed time: 154.88040947914124 s
INFO:root:  batch 100 loss: 0.023569114152342082
INFO:root:LOSS train' 0.023569114152342082, 9200
INFO:root:  batch 200 loss: 0.023305766098201276
INFO:root:LOSS train' 0.023305766098201276, 9300
INFO:root:  batch 300 loss: 0.02363005455583334
INFO:root:LOSS train' 0.02363005455583334, 9400
INFO:root:Epoch: 28 - LOSS train: 0.02363005455583334 LOSS val: 0.03121243417263031 - Elapsed time: 154.72908186912537 s
INFO:root:  batch 100 loss: 0.023765596337616445
INFO:root:LOSS train' 0.023765596337616445, 9525
INFO:root:  batch 200 loss: 0.0228771854005754
INFO:root:LOSS train' 0.0228771854005754, 9625
INFO:root:  batch 300 loss: 0.02212869707494974
INFO:root:LOSS train' 0.02212869707494974, 9725
INFO:root:Epoch: 29 - LOSS train: 0.02212869707494974 LOSS val: 0.021442336961627007 - Elapsed time: 154.7641146183014 s
INFO:root:  batch 100 loss: 0.022309934943914412
INFO:root:LOSS train' 0.022309934943914412, 9850
INFO:root:  batch 200 loss: 0.02315861523151398
INFO:root:LOSS train' 0.02315861523151398, 9950
INFO:root:  batch 300 loss: 0.022320524454116822
INFO:root:LOSS train' 0.022320524454116822, 10050
INFO:root:Epoch: 30 - LOSS train: 0.022320524454116822 LOSS val: 0.02277171052992344 - Elapsed time: 154.99045491218567 s
INFO:root:  batch 100 loss: 0.02156562212854624
INFO:root:LOSS train' 0.02156562212854624, 10175
INFO:root:  batch 200 loss: 0.0219714998267591
INFO:root:LOSS train' 0.0219714998267591, 10275
INFO:root:  batch 300 loss: 0.02182338051497936
INFO:root:LOSS train' 0.02182338051497936, 10375
INFO:root:Epoch: 31 - LOSS train: 0.02182338051497936 LOSS val: 0.0215049646794796 - Elapsed time: 154.80629229545593 s
INFO:root:  batch 100 loss: 0.021054954398423434
INFO:root:LOSS train' 0.021054954398423434, 10500
INFO:root:  batch 200 loss: 0.02160822758451104
INFO:root:LOSS train' 0.02160822758451104, 10600
INFO:root:  batch 300 loss: 0.02089339017868042
INFO:root:LOSS train' 0.02089339017868042, 10700
INFO:root:Epoch: 32 - LOSS train: 0.02089339017868042 LOSS val: 0.021541278809309006 - Elapsed time: 154.87362027168274 s
INFO:root:  batch 100 loss: 0.021593059804290535
INFO:root:LOSS train' 0.021593059804290535, 10825
INFO:root:  batch 200 loss: 0.021860772874206305
INFO:root:LOSS train' 0.021860772874206305, 10925
INFO:root:  batch 300 loss: 0.020170759242027998
INFO:root:LOSS train' 0.020170759242027998, 11025
INFO:root:Epoch: 33 - LOSS train: 0.020170759242027998 LOSS val: 0.0213197972625494 - Elapsed time: 154.64981508255005 s
INFO:root:  batch 100 loss: 0.020924030989408492
INFO:root:LOSS train' 0.020924030989408492, 11150
INFO:root:  batch 200 loss: 0.020155606754124165
INFO:root:LOSS train' 0.020155606754124165, 11250
INFO:root:  batch 300 loss: 0.02054461220279336
INFO:root:LOSS train' 0.02054461220279336, 11350
INFO:root:Epoch: 34 - LOSS train: 0.02054461220279336 LOSS val: 0.020413164049386978 - Elapsed time: 154.67690443992615 s
INFO:root:  batch 100 loss: 0.020213676728308202
INFO:root:LOSS train' 0.020213676728308202, 11475
INFO:root:  batch 200 loss: 0.024861263260245323
INFO:root:LOSS train' 0.024861263260245323, 11575
INFO:root:  batch 300 loss: 0.020936761405318974
INFO:root:LOSS train' 0.020936761405318974, 11675
INFO:root:Epoch: 35 - LOSS train: 0.020936761405318974 LOSS val: 0.021697761490941048 - Elapsed time: 154.63209867477417 s
INFO:root:  batch 100 loss: 0.020275225806981326
INFO:root:LOSS train' 0.020275225806981326, 11800
INFO:root:  batch 200 loss: 0.019632328785955905
INFO:root:LOSS train' 0.019632328785955905, 11900
INFO:root:  batch 300 loss: 0.01958519220352173
INFO:root:LOSS train' 0.01958519220352173, 12000
INFO:root:Epoch: 36 - LOSS train: 0.01958519220352173 LOSS val: 0.018505239859223366 - Elapsed time: 154.62615323066711 s
INFO:root:  batch 100 loss: 0.019397415332496167
INFO:root:LOSS train' 0.019397415332496167, 12125
INFO:root:  batch 200 loss: 0.019992834497243164
INFO:root:LOSS train' 0.019992834497243164, 12225
INFO:root:  batch 300 loss: 0.020190595351159572
INFO:root:LOSS train' 0.020190595351159572, 12325
INFO:root:Epoch: 37 - LOSS train: 0.020190595351159572 LOSS val: 0.018460534512996674 - Elapsed time: 154.86862421035767 s
INFO:root:  batch 100 loss: 0.019098954442888498
INFO:root:LOSS train' 0.019098954442888498, 12450
INFO:root:  batch 200 loss: 0.019073326867073775
INFO:root:LOSS train' 0.019073326867073775, 12550
INFO:root:  batch 300 loss: 0.019111346788704395
INFO:root:LOSS train' 0.019111346788704395, 12650
INFO:root:Epoch: 38 - LOSS train: 0.019111346788704395 LOSS val: 0.01950838789343834 - Elapsed time: 154.57356452941895 s
INFO:root:  batch 100 loss: 0.018876541862264274
INFO:root:LOSS train' 0.018876541862264274, 12775
INFO:root:  batch 200 loss: 0.0190209648758173
INFO:root:LOSS train' 0.0190209648758173, 12875
INFO:root:  batch 300 loss: 0.018714827597141267
INFO:root:LOSS train' 0.018714827597141267, 12975
INFO:root:Epoch: 39 - LOSS train: 0.018714827597141267 LOSS val: 0.017901621758937836 - Elapsed time: 154.59120416641235 s
INFO:root:  batch 100 loss: 0.018488250458613038
INFO:root:LOSS train' 0.018488250458613038, 13100
INFO:root:  batch 200 loss: 0.018549617901444434
INFO:root:LOSS train' 0.018549617901444434, 13200
INFO:root:  batch 300 loss: 0.01872507557272911
INFO:root:LOSS train' 0.01872507557272911, 13300
INFO:root:Epoch: 40 - LOSS train: 0.01872507557272911 LOSS val: 0.0176484864205122 - Elapsed time: 154.79827785491943 s
INFO:root:  batch 100 loss: 0.01814762970432639
INFO:root:LOSS train' 0.01814762970432639, 13425
INFO:root:  batch 200 loss: 0.018166059162467718
INFO:root:LOSS train' 0.018166059162467718, 13525
INFO:root:  batch 300 loss: 0.020438687093555927
INFO:root:LOSS train' 0.020438687093555927, 13625
INFO:root:Epoch: 41 - LOSS train: 0.020438687093555927 LOSS val: 0.018214277923107147 - Elapsed time: 154.71002626419067 s
INFO:root:*************
INFO:root:             
INFO:root:Starting to test....
INFO:root:             
INFO:root:OneStep loss: 0.017845192924141884
INFO:root:Scalar loss: 0.023893291130661964
INFO:root:Vector loss: 0.014821143820881844
INFO:root:             
INFO:root:Done.

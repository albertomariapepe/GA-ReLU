INFO:root:*************
INFO:root:             
INFO:root:model chosen: CR
INFO:root:multivector activation function?: 3
INFO:root:training trajectories: 2080
INFO:root:training epochs: 200
INFO:root:training batchsize: 16
INFO:root:learning rate: 0.0001
INFO:root:seed: 666
INFO:root:patience: 15
INFO:root:training dataset path: datasets/trainingdataviscous/
INFO:root:test dataset path: datasets/testdataviscous/
INFO:root:             
INFO:root:*************
INFO:root:Using device: cuda
INFO:root:[[[1.6940998  1.5566934  1.3046039  1.0440726 ]
  [1.6066581  1.3995012  1.342347   1.233624  ]
  [1.4666691  1.3354036  1.3883016  1.2737162 ]
  [1.4122795  1.3854291  1.4587754  1.339578  ]]

 [[1.6459564  1.3450366  1.0299298  0.77708894]
  [1.6489182  1.5250436  1.3721011  1.2203181 ]
  [1.4844782  1.3996952  1.3643513  1.3251002 ]
  [1.3969231  1.3963239  1.4048748  1.4067723 ]]]
INFO:root:****
INFO:root:[[[1.6940998  1.5566934  1.3046039  1.0440726 ]
  [1.6066581  1.3995012  1.342347   1.233624  ]
  [1.4666691  1.3354036  1.3883016  1.2737162 ]
  [1.4122795  1.3854291  1.4587754  1.339578  ]]

 [[1.6459564  1.3450366  1.0299298  0.77708894]
  [1.6489182  1.5250436  1.3721011  1.2203181 ]
  [1.4844782  1.3996952  1.3643513  1.3251002 ]
  [1.3969231  1.3963239  1.4048748  1.4067723 ]]]
INFO:root:Train input shape: torch.Size([2080, 2, 128, 128, 3])
INFO:root:Train labels shape: torch.Size([2080, 1, 128, 128, 3])
INFO:root:                   
INFO:root:Val input shape: torch.Size([4680, 2, 128, 128, 3])
INFO:root:Val labels shape: torch.Size([4680, 1, 128, 128, 3])
INFO:root:*************
INFO:root:             
INFO:root:Starting to train....
INFO:root:  batch 100 loss: 0.2360239066183567
INFO:root:LOSS train' 0.2360239066183567, 100
INFO:root:Epoch: 0 - LOSS train: 0.2360239066183567 LOSS val: 0.1615113615989685 - Elapsed time: 96.71397733688354 s
INFO:root:  batch 100 loss: 0.14804145872592925
INFO:root:LOSS train' 0.14804145872592925, 230
INFO:root:Epoch: 1 - LOSS train: 0.14804145872592925 LOSS val: 0.1290542632341385 - Elapsed time: 95.55609774589539 s
INFO:root:  batch 100 loss: 0.1271197659522295
INFO:root:LOSS train' 0.1271197659522295, 360
INFO:root:Epoch: 2 - LOSS train: 0.1271197659522295 LOSS val: 0.11060845851898193 - Elapsed time: 95.73482775688171 s
INFO:root:  batch 100 loss: 0.11405699037015438
INFO:root:LOSS train' 0.11405699037015438, 490
INFO:root:Epoch: 3 - LOSS train: 0.11405699037015438 LOSS val: 0.10219963639974594 - Elapsed time: 95.60326647758484 s
INFO:root:  batch 100 loss: 0.10063697390258312
INFO:root:LOSS train' 0.10063697390258312, 620
INFO:root:Epoch: 4 - LOSS train: 0.10063697390258312 LOSS val: 0.09879235923290253 - Elapsed time: 95.71903562545776 s
INFO:root:  batch 100 loss: 0.09010283753275872
INFO:root:LOSS train' 0.09010283753275872, 750
INFO:root:Epoch: 5 - LOSS train: 0.09010283753275872 LOSS val: 0.08602915704250336 - Elapsed time: 95.68843007087708 s
INFO:root:  batch 100 loss: 0.08360246308147908
INFO:root:LOSS train' 0.08360246308147908, 880
INFO:root:Epoch: 6 - LOSS train: 0.08360246308147908 LOSS val: 0.07394318282604218 - Elapsed time: 95.65669536590576 s
INFO:root:  batch 100 loss: 0.07779639340937138
INFO:root:LOSS train' 0.07779639340937138, 1010
INFO:root:Epoch: 7 - LOSS train: 0.07779639340937138 LOSS val: 0.06991595774888992 - Elapsed time: 95.5782880783081 s
INFO:root:  batch 100 loss: 0.07190692666918039
INFO:root:LOSS train' 0.07190692666918039, 1140
INFO:root:Epoch: 8 - LOSS train: 0.07190692666918039 LOSS val: 0.0707181990146637 - Elapsed time: 95.76281380653381 s
INFO:root:  batch 100 loss: 0.06773604162037372
INFO:root:LOSS train' 0.06773604162037372, 1270
INFO:root:Epoch: 9 - LOSS train: 0.06773604162037372 LOSS val: 0.06544289737939835 - Elapsed time: 95.60283493995667 s
INFO:root:  batch 100 loss: 0.06479136485606432
INFO:root:LOSS train' 0.06479136485606432, 1400
INFO:root:Epoch: 10 - LOSS train: 0.06479136485606432 LOSS val: 0.06150636821985245 - Elapsed time: 95.60029077529907 s
INFO:root:  batch 100 loss: 0.06300570290535688
INFO:root:LOSS train' 0.06300570290535688, 1530
INFO:root:Epoch: 11 - LOSS train: 0.06300570290535688 LOSS val: 0.05800133943557739 - Elapsed time: 95.65744590759277 s
INFO:root:  batch 100 loss: 0.0590365120768547
INFO:root:LOSS train' 0.0590365120768547, 1660
INFO:root:Epoch: 12 - LOSS train: 0.0590365120768547 LOSS val: 0.057324785739183426 - Elapsed time: 95.64145994186401 s
INFO:root:  batch 100 loss: 0.05755275383591652
INFO:root:LOSS train' 0.05755275383591652, 1790
INFO:root:Epoch: 13 - LOSS train: 0.05755275383591652 LOSS val: 0.05211751163005829 - Elapsed time: 95.8358085155487 s
INFO:root:  batch 100 loss: 0.05316523630172014
INFO:root:LOSS train' 0.05316523630172014, 1920
INFO:root:Epoch: 14 - LOSS train: 0.05316523630172014 LOSS val: 0.053657036274671555 - Elapsed time: 95.7899522781372 s
INFO:root:  batch 100 loss: 0.05543695904314518
INFO:root:LOSS train' 0.05543695904314518, 2050
INFO:root:Epoch: 15 - LOSS train: 0.05543695904314518 LOSS val: 0.04805751517415047 - Elapsed time: 95.71310663223267 s
INFO:root:  batch 100 loss: 0.04915095888078213
INFO:root:LOSS train' 0.04915095888078213, 2180
INFO:root:Epoch: 16 - LOSS train: 0.04915095888078213 LOSS val: 0.04805351421236992 - Elapsed time: 95.77493166923523 s
INFO:root:  batch 100 loss: 0.04668724894523621
INFO:root:LOSS train' 0.04668724894523621, 2310
INFO:root:Epoch: 17 - LOSS train: 0.04668724894523621 LOSS val: 0.04848282039165497 - Elapsed time: 95.68020987510681 s
INFO:root:  batch 100 loss: 0.05120194219052791
INFO:root:LOSS train' 0.05120194219052791, 2440
INFO:root:Epoch: 18 - LOSS train: 0.05120194219052791 LOSS val: 0.060946233570575714 - Elapsed time: 95.70667743682861 s
INFO:root:  batch 100 loss: 0.04674947518855333
INFO:root:LOSS train' 0.04674947518855333, 2570
INFO:root:Epoch: 19 - LOSS train: 0.04674947518855333 LOSS val: 0.04459104314446449 - Elapsed time: 95.6810781955719 s
INFO:root:  batch 100 loss: 0.04590302549302578
INFO:root:LOSS train' 0.04590302549302578, 2700
INFO:root:Epoch: 20 - LOSS train: 0.04590302549302578 LOSS val: 0.04245864599943161 - Elapsed time: 95.82849407196045 s
INFO:root:  batch 100 loss: 0.04329639110714197
INFO:root:LOSS train' 0.04329639110714197, 2830
INFO:root:Epoch: 21 - LOSS train: 0.04329639110714197 LOSS val: 0.04357873275876045 - Elapsed time: 95.63568568229675 s
INFO:root:  batch 100 loss: 0.04294585850089788
INFO:root:LOSS train' 0.04294585850089788, 2960
INFO:root:Epoch: 22 - LOSS train: 0.04294585850089788 LOSS val: 0.0401797778904438 - Elapsed time: 95.73756456375122 s
INFO:root:  batch 100 loss: 0.040292502753436564
INFO:root:LOSS train' 0.040292502753436564, 3090
INFO:root:Epoch: 23 - LOSS train: 0.040292502753436564 LOSS val: 0.03828693553805351 - Elapsed time: 95.77429509162903 s
INFO:root:  batch 100 loss: 0.06476251039654017
INFO:root:LOSS train' 0.06476251039654017, 3220
INFO:root:Epoch: 24 - LOSS train: 0.06476251039654017 LOSS val: 0.040571361780166626 - Elapsed time: 95.56967234611511 s
INFO:root:  batch 100 loss: 0.04077454254031181
INFO:root:LOSS train' 0.04077454254031181, 3350
INFO:root:Epoch: 25 - LOSS train: 0.04077454254031181 LOSS val: 0.03826770931482315 - Elapsed time: 95.64000153541565 s
INFO:root:  batch 100 loss: 0.03871944982558489
INFO:root:LOSS train' 0.03871944982558489, 3480
INFO:root:Epoch: 26 - LOSS train: 0.03871944982558489 LOSS val: 0.03717194125056267 - Elapsed time: 95.81137251853943 s
INFO:root:  batch 100 loss: 0.03778116252273321
INFO:root:LOSS train' 0.03778116252273321, 3610
INFO:root:Epoch: 27 - LOSS train: 0.03778116252273321 LOSS val: 0.03808765113353729 - Elapsed time: 95.64540266990662 s
INFO:root:  batch 100 loss: 0.03775209806859493
INFO:root:LOSS train' 0.03775209806859493, 3740
INFO:root:Epoch: 28 - LOSS train: 0.03775209806859493 LOSS val: 0.03817269951105118 - Elapsed time: 95.60961771011353 s
INFO:root:  batch 100 loss: 0.03509701423346996
INFO:root:LOSS train' 0.03509701423346996, 3870
INFO:root:Epoch: 29 - LOSS train: 0.03509701423346996 LOSS val: 0.033567287027835846 - Elapsed time: 95.6648485660553 s
INFO:root:  batch 100 loss: 0.035284809023141864
INFO:root:LOSS train' 0.035284809023141864, 4000
INFO:root:Epoch: 30 - LOSS train: 0.035284809023141864 LOSS val: 0.038362134248018265 - Elapsed time: 95.65691685676575 s
INFO:root:  batch 100 loss: 0.03456468664109707
INFO:root:LOSS train' 0.03456468664109707, 4130
INFO:root:Epoch: 31 - LOSS train: 0.03456468664109707 LOSS val: 0.03616691380739212 - Elapsed time: 95.64953184127808 s
INFO:root:  batch 100 loss: 0.03525557205080986
INFO:root:LOSS train' 0.03525557205080986, 4260
INFO:root:Epoch: 32 - LOSS train: 0.03525557205080986 LOSS val: 0.033655796200037 - Elapsed time: 95.72266221046448 s
INFO:root:  batch 100 loss: 0.032300761062651874
INFO:root:LOSS train' 0.032300761062651874, 4390
INFO:root:Epoch: 33 - LOSS train: 0.032300761062651874 LOSS val: 0.03112718090415001 - Elapsed time: 95.67191004753113 s
INFO:root:  batch 100 loss: 0.03186785245314241
INFO:root:LOSS train' 0.03186785245314241, 4520
INFO:root:Epoch: 34 - LOSS train: 0.03186785245314241 LOSS val: 0.03149791434407234 - Elapsed time: 95.67002177238464 s
INFO:root:  batch 100 loss: 0.031762496754527095
INFO:root:LOSS train' 0.031762496754527095, 4650
INFO:root:Epoch: 35 - LOSS train: 0.031762496754527095 LOSS val: 0.03243577852845192 - Elapsed time: 95.7551519870758 s
INFO:root:  batch 100 loss: 0.03412345780059695
INFO:root:LOSS train' 0.03412345780059695, 4780
INFO:root:Epoch: 36 - LOSS train: 0.03412345780059695 LOSS val: 0.031148122623562813 - Elapsed time: 95.69990611076355 s
INFO:root:  batch 100 loss: 0.0313132756575942
INFO:root:LOSS train' 0.0313132756575942, 4910
INFO:root:Epoch: 37 - LOSS train: 0.0313132756575942 LOSS val: 0.029758678749203682 - Elapsed time: 95.67987298965454 s
INFO:root:  batch 100 loss: 0.032914739251136776
INFO:root:LOSS train' 0.032914739251136776, 5040
INFO:root:Epoch: 38 - LOSS train: 0.032914739251136776 LOSS val: 0.029378842562437057 - Elapsed time: 95.72142148017883 s
INFO:root:  batch 100 loss: 0.0653796985372901
INFO:root:LOSS train' 0.0653796985372901, 5170
INFO:root:Epoch: 39 - LOSS train: 0.0653796985372901 LOSS val: 0.0378119982779026 - Elapsed time: 95.62234234809875 s
INFO:root:*************
INFO:root:             
INFO:root:Starting to test....
INFO:root:             
INFO:root:OneStep loss: 0.02970137447118759
INFO:root:Scalar loss: 0.03882741183042526
INFO:root:Vector loss: 0.025138365104794502
INFO:root:             
INFO:root:Done.

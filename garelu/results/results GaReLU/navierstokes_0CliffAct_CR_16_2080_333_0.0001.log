INFO:root:*************
INFO:root:             
INFO:root:model chosen: CR
INFO:root:multivector activation function?: 0
INFO:root:training trajectories: 2080
INFO:root:training epochs: 200
INFO:root:training batchsize: 16
INFO:root:learning rate: 0.0001
INFO:root:seed: 333
INFO:root:patience: 15
INFO:root:training dataset path: datasets/trainingdataviscous/
INFO:root:test dataset path: datasets/testdataviscous/
INFO:root:             
INFO:root:*************
INFO:root:Using device: cuda
INFO:root:[[[1.6940998  1.5566934  1.3046039  1.0440726 ]
  [1.6066581  1.3995012  1.342347   1.233624  ]
  [1.4666691  1.3354036  1.3883016  1.2737162 ]
  [1.4122795  1.3854291  1.4587754  1.339578  ]]

 [[1.6459564  1.3450366  1.0299298  0.77708894]
  [1.6489182  1.5250436  1.3721011  1.2203181 ]
  [1.4844782  1.3996952  1.3643513  1.3251002 ]
  [1.3969231  1.3963239  1.4048748  1.4067723 ]]]
INFO:root:****
INFO:root:[[[1.6940998  1.5566934  1.3046039  1.0440726 ]
  [1.6066581  1.3995012  1.342347   1.233624  ]
  [1.4666691  1.3354036  1.3883016  1.2737162 ]
  [1.4122795  1.3854291  1.4587754  1.339578  ]]

 [[1.6459564  1.3450366  1.0299298  0.77708894]
  [1.6489182  1.5250436  1.3721011  1.2203181 ]
  [1.4844782  1.3996952  1.3643513  1.3251002 ]
  [1.3969231  1.3963239  1.4048748  1.4067723 ]]]
INFO:root:Train input shape: torch.Size([2080, 2, 128, 128, 3])
INFO:root:Train labels shape: torch.Size([2080, 1, 128, 128, 3])
INFO:root:                   
INFO:root:Val input shape: torch.Size([4680, 2, 128, 128, 3])
INFO:root:Val labels shape: torch.Size([4680, 1, 128, 128, 3])
INFO:root:*************
INFO:root:             
INFO:root:Starting to train....
INFO:root:  batch 100 loss: 0.23700281158089637
INFO:root:LOSS train' 0.23700281158089637, 100
INFO:root:Epoch: 0 - LOSS train: 0.23700281158089637 LOSS val: 0.1527288407087326 - Elapsed time: 96.76113677024841 s
INFO:root:  batch 100 loss: 0.14515773832798004
INFO:root:LOSS train' 0.14515773832798004, 230
INFO:root:Epoch: 1 - LOSS train: 0.14515773832798004 LOSS val: 0.13142889738082886 - Elapsed time: 95.52307343482971 s
INFO:root:  batch 100 loss: 0.12766262397170067
INFO:root:LOSS train' 0.12766262397170067, 360
INFO:root:Epoch: 2 - LOSS train: 0.12766262397170067 LOSS val: 0.10750662535429001 - Elapsed time: 95.70919394493103 s
INFO:root:  batch 100 loss: 0.10988967791199684
INFO:root:LOSS train' 0.10988967791199684, 490
INFO:root:Epoch: 3 - LOSS train: 0.10988967791199684 LOSS val: 0.11099821329116821 - Elapsed time: 95.66708302497864 s
INFO:root:  batch 100 loss: 0.09679066278040409
INFO:root:LOSS train' 0.09679066278040409, 620
INFO:root:Epoch: 4 - LOSS train: 0.09679066278040409 LOSS val: 0.09518007189035416 - Elapsed time: 95.60929918289185 s
INFO:root:  batch 100 loss: 0.08796943090856076
INFO:root:LOSS train' 0.08796943090856076, 750
INFO:root:Epoch: 5 - LOSS train: 0.08796943090856076 LOSS val: 0.07838670164346695 - Elapsed time: 95.63268709182739 s
INFO:root:  batch 100 loss: 0.07981276102364063
INFO:root:LOSS train' 0.07981276102364063, 880
INFO:root:Epoch: 6 - LOSS train: 0.07981276102364063 LOSS val: 0.08141285181045532 - Elapsed time: 95.61687517166138 s
INFO:root:  batch 100 loss: 0.07796584315598011
INFO:root:LOSS train' 0.07796584315598011, 1010
INFO:root:Epoch: 7 - LOSS train: 0.07796584315598011 LOSS val: 0.07047183811664581 - Elapsed time: 95.6008653640747 s
INFO:root:  batch 100 loss: 0.07030952662229538
INFO:root:LOSS train' 0.07030952662229538, 1140
INFO:root:Epoch: 8 - LOSS train: 0.07030952662229538 LOSS val: 0.06929606944322586 - Elapsed time: 95.77214646339417 s
INFO:root:  batch 100 loss: 0.06887681916356087
INFO:root:LOSS train' 0.06887681916356087, 1270
INFO:root:Epoch: 9 - LOSS train: 0.06887681916356087 LOSS val: 0.062136534601449966 - Elapsed time: 95.65629744529724 s
INFO:root:  batch 100 loss: 0.06369032144546509
INFO:root:LOSS train' 0.06369032144546509, 1400
INFO:root:Epoch: 10 - LOSS train: 0.06369032144546509 LOSS val: 0.05897415801882744 - Elapsed time: 95.52961659431458 s
INFO:root:  batch 100 loss: 0.06277424443513155
INFO:root:LOSS train' 0.06277424443513155, 1530
INFO:root:Epoch: 11 - LOSS train: 0.06277424443513155 LOSS val: 0.056724149733781815 - Elapsed time: 95.70265579223633 s
INFO:root:  batch 100 loss: 0.06634167332202195
INFO:root:LOSS train' 0.06634167332202195, 1660
INFO:root:Epoch: 12 - LOSS train: 0.06634167332202195 LOSS val: 0.05492416024208069 - Elapsed time: 95.6896562576294 s
INFO:root:  batch 100 loss: 0.056949092745780944
INFO:root:LOSS train' 0.056949092745780944, 1790
INFO:root:Epoch: 13 - LOSS train: 0.056949092745780944 LOSS val: 0.054802071303129196 - Elapsed time: 95.55940961837769 s
INFO:root:  batch 100 loss: 0.05342359073460102
INFO:root:LOSS train' 0.05342359073460102, 1920
INFO:root:Epoch: 14 - LOSS train: 0.05342359073460102 LOSS val: 0.05491814389824867 - Elapsed time: 95.76349782943726 s
INFO:root:  batch 100 loss: 0.05260269302874804
INFO:root:LOSS train' 0.05260269302874804, 2050
INFO:root:Epoch: 15 - LOSS train: 0.05260269302874804 LOSS val: 0.0511007234454155 - Elapsed time: 95.68516516685486 s
INFO:root:  batch 100 loss: 0.052246497794985775
INFO:root:LOSS train' 0.052246497794985775, 2180
INFO:root:Epoch: 16 - LOSS train: 0.052246497794985775 LOSS val: 0.049657080322504044 - Elapsed time: 95.63853430747986 s
INFO:root:  batch 100 loss: 0.04806923408061266
INFO:root:LOSS train' 0.04806923408061266, 2310
INFO:root:Epoch: 17 - LOSS train: 0.04806923408061266 LOSS val: 0.04507068917155266 - Elapsed time: 95.70152449607849 s
INFO:root:  batch 100 loss: 0.04682095471769571
INFO:root:LOSS train' 0.04682095471769571, 2440
INFO:root:Epoch: 18 - LOSS train: 0.04682095471769571 LOSS val: 0.043845757842063904 - Elapsed time: 95.69967460632324 s
INFO:root:  batch 100 loss: 0.04591571882367134
INFO:root:LOSS train' 0.04591571882367134, 2570
INFO:root:Epoch: 19 - LOSS train: 0.04591571882367134 LOSS val: 0.0442780964076519 - Elapsed time: 95.65437245368958 s
INFO:root:  batch 100 loss: 0.0517901424318552
INFO:root:LOSS train' 0.0517901424318552, 2700
INFO:root:Epoch: 20 - LOSS train: 0.0517901424318552 LOSS val: 0.043952979147434235 - Elapsed time: 95.72329759597778 s
INFO:root:  batch 100 loss: 0.043543267585337164
INFO:root:LOSS train' 0.043543267585337164, 2830
INFO:root:Epoch: 21 - LOSS train: 0.043543267585337164 LOSS val: 0.044017910957336426 - Elapsed time: 95.66372990608215 s
INFO:root:  batch 100 loss: 0.04136726450175047
INFO:root:LOSS train' 0.04136726450175047, 2960
INFO:root:Epoch: 22 - LOSS train: 0.04136726450175047 LOSS val: 0.046704769134521484 - Elapsed time: 95.7531225681305 s
INFO:root:  batch 100 loss: 0.0400149454921484
INFO:root:LOSS train' 0.0400149454921484, 3090
INFO:root:Epoch: 23 - LOSS train: 0.0400149454921484 LOSS val: 0.03936443477869034 - Elapsed time: 95.65371084213257 s
INFO:root:  batch 100 loss: 0.03959460042417049
INFO:root:LOSS train' 0.03959460042417049, 3220
INFO:root:Epoch: 24 - LOSS train: 0.03959460042417049 LOSS val: 0.03913915902376175 - Elapsed time: 95.72804522514343 s
INFO:root:  batch 100 loss: 0.04574896134436131
INFO:root:LOSS train' 0.04574896134436131, 3350
INFO:root:Epoch: 25 - LOSS train: 0.04574896134436131 LOSS val: 0.06301160156726837 - Elapsed time: 95.6164984703064 s
INFO:root:  batch 100 loss: 0.048613681271672246
INFO:root:LOSS train' 0.048613681271672246, 3480
INFO:root:Epoch: 26 - LOSS train: 0.048613681271672246 LOSS val: 0.0445111058652401 - Elapsed time: 95.66343998908997 s
INFO:root:  batch 100 loss: 0.040170899406075475
INFO:root:LOSS train' 0.040170899406075475, 3610
INFO:root:Epoch: 27 - LOSS train: 0.040170899406075475 LOSS val: 0.03783339262008667 - Elapsed time: 95.56399393081665 s
INFO:root:  batch 100 loss: 0.03796182632446289
INFO:root:LOSS train' 0.03796182632446289, 3740
INFO:root:Epoch: 28 - LOSS train: 0.03796182632446289 LOSS val: 0.042690664529800415 - Elapsed time: 95.60045552253723 s
INFO:root:  batch 100 loss: 0.04230578262358904
INFO:root:LOSS train' 0.04230578262358904, 3870
INFO:root:Epoch: 29 - LOSS train: 0.04230578262358904 LOSS val: 0.03518029302358627 - Elapsed time: 95.66682076454163 s
INFO:root:  batch 100 loss: 0.036086333077400924
INFO:root:LOSS train' 0.036086333077400924, 4000
INFO:root:Epoch: 30 - LOSS train: 0.036086333077400924 LOSS val: 0.03408937156200409 - Elapsed time: 95.61866021156311 s
INFO:root:  batch 100 loss: 0.03484318131580949
INFO:root:LOSS train' 0.03484318131580949, 4130
INFO:root:Epoch: 31 - LOSS train: 0.03484318131580949 LOSS val: 0.03510630875825882 - Elapsed time: 95.70893096923828 s
INFO:root:  batch 100 loss: 0.0359892944432795
INFO:root:LOSS train' 0.0359892944432795, 4260
INFO:root:Epoch: 32 - LOSS train: 0.0359892944432795 LOSS val: 0.03806578367948532 - Elapsed time: 95.65045762062073 s
INFO:root:  batch 100 loss: 0.035317470747977496
INFO:root:LOSS train' 0.035317470747977496, 4390
INFO:root:Epoch: 33 - LOSS train: 0.035317470747977496 LOSS val: 0.03181014582514763 - Elapsed time: 95.77220726013184 s
INFO:root:  batch 100 loss: 0.03335297331213951
INFO:root:LOSS train' 0.03335297331213951, 4520
INFO:root:Epoch: 34 - LOSS train: 0.03335297331213951 LOSS val: 0.031705956906080246 - Elapsed time: 95.6064624786377 s
INFO:root:  batch 100 loss: 0.03729675306007266
INFO:root:LOSS train' 0.03729675306007266, 4650
INFO:root:Epoch: 35 - LOSS train: 0.03729675306007266 LOSS val: 0.03267909213900566 - Elapsed time: 95.59408211708069 s
INFO:root:  batch 100 loss: 0.032244257666170596
INFO:root:LOSS train' 0.032244257666170596, 4780
INFO:root:Epoch: 36 - LOSS train: 0.032244257666170596 LOSS val: 0.03230230510234833 - Elapsed time: 95.66697454452515 s
INFO:root:  batch 100 loss: 0.034932567160576584
INFO:root:LOSS train' 0.034932567160576584, 4910
INFO:root:Epoch: 37 - LOSS train: 0.034932567160576584 LOSS val: 0.03103821910917759 - Elapsed time: 95.6485447883606 s
INFO:root:  batch 100 loss: 0.033713621534407136
INFO:root:LOSS train' 0.033713621534407136, 5040
INFO:root:Epoch: 38 - LOSS train: 0.033713621534407136 LOSS val: 0.03142853081226349 - Elapsed time: 95.71523928642273 s
INFO:root:*************
INFO:root:             
INFO:root:Starting to test....
INFO:root:             
INFO:root:OneStep loss: 0.03135566785931587
INFO:root:Scalar loss: 0.04117602854967117
INFO:root:Vector loss: 0.026445496827363968
INFO:root:             
INFO:root:Done.

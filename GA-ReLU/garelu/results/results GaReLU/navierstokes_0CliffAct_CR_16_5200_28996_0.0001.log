INFO:root:*************
INFO:root:             
INFO:root:model chosen: CR
INFO:root:multivector activation function?: 0
INFO:root:training trajectories: 5200
INFO:root:training epochs: 200
INFO:root:training batchsize: 16
INFO:root:learning rate: 0.0001
INFO:root:seed: 28996
INFO:root:patience: 15
INFO:root:training dataset path: datasets/trainingdataviscous/
INFO:root:test dataset path: datasets/testdataviscous/
INFO:root:             
INFO:root:*************
INFO:root:Using device: cuda
INFO:root:[[[1.6940998  1.5566934  1.3046039  1.0440726 ]
  [1.6066581  1.3995012  1.342347   1.233624  ]
  [1.4666691  1.3354036  1.3883016  1.2737162 ]
  [1.4122795  1.3854291  1.4587754  1.339578  ]]

 [[1.6459564  1.3450366  1.0299298  0.77708894]
  [1.6489182  1.5250436  1.3721011  1.2203181 ]
  [1.4844782  1.3996952  1.3643513  1.3251002 ]
  [1.3969231  1.3963239  1.4048748  1.4067723 ]]]
INFO:root:****
INFO:root:[[[1.6940998  1.5566934  1.3046039  1.0440726 ]
  [1.6066581  1.3995012  1.342347   1.233624  ]
  [1.4666691  1.3354036  1.3883016  1.2737162 ]
  [1.4122795  1.3854291  1.4587754  1.339578  ]]

 [[1.6459564  1.3450366  1.0299298  0.77708894]
  [1.6489182  1.5250436  1.3721011  1.2203181 ]
  [1.4844782  1.3996952  1.3643513  1.3251002 ]
  [1.3969231  1.3963239  1.4048748  1.4067723 ]]]
INFO:root:Train input shape: torch.Size([5200, 2, 128, 128, 3])
INFO:root:Train labels shape: torch.Size([5200, 1, 128, 128, 3])
INFO:root:                   
INFO:root:Val input shape: torch.Size([4680, 2, 128, 128, 3])
INFO:root:Val labels shape: torch.Size([4680, 1, 128, 128, 3])
INFO:root:*************
INFO:root:             
INFO:root:Starting to train....
INFO:root:  batch 100 loss: 0.2341619089245796
INFO:root:LOSS train' 0.2341619089245796, 100
INFO:root:  batch 200 loss: 0.1577915979921818
INFO:root:LOSS train' 0.1577915979921818, 200
INFO:root:  batch 300 loss: 0.13259651109576226
INFO:root:LOSS train' 0.13259651109576226, 300
INFO:root:Epoch: 0 - LOSS train: 0.13259651109576226 LOSS val: 0.13483452796936035 - Elapsed time: 155.94998455047607 s
INFO:root:  batch 100 loss: 0.11693248696625233
INFO:root:LOSS train' 0.11693248696625233, 425
INFO:root:  batch 200 loss: 0.11289709642529487
INFO:root:LOSS train' 0.11289709642529487, 525
INFO:root:  batch 300 loss: 0.09920594319701195
INFO:root:LOSS train' 0.09920594319701195, 625
INFO:root:Epoch: 1 - LOSS train: 0.09920594319701195 LOSS val: 0.0873279944062233 - Elapsed time: 154.71452140808105 s
INFO:root:  batch 100 loss: 0.08983213037252426
INFO:root:LOSS train' 0.08983213037252426, 750
INFO:root:  batch 200 loss: 0.08970279730856419
INFO:root:LOSS train' 0.08970279730856419, 850
INFO:root:  batch 300 loss: 0.08070983700454235
INFO:root:LOSS train' 0.08070983700454235, 950
INFO:root:Epoch: 2 - LOSS train: 0.08070983700454235 LOSS val: 0.07925128936767578 - Elapsed time: 155.18061327934265 s
INFO:root:  batch 100 loss: 0.07577246591448784
INFO:root:LOSS train' 0.07577246591448784, 1075
INFO:root:  batch 200 loss: 0.07069746218621731
INFO:root:LOSS train' 0.07069746218621731, 1175
INFO:root:  batch 300 loss: 0.06946716599166393
INFO:root:LOSS train' 0.06946716599166393, 1275
INFO:root:Epoch: 3 - LOSS train: 0.06946716599166393 LOSS val: 0.06964084506034851 - Elapsed time: 154.87354373931885 s
INFO:root:  batch 100 loss: 0.06419248506426811
INFO:root:LOSS train' 0.06419248506426811, 1400
INFO:root:  batch 200 loss: 0.06508914876729249
INFO:root:LOSS train' 0.06508914876729249, 1500
INFO:root:  batch 300 loss: 0.06186682030558586
INFO:root:LOSS train' 0.06186682030558586, 1600
INFO:root:Epoch: 4 - LOSS train: 0.06186682030558586 LOSS val: 0.07280652225017548 - Elapsed time: 155.05746793746948 s
INFO:root:  batch 100 loss: 0.06105061542242765
INFO:root:LOSS train' 0.06105061542242765, 1725
INFO:root:  batch 200 loss: 0.05996175020933151
INFO:root:LOSS train' 0.05996175020933151, 1825
INFO:root:  batch 300 loss: 0.05642295714467764
INFO:root:LOSS train' 0.05642295714467764, 1925
INFO:root:Epoch: 5 - LOSS train: 0.05642295714467764 LOSS val: 0.05379997938871384 - Elapsed time: 155.12494540214539 s
INFO:root:  batch 100 loss: 0.055815887078642844
INFO:root:LOSS train' 0.055815887078642844, 2050
INFO:root:  batch 200 loss: 0.05123439725488424
INFO:root:LOSS train' 0.05123439725488424, 2150
INFO:root:  batch 300 loss: 0.05108852703124285
INFO:root:LOSS train' 0.05108852703124285, 2250
INFO:root:Epoch: 6 - LOSS train: 0.05108852703124285 LOSS val: 0.04775145649909973 - Elapsed time: 155.13407182693481 s
INFO:root:  batch 100 loss: 0.04990909121930599
INFO:root:LOSS train' 0.04990909121930599, 2375
INFO:root:  batch 200 loss: 0.04668385159224272
INFO:root:LOSS train' 0.04668385159224272, 2475
INFO:root:  batch 300 loss: 0.04920307382941246
INFO:root:LOSS train' 0.04920307382941246, 2575
INFO:root:Epoch: 7 - LOSS train: 0.04920307382941246 LOSS val: 0.05107849836349487 - Elapsed time: 155.13468265533447 s
INFO:root:  batch 100 loss: 0.04571167293936014
INFO:root:LOSS train' 0.04571167293936014, 2700
INFO:root:  batch 200 loss: 0.04624556764960289
INFO:root:LOSS train' 0.04624556764960289, 2800
INFO:root:  batch 300 loss: 0.04322086025029421
INFO:root:LOSS train' 0.04322086025029421, 2900
INFO:root:Epoch: 8 - LOSS train: 0.04322086025029421 LOSS val: 0.09576097875833511 - Elapsed time: 155.20049476623535 s
INFO:root:  batch 100 loss: 0.050717583298683165
INFO:root:LOSS train' 0.050717583298683165, 3025
INFO:root:  batch 200 loss: 0.041249153353273865
INFO:root:LOSS train' 0.041249153353273865, 3125
INFO:root:  batch 300 loss: 0.041945533640682695
INFO:root:LOSS train' 0.041945533640682695, 3225
INFO:root:Epoch: 9 - LOSS train: 0.041945533640682695 LOSS val: 0.03803997486829758 - Elapsed time: 155.08836722373962 s
INFO:root:  batch 100 loss: 0.03985340379178524
INFO:root:LOSS train' 0.03985340379178524, 3350
INFO:root:  batch 200 loss: 0.04213648594915867
INFO:root:LOSS train' 0.04213648594915867, 3450
INFO:root:  batch 300 loss: 0.03991737715899944
INFO:root:LOSS train' 0.03991737715899944, 3550
INFO:root:Epoch: 10 - LOSS train: 0.03991737715899944 LOSS val: 0.037006452679634094 - Elapsed time: 155.06147408485413 s
INFO:root:  batch 100 loss: 0.039348686821758745
INFO:root:LOSS train' 0.039348686821758745, 3675
INFO:root:  batch 200 loss: 0.03740177534520626
INFO:root:LOSS train' 0.03740177534520626, 3775
INFO:root:  batch 300 loss: 0.0361902342364192
INFO:root:LOSS train' 0.0361902342364192, 3875
INFO:root:Epoch: 11 - LOSS train: 0.0361902342364192 LOSS val: 0.03388604149222374 - Elapsed time: 155.0614504814148 s
INFO:root:  batch 100 loss: 0.03900068575516343
INFO:root:LOSS train' 0.03900068575516343, 4000
INFO:root:  batch 200 loss: 0.03640675602480769
INFO:root:LOSS train' 0.03640675602480769, 4100
INFO:root:  batch 300 loss: 0.037791756298393014
INFO:root:LOSS train' 0.037791756298393014, 4200
INFO:root:Epoch: 12 - LOSS train: 0.037791756298393014 LOSS val: 0.03319991007447243 - Elapsed time: 155.22992396354675 s
INFO:root:  batch 100 loss: 0.03689616030082107
INFO:root:LOSS train' 0.03689616030082107, 4325
INFO:root:  batch 200 loss: 0.041445549856871364
INFO:root:LOSS train' 0.041445549856871364, 4425
INFO:root:  batch 300 loss: 0.03607467329129577
INFO:root:LOSS train' 0.03607467329129577, 4525
INFO:root:Epoch: 13 - LOSS train: 0.03607467329129577 LOSS val: 0.032346561551094055 - Elapsed time: 154.9984691143036 s
INFO:root:  batch 100 loss: 0.03373274454846978
INFO:root:LOSS train' 0.03373274454846978, 4650
INFO:root:  batch 200 loss: 0.03209147159010172
INFO:root:LOSS train' 0.03209147159010172, 4750
INFO:root:  batch 300 loss: 0.03160491986200213
INFO:root:LOSS train' 0.03160491986200213, 4850
INFO:root:Epoch: 14 - LOSS train: 0.03160491986200213 LOSS val: 0.03379224240779877 - Elapsed time: 155.2021129131317 s
INFO:root:  batch 100 loss: 0.031561627853661775
INFO:root:LOSS train' 0.031561627853661775, 4975
INFO:root:  batch 200 loss: 0.031017171666026116
INFO:root:LOSS train' 0.031017171666026116, 5075
INFO:root:  batch 300 loss: 0.031749069970101115
INFO:root:LOSS train' 0.031749069970101115, 5175
INFO:root:Epoch: 15 - LOSS train: 0.031749069970101115 LOSS val: 0.02989737130701542 - Elapsed time: 155.03128719329834 s
INFO:root:  batch 100 loss: 0.030898123905062677
INFO:root:LOSS train' 0.030898123905062677, 5300
INFO:root:  batch 200 loss: 0.030288045480847358
INFO:root:LOSS train' 0.030288045480847358, 5400
INFO:root:  batch 300 loss: 0.03688488619402051
INFO:root:LOSS train' 0.03688488619402051, 5500
INFO:root:Epoch: 16 - LOSS train: 0.03688488619402051 LOSS val: 0.04292328655719757 - Elapsed time: 155.10521149635315 s
INFO:root:  batch 100 loss: 0.035197249799966815
INFO:root:LOSS train' 0.035197249799966815, 5625
INFO:root:  batch 200 loss: 0.030736954417079687
INFO:root:LOSS train' 0.030736954417079687, 5725
INFO:root:  batch 300 loss: 0.04414807116612792
INFO:root:LOSS train' 0.04414807116612792, 5825
INFO:root:Epoch: 17 - LOSS train: 0.04414807116612792 LOSS val: 0.042713869363069534 - Elapsed time: 154.7960398197174 s
INFO:root:  batch 100 loss: 0.03503109121695161
INFO:root:LOSS train' 0.03503109121695161, 5950
INFO:root:  batch 200 loss: 0.031332460343837736
INFO:root:LOSS train' 0.031332460343837736, 6050
INFO:root:  batch 300 loss: 0.029846429359167814
INFO:root:LOSS train' 0.029846429359167814, 6150
INFO:root:Epoch: 18 - LOSS train: 0.029846429359167814 LOSS val: 0.027523096650838852 - Elapsed time: 154.9617087841034 s
INFO:root:  batch 100 loss: 0.02825883775949478
INFO:root:LOSS train' 0.02825883775949478, 6275
INFO:root:  batch 200 loss: 0.028989446703344583
INFO:root:LOSS train' 0.028989446703344583, 6375
INFO:root:  batch 300 loss: 0.028207120262086393
INFO:root:LOSS train' 0.028207120262086393, 6475
INFO:root:Epoch: 19 - LOSS train: 0.028207120262086393 LOSS val: 0.029426544904708862 - Elapsed time: 154.78571033477783 s
INFO:root:  batch 100 loss: 0.027305067777633668
INFO:root:LOSS train' 0.027305067777633668, 6600
INFO:root:  batch 200 loss: 0.031118414476513864
INFO:root:LOSS train' 0.031118414476513864, 6700
INFO:root:  batch 300 loss: 0.02633915275335312
INFO:root:LOSS train' 0.02633915275335312, 6800
INFO:root:Epoch: 20 - LOSS train: 0.02633915275335312 LOSS val: 0.026959342882037163 - Elapsed time: 154.9920814037323 s
INFO:root:  batch 100 loss: 0.0334866376966238
INFO:root:LOSS train' 0.0334866376966238, 6925
INFO:root:  batch 200 loss: 0.028798169232904913
INFO:root:LOSS train' 0.028798169232904913, 7025
INFO:root:  batch 300 loss: 0.026975548770278693
INFO:root:LOSS train' 0.026975548770278693, 7125
INFO:root:Epoch: 21 - LOSS train: 0.026975548770278693 LOSS val: 0.02549232356250286 - Elapsed time: 155.2151129245758 s
INFO:root:  batch 100 loss: 0.02588753255084157
INFO:root:LOSS train' 0.02588753255084157, 7250
INFO:root:  batch 200 loss: 0.02561623591929674
INFO:root:LOSS train' 0.02561623591929674, 7350
INFO:root:  batch 300 loss: 0.02587278887629509
INFO:root:LOSS train' 0.02587278887629509, 7450
INFO:root:Epoch: 22 - LOSS train: 0.02587278887629509 LOSS val: 0.024423589929938316 - Elapsed time: 155.1211347579956 s
INFO:root:  batch 100 loss: 0.024760335963219405
INFO:root:LOSS train' 0.024760335963219405, 7575
INFO:root:  batch 200 loss: 0.02815671429038048
INFO:root:LOSS train' 0.02815671429038048, 7675
INFO:root:  batch 300 loss: 0.02480644917115569
INFO:root:LOSS train' 0.02480644917115569, 7775
INFO:root:Epoch: 23 - LOSS train: 0.02480644917115569 LOSS val: 0.023912101984024048 - Elapsed time: 154.8882396221161 s
INFO:root:  batch 100 loss: 0.024945604670792817
INFO:root:LOSS train' 0.024945604670792817, 7900
INFO:root:  batch 200 loss: 0.02403875544667244
INFO:root:LOSS train' 0.02403875544667244, 8000
INFO:root:  batch 300 loss: 0.026243244744837285
INFO:root:LOSS train' 0.026243244744837285, 8100
INFO:root:Epoch: 24 - LOSS train: 0.026243244744837285 LOSS val: 0.024371089413762093 - Elapsed time: 155.1702914237976 s
INFO:root:  batch 100 loss: 0.02676472606137395
INFO:root:LOSS train' 0.02676472606137395, 8225
INFO:root:  batch 200 loss: 0.023946272693574428
INFO:root:LOSS train' 0.023946272693574428, 8325
INFO:root:  batch 300 loss: 0.023326465897262096
INFO:root:LOSS train' 0.023326465897262096, 8425
INFO:root:Epoch: 25 - LOSS train: 0.023326465897262096 LOSS val: 0.03873073309659958 - Elapsed time: 155.0413522720337 s
INFO:root:  batch 100 loss: 0.02628533972427249
INFO:root:LOSS train' 0.02628533972427249, 8550
INFO:root:  batch 200 loss: 0.022751978524029257
INFO:root:LOSS train' 0.022751978524029257, 8650
INFO:root:  batch 300 loss: 0.023133904859423637
INFO:root:LOSS train' 0.023133904859423637, 8750
INFO:root:Epoch: 26 - LOSS train: 0.023133904859423637 LOSS val: 0.0305336881428957 - Elapsed time: 155.32148933410645 s
INFO:root:  batch 100 loss: 0.023859580121934412
INFO:root:LOSS train' 0.023859580121934412, 8875
INFO:root:  batch 200 loss: 0.041933676786720754
INFO:root:LOSS train' 0.041933676786720754, 8975
INFO:root:  batch 300 loss: 0.027065149694681167
INFO:root:LOSS train' 0.027065149694681167, 9075
INFO:root:Epoch: 27 - LOSS train: 0.027065149694681167 LOSS val: 0.023193152621388435 - Elapsed time: 154.98270344734192 s
INFO:root:  batch 100 loss: 0.023302046563476324
INFO:root:LOSS train' 0.023302046563476324, 9200
INFO:root:  batch 200 loss: 0.023183201532810928
INFO:root:LOSS train' 0.023183201532810928, 9300
INFO:root:  batch 300 loss: 0.023261239249259234
INFO:root:LOSS train' 0.023261239249259234, 9400
INFO:root:Epoch: 28 - LOSS train: 0.023261239249259234 LOSS val: 0.022841015830636024 - Elapsed time: 155.0360791683197 s
INFO:root:  batch 100 loss: 0.022058006543666124
INFO:root:LOSS train' 0.022058006543666124, 9525
INFO:root:  batch 200 loss: 0.022309848964214327
INFO:root:LOSS train' 0.022309848964214327, 9625
INFO:root:  batch 300 loss: 0.021539219208061695
INFO:root:LOSS train' 0.021539219208061695, 9725
INFO:root:Epoch: 29 - LOSS train: 0.021539219208061695 LOSS val: 0.020535703748464584 - Elapsed time: 155.07969427108765 s
INFO:root:  batch 100 loss: 0.023582004103809596
INFO:root:LOSS train' 0.023582004103809596, 9850
INFO:root:  batch 200 loss: 0.021652165986597537
INFO:root:LOSS train' 0.021652165986597537, 9950
INFO:root:  batch 300 loss: 0.02136172603815794
INFO:root:LOSS train' 0.02136172603815794, 10050
INFO:root:Epoch: 30 - LOSS train: 0.02136172603815794 LOSS val: 0.020474212244153023 - Elapsed time: 155.1902210712433 s
INFO:root:  batch 100 loss: 0.02117309682071209
INFO:root:LOSS train' 0.02117309682071209, 10175
INFO:root:  batch 200 loss: 0.021718670688569544
INFO:root:LOSS train' 0.021718670688569544, 10275
INFO:root:  batch 300 loss: 0.023505616281181575
INFO:root:LOSS train' 0.023505616281181575, 10375
INFO:root:Epoch: 31 - LOSS train: 0.023505616281181575 LOSS val: 0.020644571632146835 - Elapsed time: 154.97927260398865 s
INFO:root:  batch 100 loss: 0.02401183992624283
INFO:root:LOSS train' 0.02401183992624283, 10500
INFO:root:  batch 200 loss: 0.032687269560992716
INFO:root:LOSS train' 0.032687269560992716, 10600
INFO:root:  batch 300 loss: 0.022721140645444393
INFO:root:LOSS train' 0.022721140645444393, 10700
INFO:root:Epoch: 32 - LOSS train: 0.022721140645444393 LOSS val: 0.021364910528063774 - Elapsed time: 155.105122089386 s
INFO:root:  batch 100 loss: 0.02127326788380742
INFO:root:LOSS train' 0.02127326788380742, 10825
INFO:root:  batch 200 loss: 0.025248106680810452
INFO:root:LOSS train' 0.025248106680810452, 10925
INFO:root:  batch 300 loss: 0.0331201202981174
INFO:root:LOSS train' 0.0331201202981174, 11025
INFO:root:Epoch: 33 - LOSS train: 0.0331201202981174 LOSS val: 0.02249513380229473 - Elapsed time: 154.95090198516846 s
INFO:root:  batch 100 loss: 0.02117975236847997
INFO:root:LOSS train' 0.02117975236847997, 11150
INFO:root:  batch 200 loss: 0.020768753942102192
INFO:root:LOSS train' 0.020768753942102192, 11250
INFO:root:  batch 300 loss: 0.02045176539570093
INFO:root:LOSS train' 0.02045176539570093, 11350
INFO:root:Epoch: 34 - LOSS train: 0.02045176539570093 LOSS val: 0.020129526033997536 - Elapsed time: 154.85730814933777 s
INFO:root:  batch 100 loss: 0.020313809588551522
INFO:root:LOSS train' 0.020313809588551522, 11475
INFO:root:  batch 200 loss: 0.01983093351125717
INFO:root:LOSS train' 0.01983093351125717, 11575
INFO:root:  batch 300 loss: 0.0200115099363029
INFO:root:LOSS train' 0.0200115099363029, 11675
INFO:root:Epoch: 35 - LOSS train: 0.0200115099363029 LOSS val: 0.019514013081789017 - Elapsed time: 154.9736680984497 s
INFO:root:  batch 100 loss: 0.019402999132871628
INFO:root:LOSS train' 0.019402999132871628, 11800
INFO:root:  batch 200 loss: 0.01968842826783657
INFO:root:LOSS train' 0.01968842826783657, 11900
INFO:root:  batch 300 loss: 0.019425193350762128
INFO:root:LOSS train' 0.019425193350762128, 12000
INFO:root:Epoch: 36 - LOSS train: 0.019425193350762128 LOSS val: 0.018545420840382576 - Elapsed time: 155.01265716552734 s
INFO:root:  batch 100 loss: 0.01890603480860591
INFO:root:LOSS train' 0.01890603480860591, 12125
INFO:root:  batch 200 loss: 0.01915950458496809
INFO:root:LOSS train' 0.01915950458496809, 12225
INFO:root:  batch 300 loss: 0.019289839733392
INFO:root:LOSS train' 0.019289839733392, 12325
INFO:root:Epoch: 37 - LOSS train: 0.019289839733392 LOSS val: 0.021691840142011642 - Elapsed time: 155.13717365264893 s
INFO:root:  batch 100 loss: 0.01907134854234755
INFO:root:LOSS train' 0.01907134854234755, 12450
INFO:root:  batch 200 loss: 0.018942066431045533
INFO:root:LOSS train' 0.018942066431045533, 12550
INFO:root:  batch 300 loss: 0.01893987426534295
INFO:root:LOSS train' 0.01893987426534295, 12650
INFO:root:Epoch: 38 - LOSS train: 0.01893987426534295 LOSS val: 0.019128842279314995 - Elapsed time: 155.1413552761078 s
INFO:root:*************
INFO:root:             
INFO:root:Starting to test....
INFO:root:             
INFO:root:OneStep loss: 0.01882418803870678
INFO:root:Scalar loss: 0.025446556508541107
INFO:root:Vector loss: 0.015513009391725063
INFO:root:             
INFO:root:Done.

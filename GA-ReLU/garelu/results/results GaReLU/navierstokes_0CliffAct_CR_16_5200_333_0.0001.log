INFO:root:*************
INFO:root:             
INFO:root:model chosen: CR
INFO:root:multivector activation function?: 0
INFO:root:training trajectories: 5200
INFO:root:training epochs: 200
INFO:root:training batchsize: 16
INFO:root:learning rate: 0.0001
INFO:root:seed: 333
INFO:root:patience: 15
INFO:root:training dataset path: datasets/trainingdataviscous/
INFO:root:test dataset path: datasets/testdataviscous/
INFO:root:             
INFO:root:*************
INFO:root:Using device: cuda
INFO:root:[[[1.6940998  1.5566934  1.3046039  1.0440726 ]
  [1.6066581  1.3995012  1.342347   1.233624  ]
  [1.4666691  1.3354036  1.3883016  1.2737162 ]
  [1.4122795  1.3854291  1.4587754  1.339578  ]]

 [[1.6459564  1.3450366  1.0299298  0.77708894]
  [1.6489182  1.5250436  1.3721011  1.2203181 ]
  [1.4844782  1.3996952  1.3643513  1.3251002 ]
  [1.3969231  1.3963239  1.4048748  1.4067723 ]]]
INFO:root:****
INFO:root:[[[1.6940998  1.5566934  1.3046039  1.0440726 ]
  [1.6066581  1.3995012  1.342347   1.233624  ]
  [1.4666691  1.3354036  1.3883016  1.2737162 ]
  [1.4122795  1.3854291  1.4587754  1.339578  ]]

 [[1.6459564  1.3450366  1.0299298  0.77708894]
  [1.6489182  1.5250436  1.3721011  1.2203181 ]
  [1.4844782  1.3996952  1.3643513  1.3251002 ]
  [1.3969231  1.3963239  1.4048748  1.4067723 ]]]
INFO:root:Train input shape: torch.Size([5200, 2, 128, 128, 3])
INFO:root:Train labels shape: torch.Size([5200, 1, 128, 128, 3])
INFO:root:                   
INFO:root:Val input shape: torch.Size([4680, 2, 128, 128, 3])
INFO:root:Val labels shape: torch.Size([4680, 1, 128, 128, 3])
INFO:root:*************
INFO:root:             
INFO:root:Starting to train....
INFO:root:  batch 100 loss: 0.2334483651816845
INFO:root:LOSS train' 0.2334483651816845, 100
INFO:root:  batch 200 loss: 0.1552969914674759
INFO:root:LOSS train' 0.1552969914674759, 200
INFO:root:  batch 300 loss: 0.13265957973897458
INFO:root:LOSS train' 0.13265957973897458, 300
INFO:root:Epoch: 0 - LOSS train: 0.13265957973897458 LOSS val: 0.11474882066249847 - Elapsed time: 155.90576696395874 s
INFO:root:  batch 100 loss: 0.1139719807356596
INFO:root:LOSS train' 0.1139719807356596, 425
INFO:root:  batch 200 loss: 0.11193797446787357
INFO:root:LOSS train' 0.11193797446787357, 525
INFO:root:  batch 300 loss: 0.10068361595273018
INFO:root:LOSS train' 0.10068361595273018, 625
INFO:root:Epoch: 1 - LOSS train: 0.10068361595273018 LOSS val: 0.10249815136194229 - Elapsed time: 154.71623849868774 s
INFO:root:  batch 100 loss: 0.09294486865401268
INFO:root:LOSS train' 0.09294486865401268, 750
INFO:root:  batch 200 loss: 0.08410819612443447
INFO:root:LOSS train' 0.08410819612443447, 850
INFO:root:  batch 300 loss: 0.07981003016233444
INFO:root:LOSS train' 0.07981003016233444, 950
INFO:root:Epoch: 2 - LOSS train: 0.07981003016233444 LOSS val: 0.08252830803394318 - Elapsed time: 155.02172422409058 s
INFO:root:  batch 100 loss: 0.07774843193590641
INFO:root:LOSS train' 0.07774843193590641, 1075
INFO:root:  batch 200 loss: 0.07465828247368336
INFO:root:LOSS train' 0.07465828247368336, 1175
INFO:root:  batch 300 loss: 0.06841167263686657
INFO:root:LOSS train' 0.06841167263686657, 1275
INFO:root:Epoch: 3 - LOSS train: 0.06841167263686657 LOSS val: 0.06279662996530533 - Elapsed time: 154.85497498512268 s
INFO:root:  batch 100 loss: 0.07268796436488628
INFO:root:LOSS train' 0.07268796436488628, 1400
INFO:root:  batch 200 loss: 0.0630253878608346
INFO:root:LOSS train' 0.0630253878608346, 1500
INFO:root:  batch 300 loss: 0.061746325120329855
INFO:root:LOSS train' 0.061746325120329855, 1600
INFO:root:Epoch: 4 - LOSS train: 0.061746325120329855 LOSS val: 0.058418359607458115 - Elapsed time: 154.78371167182922 s
INFO:root:  batch 100 loss: 0.05820607952773571
INFO:root:LOSS train' 0.05820607952773571, 1725
INFO:root:  batch 200 loss: 0.05495117262005806
INFO:root:LOSS train' 0.05495117262005806, 1825
INFO:root:  batch 300 loss: 0.05500191703438759
INFO:root:LOSS train' 0.05500191703438759, 1925
INFO:root:Epoch: 5 - LOSS train: 0.05500191703438759 LOSS val: 0.053740061819553375 - Elapsed time: 154.8519253730774 s
INFO:root:  batch 100 loss: 0.05292785033583641
INFO:root:LOSS train' 0.05292785033583641, 2050
INFO:root:  batch 200 loss: 0.05173096481710673
INFO:root:LOSS train' 0.05173096481710673, 2150
INFO:root:  batch 300 loss: 0.05153394680470228
INFO:root:LOSS train' 0.05153394680470228, 2250
INFO:root:Epoch: 6 - LOSS train: 0.05153394680470228 LOSS val: 0.04678133502602577 - Elapsed time: 154.94435358047485 s
INFO:root:  batch 100 loss: 0.04631242662668228
INFO:root:LOSS train' 0.04631242662668228, 2375
INFO:root:  batch 200 loss: 0.046928111910820004
INFO:root:LOSS train' 0.046928111910820004, 2475
INFO:root:  batch 300 loss: 0.0459133231267333
INFO:root:LOSS train' 0.0459133231267333, 2575
INFO:root:Epoch: 7 - LOSS train: 0.0459133231267333 LOSS val: 0.04226355999708176 - Elapsed time: 155.02068758010864 s
INFO:root:  batch 100 loss: 0.04372760768979788
INFO:root:LOSS train' 0.04372760768979788, 2700
INFO:root:  batch 200 loss: 0.04434337735176087
INFO:root:LOSS train' 0.04434337735176087, 2800
INFO:root:  batch 300 loss: 0.042169728837907317
INFO:root:LOSS train' 0.042169728837907317, 2900
INFO:root:Epoch: 8 - LOSS train: 0.042169728837907317 LOSS val: 0.04054933786392212 - Elapsed time: 155.02359437942505 s
INFO:root:  batch 100 loss: 0.0426413194835186
INFO:root:LOSS train' 0.0426413194835186, 3025
INFO:root:  batch 200 loss: 0.0887362564355135
INFO:root:LOSS train' 0.0887362564355135, 3125
INFO:root:  batch 300 loss: 0.06543236490339041
INFO:root:LOSS train' 0.06543236490339041, 3225
INFO:root:Epoch: 9 - LOSS train: 0.06543236490339041 LOSS val: 0.05336981639266014 - Elapsed time: 154.66056871414185 s
INFO:root:  batch 100 loss: 0.05009779367595911
INFO:root:LOSS train' 0.05009779367595911, 3350
INFO:root:  batch 200 loss: 0.04451109703630209
INFO:root:LOSS train' 0.04451109703630209, 3450
INFO:root:  batch 300 loss: 0.04428373139351607
INFO:root:LOSS train' 0.04428373139351607, 3550
INFO:root:Epoch: 10 - LOSS train: 0.04428373139351607 LOSS val: 0.0400811992585659 - Elapsed time: 154.76856684684753 s
INFO:root:  batch 100 loss: 0.03954817276448011
INFO:root:LOSS train' 0.03954817276448011, 3675
INFO:root:  batch 200 loss: 0.040358114056289196
INFO:root:LOSS train' 0.040358114056289196, 3775
INFO:root:  batch 300 loss: 0.0405131546407938
INFO:root:LOSS train' 0.0405131546407938, 3875
INFO:root:Epoch: 11 - LOSS train: 0.0405131546407938 LOSS val: 0.035924267023801804 - Elapsed time: 155.01235842704773 s
INFO:root:  batch 100 loss: 0.03734234005212784
INFO:root:LOSS train' 0.03734234005212784, 4000
INFO:root:  batch 200 loss: 0.03790520131587982
INFO:root:LOSS train' 0.03790520131587982, 4100
INFO:root:  batch 300 loss: 0.03697289023548365
INFO:root:LOSS train' 0.03697289023548365, 4200
INFO:root:Epoch: 12 - LOSS train: 0.03697289023548365 LOSS val: 0.034227605909109116 - Elapsed time: 154.93375205993652 s
INFO:root:  batch 100 loss: 0.035462902933359144
INFO:root:LOSS train' 0.035462902933359144, 4325
INFO:root:  batch 200 loss: 0.0341494257748127
INFO:root:LOSS train' 0.0341494257748127, 4425
INFO:root:  batch 300 loss: 0.0357999188452959
INFO:root:LOSS train' 0.0357999188452959, 4525
INFO:root:Epoch: 13 - LOSS train: 0.0357999188452959 LOSS val: 0.03585488721728325 - Elapsed time: 154.8123219013214 s
INFO:root:  batch 100 loss: 0.03370614754036069
INFO:root:LOSS train' 0.03370614754036069, 4650
INFO:root:  batch 200 loss: 0.03369638204574585
INFO:root:LOSS train' 0.03369638204574585, 4750
INFO:root:  batch 300 loss: 0.033575421255081894
INFO:root:LOSS train' 0.033575421255081894, 4850
INFO:root:Epoch: 14 - LOSS train: 0.033575421255081894 LOSS val: 0.03151362016797066 - Elapsed time: 154.80586123466492 s
INFO:root:  batch 100 loss: 0.032687955722212794
INFO:root:LOSS train' 0.032687955722212794, 4975
INFO:root:  batch 200 loss: 0.03331323837861419
INFO:root:LOSS train' 0.03331323837861419, 5075
INFO:root:  batch 300 loss: 0.031996387001127
INFO:root:LOSS train' 0.031996387001127, 5175
INFO:root:Epoch: 15 - LOSS train: 0.031996387001127 LOSS val: 0.0728372260928154 - Elapsed time: 154.83560609817505 s
INFO:root:  batch 100 loss: 0.04824058346450329
INFO:root:LOSS train' 0.04824058346450329, 5300
INFO:root:  batch 200 loss: 0.035226666666567326
INFO:root:LOSS train' 0.035226666666567326, 5400
INFO:root:  batch 300 loss: 0.03353605510666966
INFO:root:LOSS train' 0.03353605510666966, 5500
INFO:root:Epoch: 16 - LOSS train: 0.03353605510666966 LOSS val: 0.046850115060806274 - Elapsed time: 155.0221221446991 s
INFO:root:  batch 100 loss: 0.03385511919856071
INFO:root:LOSS train' 0.03385511919856071, 5625
INFO:root:  batch 200 loss: 0.031379467248916625
INFO:root:LOSS train' 0.031379467248916625, 5725
INFO:root:  batch 300 loss: 0.03029092274606228
INFO:root:LOSS train' 0.03029092274606228, 5825
INFO:root:Epoch: 17 - LOSS train: 0.03029092274606228 LOSS val: 0.02882738783955574 - Elapsed time: 155.014741897583 s
INFO:root:  batch 100 loss: 0.029228247329592706
INFO:root:LOSS train' 0.029228247329592706, 5950
INFO:root:  batch 200 loss: 0.02959364902228117
INFO:root:LOSS train' 0.02959364902228117, 6050
INFO:root:  batch 300 loss: 0.030193125046789646
INFO:root:LOSS train' 0.030193125046789646, 6150
INFO:root:Epoch: 18 - LOSS train: 0.030193125046789646 LOSS val: 0.027314897626638412 - Elapsed time: 155.18884253501892 s
INFO:root:  batch 100 loss: 0.02895300978794694
INFO:root:LOSS train' 0.02895300978794694, 6275
INFO:root:  batch 200 loss: 0.031813537031412126
INFO:root:LOSS train' 0.031813537031412126, 6375
INFO:root:  batch 300 loss: 0.02886138442903757
INFO:root:LOSS train' 0.02886138442903757, 6475
INFO:root:Epoch: 19 - LOSS train: 0.02886138442903757 LOSS val: 0.02692771516740322 - Elapsed time: 154.8153395652771 s
INFO:root:  batch 100 loss: 0.028594853784888984
INFO:root:LOSS train' 0.028594853784888984, 6600
INFO:root:  batch 200 loss: 0.029820674769580363
INFO:root:LOSS train' 0.029820674769580363, 6700
INFO:root:  batch 300 loss: 0.026852460484951733
INFO:root:LOSS train' 0.026852460484951733, 6800
INFO:root:Epoch: 20 - LOSS train: 0.026852460484951733 LOSS val: 0.02556547522544861 - Elapsed time: 154.93756008148193 s
INFO:root:  batch 100 loss: 0.02616855138912797
INFO:root:LOSS train' 0.02616855138912797, 6925
INFO:root:  batch 200 loss: 0.026487296279519797
INFO:root:LOSS train' 0.026487296279519797, 7025
INFO:root:  batch 300 loss: 0.029841189607977867
INFO:root:LOSS train' 0.029841189607977867, 7125
INFO:root:Epoch: 21 - LOSS train: 0.029841189607977867 LOSS val: 0.02610136941075325 - Elapsed time: 154.84260368347168 s
INFO:root:  batch 100 loss: 0.026095278710126877
INFO:root:LOSS train' 0.026095278710126877, 7250
INFO:root:  batch 200 loss: 0.041159412879496815
INFO:root:LOSS train' 0.041159412879496815, 7350
INFO:root:  batch 300 loss: 0.028214457780122756
INFO:root:LOSS train' 0.028214457780122756, 7450
INFO:root:Epoch: 22 - LOSS train: 0.028214457780122756 LOSS val: 0.027062736451625824 - Elapsed time: 154.9248824119568 s
INFO:root:  batch 100 loss: 0.028168200496584177
INFO:root:LOSS train' 0.028168200496584177, 7575
INFO:root:  batch 200 loss: 0.0254283239133656
INFO:root:LOSS train' 0.0254283239133656, 7675
INFO:root:  batch 300 loss: 0.025374236945062877
INFO:root:LOSS train' 0.025374236945062877, 7775
INFO:root:Epoch: 23 - LOSS train: 0.025374236945062877 LOSS val: 0.023783599957823753 - Elapsed time: 154.91306519508362 s
INFO:root:  batch 100 loss: 0.03448716046288609
INFO:root:LOSS train' 0.03448716046288609, 7900
INFO:root:  batch 200 loss: 0.03602640986442566
INFO:root:LOSS train' 0.03602640986442566, 8000
INFO:root:  batch 300 loss: 0.026763441637158394
INFO:root:LOSS train' 0.026763441637158394, 8100
INFO:root:Epoch: 24 - LOSS train: 0.026763441637158394 LOSS val: 0.0282064788043499 - Elapsed time: 154.94663977622986 s
INFO:root:  batch 100 loss: 0.025378875769674777
INFO:root:LOSS train' 0.025378875769674777, 8225
INFO:root:  batch 200 loss: 0.024614718575030566
INFO:root:LOSS train' 0.024614718575030566, 8325
INFO:root:  batch 300 loss: 0.02416326068341732
INFO:root:LOSS train' 0.02416326068341732, 8425
INFO:root:Epoch: 25 - LOSS train: 0.02416326068341732 LOSS val: 0.023197311908006668 - Elapsed time: 154.98911547660828 s
INFO:root:  batch 100 loss: 0.024035102464258672
INFO:root:LOSS train' 0.024035102464258672, 8550
INFO:root:  batch 200 loss: 0.03161424031481147
INFO:root:LOSS train' 0.03161424031481147, 8650
INFO:root:  batch 300 loss: 0.023825903069227935
INFO:root:LOSS train' 0.023825903069227935, 8750
INFO:root:Epoch: 26 - LOSS train: 0.023825903069227935 LOSS val: 0.024475818499922752 - Elapsed time: 154.8437535762787 s
INFO:root:  batch 100 loss: 0.024092276580631733
INFO:root:LOSS train' 0.024092276580631733, 8875
INFO:root:  batch 200 loss: 0.023857859037816523
INFO:root:LOSS train' 0.023857859037816523, 8975
INFO:root:  batch 300 loss: 0.022958003245294095
INFO:root:LOSS train' 0.022958003245294095, 9075
INFO:root:Epoch: 27 - LOSS train: 0.022958003245294095 LOSS val: 0.02213866077363491 - Elapsed time: 154.85166382789612 s
INFO:root:  batch 100 loss: 0.022725877929478885
INFO:root:LOSS train' 0.022725877929478885, 9200
INFO:root:  batch 200 loss: 0.02267675466835499
INFO:root:LOSS train' 0.02267675466835499, 9300
INFO:root:  batch 300 loss: 0.02200013916939497
INFO:root:LOSS train' 0.02200013916939497, 9400
INFO:root:Epoch: 28 - LOSS train: 0.02200013916939497 LOSS val: 0.021460769698023796 - Elapsed time: 154.6820845603943 s
INFO:root:  batch 100 loss: 0.028484464231878517
INFO:root:LOSS train' 0.028484464231878517, 9525
INFO:root:  batch 200 loss: 0.02225676564499736
INFO:root:LOSS train' 0.02225676564499736, 9625
INFO:root:  batch 300 loss: 0.021899265106767415
INFO:root:LOSS train' 0.021899265106767415, 9725
INFO:root:Epoch: 29 - LOSS train: 0.021899265106767415 LOSS val: 0.021139947697520256 - Elapsed time: 154.86739778518677 s
INFO:root:  batch 100 loss: 0.026670603919774293
INFO:root:LOSS train' 0.026670603919774293, 9850
INFO:root:  batch 200 loss: 0.025033023469150067
INFO:root:LOSS train' 0.025033023469150067, 9950
INFO:root:  batch 300 loss: 0.024505239091813565
INFO:root:LOSS train' 0.024505239091813565, 10050
INFO:root:Epoch: 30 - LOSS train: 0.024505239091813565 LOSS val: 0.021387331187725067 - Elapsed time: 154.91783165931702 s
INFO:root:  batch 100 loss: 0.0212365179695189
INFO:root:LOSS train' 0.0212365179695189, 10175
INFO:root:  batch 200 loss: 0.02145732766017318
INFO:root:LOSS train' 0.02145732766017318, 10275
INFO:root:  batch 300 loss: 0.020995495822280646
INFO:root:LOSS train' 0.020995495822280646, 10375
INFO:root:Epoch: 31 - LOSS train: 0.020995495822280646 LOSS val: 0.02790343202650547 - Elapsed time: 154.83978366851807 s
INFO:root:  batch 100 loss: 0.02191160185262561
INFO:root:LOSS train' 0.02191160185262561, 10500
INFO:root:  batch 200 loss: 0.02105890626087785
INFO:root:LOSS train' 0.02105890626087785, 10600
INFO:root:  batch 300 loss: 0.021647063046693803
INFO:root:LOSS train' 0.021647063046693803, 10700
INFO:root:Epoch: 32 - LOSS train: 0.021647063046693803 LOSS val: 0.02193707413971424 - Elapsed time: 154.72466444969177 s
INFO:root:  batch 100 loss: 0.020542980562895538
INFO:root:LOSS train' 0.020542980562895538, 10825
INFO:root:  batch 200 loss: 0.02111855635419488
INFO:root:LOSS train' 0.02111855635419488, 10925
INFO:root:  batch 300 loss: 0.020114597864449024
INFO:root:LOSS train' 0.020114597864449024, 11025
INFO:root:Epoch: 33 - LOSS train: 0.020114597864449024 LOSS val: 0.024949191138148308 - Elapsed time: 154.8335726261139 s
INFO:root:  batch 100 loss: 0.020352920778095723
INFO:root:LOSS train' 0.020352920778095723, 11150
INFO:root:  batch 200 loss: 0.019919598065316676
INFO:root:LOSS train' 0.019919598065316676, 11250
INFO:root:  batch 300 loss: 0.020394994784146546
INFO:root:LOSS train' 0.020394994784146546, 11350
INFO:root:Epoch: 34 - LOSS train: 0.020394994784146546 LOSS val: 0.02013768069446087 - Elapsed time: 154.72021865844727 s
INFO:root:  batch 100 loss: 0.019679574463516473
INFO:root:LOSS train' 0.019679574463516473, 11475
INFO:root:  batch 200 loss: 0.019551151841878892
INFO:root:LOSS train' 0.019551151841878892, 11575
INFO:root:  batch 300 loss: 0.019292678497731686
INFO:root:LOSS train' 0.019292678497731686, 11675
INFO:root:Epoch: 35 - LOSS train: 0.019292678497731686 LOSS val: 0.02113180048763752 - Elapsed time: 154.88237714767456 s
INFO:root:  batch 100 loss: 0.019270349107682706
INFO:root:LOSS train' 0.019270349107682706, 11800
INFO:root:  batch 200 loss: 0.045586193408817054
INFO:root:LOSS train' 0.045586193408817054, 11900
INFO:root:  batch 300 loss: 0.029143939428031444
INFO:root:LOSS train' 0.029143939428031444, 12000
INFO:root:Epoch: 36 - LOSS train: 0.029143939428031444 LOSS val: 0.024068372324109077 - Elapsed time: 154.6945436000824 s
INFO:root:  batch 100 loss: 0.021998827941715718
INFO:root:LOSS train' 0.021998827941715718, 12125
INFO:root:  batch 200 loss: 0.025514922458678483
INFO:root:LOSS train' 0.025514922458678483, 12225
INFO:root:  batch 300 loss: 0.020513099040836095
INFO:root:LOSS train' 0.020513099040836095, 12325
INFO:root:Epoch: 37 - LOSS train: 0.020513099040836095 LOSS val: 0.019668377935886383 - Elapsed time: 154.56793308258057 s
INFO:root:  batch 100 loss: 0.02707793699577451
INFO:root:LOSS train' 0.02707793699577451, 12450
INFO:root:  batch 200 loss: 0.0241629258915782
INFO:root:LOSS train' 0.0241629258915782, 12550
INFO:root:  batch 300 loss: 0.020142805762588978
INFO:root:LOSS train' 0.020142805762588978, 12650
INFO:root:Epoch: 38 - LOSS train: 0.020142805762588978 LOSS val: 0.019603433087468147 - Elapsed time: 154.73364734649658 s
INFO:root:  batch 100 loss: 0.019545186255127193
INFO:root:LOSS train' 0.019545186255127193, 12775
INFO:root:  batch 200 loss: 0.01936049398034811
INFO:root:LOSS train' 0.01936049398034811, 12875
INFO:root:  batch 300 loss: 0.018581125885248184
INFO:root:LOSS train' 0.018581125885248184, 12975
INFO:root:Epoch: 39 - LOSS train: 0.018581125885248184 LOSS val: 0.018397517502307892 - Elapsed time: 154.75109577178955 s
INFO:root:  batch 100 loss: 0.018652261663228274
INFO:root:LOSS train' 0.018652261663228274, 13100
INFO:root:  batch 200 loss: 0.018734062919393182
INFO:root:LOSS train' 0.018734062919393182, 13200
INFO:root:  batch 300 loss: 0.01824682453647256
INFO:root:LOSS train' 0.01824682453647256, 13300
INFO:root:Epoch: 40 - LOSS train: 0.01824682453647256 LOSS val: 0.019402313977479935 - Elapsed time: 154.8220658302307 s
INFO:root:*************
INFO:root:             
INFO:root:Starting to test....
INFO:root:             
INFO:root:OneStep loss: 0.01865493319928646
INFO:root:Scalar loss: 0.025578362867236137
INFO:root:Vector loss: 0.015193214640021324
INFO:root:             
INFO:root:Done.

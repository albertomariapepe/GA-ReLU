INFO:root:*************
INFO:root:             
INFO:root:model chosen: CR
INFO:root:multivector activation function?: 0
INFO:root:training trajectories: 2080
INFO:root:training epochs: 200
INFO:root:training batchsize: 16
INFO:root:learning rate: 0.0001
INFO:root:seed: 28996
INFO:root:patience: 15
INFO:root:training dataset path: datasets/trainingdataviscous/
INFO:root:test dataset path: datasets/testdataviscous/
INFO:root:             
INFO:root:*************
INFO:root:Using device: cuda
INFO:root:[[[1.6940998  1.5566934  1.3046039  1.0440726 ]
  [1.6066581  1.3995012  1.342347   1.233624  ]
  [1.4666691  1.3354036  1.3883016  1.2737162 ]
  [1.4122795  1.3854291  1.4587754  1.339578  ]]

 [[1.6459564  1.3450366  1.0299298  0.77708894]
  [1.6489182  1.5250436  1.3721011  1.2203181 ]
  [1.4844782  1.3996952  1.3643513  1.3251002 ]
  [1.3969231  1.3963239  1.4048748  1.4067723 ]]]
INFO:root:****
INFO:root:[[[1.6940998  1.5566934  1.3046039  1.0440726 ]
  [1.6066581  1.3995012  1.342347   1.233624  ]
  [1.4666691  1.3354036  1.3883016  1.2737162 ]
  [1.4122795  1.3854291  1.4587754  1.339578  ]]

 [[1.6459564  1.3450366  1.0299298  0.77708894]
  [1.6489182  1.5250436  1.3721011  1.2203181 ]
  [1.4844782  1.3996952  1.3643513  1.3251002 ]
  [1.3969231  1.3963239  1.4048748  1.4067723 ]]]
INFO:root:Train input shape: torch.Size([2080, 2, 128, 128, 3])
INFO:root:Train labels shape: torch.Size([2080, 1, 128, 128, 3])
INFO:root:                   
INFO:root:Val input shape: torch.Size([4680, 2, 128, 128, 3])
INFO:root:Val labels shape: torch.Size([4680, 1, 128, 128, 3])
INFO:root:*************
INFO:root:             
INFO:root:Starting to train....
INFO:root:  batch 100 loss: 0.22119368553161622
INFO:root:LOSS train' 0.22119368553161622, 100
INFO:root:Epoch: 0 - LOSS train: 0.22119368553161622 LOSS val: 0.15536826848983765 - Elapsed time: 96.77338767051697 s
INFO:root:  batch 100 loss: 0.1450550964474678
INFO:root:LOSS train' 0.1450550964474678, 230
INFO:root:Epoch: 1 - LOSS train: 0.1450550964474678 LOSS val: 0.12710091471672058 - Elapsed time: 95.6987419128418 s
INFO:root:  batch 100 loss: 0.12205720812082291
INFO:root:LOSS train' 0.12205720812082291, 360
INFO:root:Epoch: 2 - LOSS train: 0.12205720812082291 LOSS val: 0.10826089233160019 - Elapsed time: 95.7032105922699 s
INFO:root:  batch 100 loss: 0.10875786438584328
INFO:root:LOSS train' 0.10875786438584328, 490
INFO:root:Epoch: 3 - LOSS train: 0.10875786438584328 LOSS val: 0.09541307389736176 - Elapsed time: 95.73771119117737 s
INFO:root:  batch 100 loss: 0.09930197224020958
INFO:root:LOSS train' 0.09930197224020958, 620
INFO:root:Epoch: 4 - LOSS train: 0.09930197224020958 LOSS val: 0.09268373996019363 - Elapsed time: 95.79420256614685 s
INFO:root:  batch 100 loss: 0.0888926212489605
INFO:root:LOSS train' 0.0888926212489605, 750
INFO:root:Epoch: 5 - LOSS train: 0.0888926212489605 LOSS val: 0.0814458429813385 - Elapsed time: 95.78393220901489 s
INFO:root:  batch 100 loss: 0.08151701420545578
INFO:root:LOSS train' 0.08151701420545578, 880
INFO:root:Epoch: 6 - LOSS train: 0.08151701420545578 LOSS val: 0.07843195647001266 - Elapsed time: 95.72514986991882 s
INFO:root:  batch 100 loss: 0.07592552036046982
INFO:root:LOSS train' 0.07592552036046982, 1010
INFO:root:Epoch: 7 - LOSS train: 0.07592552036046982 LOSS val: 0.11857952177524567 - Elapsed time: 95.64718747138977 s
INFO:root:  batch 100 loss: 0.07841357596218586
INFO:root:LOSS train' 0.07841357596218586, 1140
INFO:root:Epoch: 8 - LOSS train: 0.07841357596218586 LOSS val: 0.06490689516067505 - Elapsed time: 95.77442073822021 s
INFO:root:  batch 100 loss: 0.06642789743840695
INFO:root:LOSS train' 0.06642789743840695, 1270
INFO:root:Epoch: 9 - LOSS train: 0.06642789743840695 LOSS val: 0.062494583427906036 - Elapsed time: 95.86063814163208 s
INFO:root:  batch 100 loss: 0.06639871936291457
INFO:root:LOSS train' 0.06639871936291457, 1400
INFO:root:Epoch: 10 - LOSS train: 0.06639871936291457 LOSS val: 0.06198275834321976 - Elapsed time: 95.80905485153198 s
INFO:root:  batch 100 loss: 0.058988203704357145
INFO:root:LOSS train' 0.058988203704357145, 1530
INFO:root:Epoch: 11 - LOSS train: 0.058988203704357145 LOSS val: 0.06612392514944077 - Elapsed time: 95.80243062973022 s
INFO:root:  batch 100 loss: 0.058236010223627094
INFO:root:LOSS train' 0.058236010223627094, 1660
INFO:root:Epoch: 12 - LOSS train: 0.058236010223627094 LOSS val: 0.057543449103832245 - Elapsed time: 95.76663613319397 s
INFO:root:  batch 100 loss: 0.054977724738419054
INFO:root:LOSS train' 0.054977724738419054, 1790
INFO:root:Epoch: 13 - LOSS train: 0.054977724738419054 LOSS val: 0.054383061826229095 - Elapsed time: 95.66381001472473 s
INFO:root:  batch 100 loss: 0.05329063501209021
INFO:root:LOSS train' 0.05329063501209021, 1920
INFO:root:Epoch: 14 - LOSS train: 0.05329063501209021 LOSS val: 0.05559545010328293 - Elapsed time: 95.74473428726196 s
INFO:root:  batch 100 loss: 0.06600928250700236
INFO:root:LOSS train' 0.06600928250700236, 2050
INFO:root:Epoch: 15 - LOSS train: 0.06600928250700236 LOSS val: 0.04897475987672806 - Elapsed time: 95.61166286468506 s
INFO:root:  batch 100 loss: 0.05108000479638577
INFO:root:LOSS train' 0.05108000479638577, 2180
INFO:root:Epoch: 16 - LOSS train: 0.05108000479638577 LOSS val: 0.05087586119771004 - Elapsed time: 95.7949960231781 s
INFO:root:  batch 100 loss: 0.049345652051270006
INFO:root:LOSS train' 0.049345652051270006, 2310
INFO:root:Epoch: 17 - LOSS train: 0.049345652051270006 LOSS val: 0.046094514429569244 - Elapsed time: 95.81197810173035 s
INFO:root:  batch 100 loss: 0.04889452889561653
INFO:root:LOSS train' 0.04889452889561653, 2440
INFO:root:Epoch: 18 - LOSS train: 0.04889452889561653 LOSS val: 0.07076328992843628 - Elapsed time: 95.69249272346497 s
INFO:root:  batch 100 loss: 0.05137198634445667
INFO:root:LOSS train' 0.05137198634445667, 2570
INFO:root:Epoch: 19 - LOSS train: 0.05137198634445667 LOSS val: 0.04448216035962105 - Elapsed time: 95.67816352844238 s
INFO:root:  batch 100 loss: 0.044662677571177485
INFO:root:LOSS train' 0.044662677571177485, 2700
INFO:root:Epoch: 20 - LOSS train: 0.044662677571177485 LOSS val: 0.04247197136282921 - Elapsed time: 95.70362043380737 s
INFO:root:  batch 100 loss: 0.04674024261534214
INFO:root:LOSS train' 0.04674024261534214, 2830
INFO:root:Epoch: 21 - LOSS train: 0.04674024261534214 LOSS val: 0.046897899359464645 - Elapsed time: 95.78663563728333 s
INFO:root:  batch 100 loss: 0.04736548010259867
INFO:root:LOSS train' 0.04736548010259867, 2960
INFO:root:Epoch: 22 - LOSS train: 0.04736548010259867 LOSS val: 0.043393369764089584 - Elapsed time: 95.64642882347107 s
INFO:root:  batch 100 loss: 0.041809264160692694
INFO:root:LOSS train' 0.041809264160692694, 3090
INFO:root:Epoch: 23 - LOSS train: 0.041809264160692694 LOSS val: 0.0508798323571682 - Elapsed time: 95.81117081642151 s
INFO:root:  batch 100 loss: 0.041092293933033944
INFO:root:LOSS train' 0.041092293933033944, 3220
INFO:root:Epoch: 24 - LOSS train: 0.041092293933033944 LOSS val: 0.05106091499328613 - Elapsed time: 95.70029664039612 s
INFO:root:  batch 100 loss: 0.0406135955452919
INFO:root:LOSS train' 0.0406135955452919, 3350
INFO:root:Epoch: 25 - LOSS train: 0.0406135955452919 LOSS val: 0.038082055747509 - Elapsed time: 95.72216200828552 s
INFO:root:  batch 100 loss: 0.042387822680175304
INFO:root:LOSS train' 0.042387822680175304, 3480
INFO:root:Epoch: 26 - LOSS train: 0.042387822680175304 LOSS val: 0.037933994084596634 - Elapsed time: 95.69711899757385 s
INFO:root:  batch 100 loss: 0.03702860299497843
INFO:root:LOSS train' 0.03702860299497843, 3610
INFO:root:Epoch: 27 - LOSS train: 0.03702860299497843 LOSS val: 0.03799708932638168 - Elapsed time: 95.76430296897888 s
INFO:root:  batch 100 loss: 0.0364429996535182
INFO:root:LOSS train' 0.0364429996535182, 3740
INFO:root:Epoch: 28 - LOSS train: 0.0364429996535182 LOSS val: 0.03718802332878113 - Elapsed time: 95.73168468475342 s
INFO:root:  batch 100 loss: 0.05385857164859772
INFO:root:LOSS train' 0.05385857164859772, 3870
INFO:root:Epoch: 29 - LOSS train: 0.05385857164859772 LOSS val: 0.04474063962697983 - Elapsed time: 95.80785965919495 s
INFO:root:  batch 100 loss: 0.03898871831595898
INFO:root:LOSS train' 0.03898871831595898, 4000
INFO:root:Epoch: 30 - LOSS train: 0.03898871831595898 LOSS val: 0.036805927753448486 - Elapsed time: 95.76346516609192 s
INFO:root:  batch 100 loss: 0.035714952405542136
INFO:root:LOSS train' 0.035714952405542136, 4130
INFO:root:Epoch: 31 - LOSS train: 0.035714952405542136 LOSS val: 0.033797845244407654 - Elapsed time: 95.66630053520203 s
INFO:root:  batch 100 loss: 0.034679552149027584
INFO:root:LOSS train' 0.034679552149027584, 4260
INFO:root:Epoch: 32 - LOSS train: 0.034679552149027584 LOSS val: 0.035221558064222336 - Elapsed time: 95.76635432243347 s
INFO:root:  batch 100 loss: 0.034688364919275044
INFO:root:LOSS train' 0.034688364919275044, 4390
INFO:root:Epoch: 33 - LOSS train: 0.034688364919275044 LOSS val: 0.032914452254772186 - Elapsed time: 95.64413237571716 s
INFO:root:  batch 100 loss: 0.03327807374298573
INFO:root:LOSS train' 0.03327807374298573, 4520
INFO:root:Epoch: 34 - LOSS train: 0.03327807374298573 LOSS val: 0.03257360681891441 - Elapsed time: 95.57904124259949 s
INFO:root:  batch 100 loss: 0.032280701696872714
INFO:root:LOSS train' 0.032280701696872714, 4650
INFO:root:Epoch: 35 - LOSS train: 0.032280701696872714 LOSS val: 0.05000441521406174 - Elapsed time: 95.69756197929382 s
INFO:root:  batch 100 loss: 0.03322849126532674
INFO:root:LOSS train' 0.03322849126532674, 4780
INFO:root:Epoch: 36 - LOSS train: 0.03322849126532674 LOSS val: 0.04243222624063492 - Elapsed time: 95.7144718170166 s
INFO:root:  batch 100 loss: 0.033132287058979276
INFO:root:LOSS train' 0.033132287058979276, 4910
INFO:root:Epoch: 37 - LOSS train: 0.033132287058979276 LOSS val: 0.030864592641592026 - Elapsed time: 95.65763425827026 s
INFO:root:  batch 100 loss: 0.03224404515698552
INFO:root:LOSS train' 0.03224404515698552, 5040
INFO:root:Epoch: 38 - LOSS train: 0.03224404515698552 LOSS val: 0.033473748713731766 - Elapsed time: 95.76830220222473 s
INFO:root:*************
INFO:root:             
INFO:root:Starting to test....
INFO:root:             
INFO:root:OneStep loss: 0.031123792752623558
INFO:root:Scalar loss: 0.0410831943154335
INFO:root:Vector loss: 0.02614409290254116
INFO:root:             
INFO:root:Done.
